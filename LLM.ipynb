{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "unlikely-plasma",
      "metadata": {
        "id": "unlikely-plasma"
      },
      "source": [
        "# Introduction to Large Language Models\n",
        "\n",
        "(Pytorch nanoGPT code is from: https://github.com/karpathy/nanoGPT/blob/master/model.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "senior-jesus",
      "metadata": {
        "id": "senior-jesus"
      },
      "source": [
        "## Intro\n",
        "\n",
        "This chapter serves as an introduction to the basic concepts in Large Language Model (LLM) architectures and training. In the first section we will introduce the basic blocks and mechanisms of the transformer architecture, which most modern LLMs are based on. Next, we will introduce the basic ideas involved in the training of the LLMs. In addition, this notebook is intended to provide a runnable code implementation of the nanoGPT model and a basic training pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quality-allocation",
      "metadata": {
        "id": "quality-allocation"
      },
      "source": [
        "## Transformer Architecture\n",
        "\n",
        "Most modern LLMs are based on the *decoder-only transformer* model architecture. Essentially, the decoder-only transformer (we will refer to it simply as transformer) is a deep learning model built from multiple *transformer layers* as well as an *embedding* and a *Language Model (LM) Head* layer in the input and output, respectively.\n",
        "\n",
        "The transformer model takes as input sequences of *tokens* and outputs a probability distribution over possible next tokens for each input position. Those probability distributions are then used to generate the output text of the model.\n",
        "\n",
        "Next we will describe in detail its components and provide the corresponding codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fluid-tackle",
      "metadata": {
        "id": "fluid-tackle"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from dataclasses import dataclass\n",
        "import inspect\n",
        "import numpy as np\n",
        "from typing import Callable, Iterable, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crude-market",
      "metadata": {
        "id": "crude-market"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "Neural Networks such as the transformer work with numbers, not text. Therefore the input texts need to be converted to sequences of numbers before the transformer can process them. Thus, the text is first converted into discrete components known as *tokens*, which constitute the model's vocabulary $V$. Each of the tokens corresponds to a unique number, the *token ID*.\n",
        "\n",
        "The module that performs the conversion is called the *tokenizer*. It is technically considered a preprocessing module, separate from the transformer architecture. There are a number of different approaches to tokenization with one of the most popular being *Byte Pair Encoding (BPE)*, which performs subword tokenization by iteratively merging the most frequent pairs of symbols in the text. An important parameter of the tokenizer is the vocabulary size $V$, which is the total number of unique tokens it can produce and the model can recognize.  \n",
        "\n",
        "In short, the tokenizer, given as input raw text sequences, outputs a batch of token sequences and their corresponding IDs, which normally have a shape $[B, L]$. Here $B$ is the *batch size* that determines the number of sequences (or samples) the transformer will process in parallel and $L$ is the number of tokens per sequence.\n",
        "\n",
        "The batch of token ID sequences will then be converted to a batch of *embeddings vectors* (one embedding per token) by the *embedding layer* of the transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "latest-regression",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "aaee85e870cf47d59fe68bfd2e5c6367",
            "cd6a722354fc45a9aba111d3e4f81bcc",
            "e4f2409b9c5b4e03a2d0dacb877bd1a8",
            "ac7fd2f1553f4f05a95483aca960a65d",
            "5cadb7c3923c4f78be514e744c2a9019",
            "53cccf8246d94244b870b517ea30406f",
            "a7b67c1bdddf414892c966bfff2c49bd",
            "3ed65d7e9ed045c1a95489f486ac6b3b",
            "017c582da00441c3b9e20e28b792278d",
            "9df45a7573fe414d88a6fedbe5b17e14",
            "6268c346f73f4b1e8be7b08beaf01907",
            "4227aa820574412fa35b865904c3bc5c",
            "3023c8a4ad3340e0af7fb880432a7060",
            "caec2fe11b18487aab358e3586cebaf9",
            "85334869b60d46ccb341584806ca64f2",
            "e3658c5f4bc74e79aa44faa6e4d93feb",
            "a213e82c4260472f899bb5e3784694ca",
            "345b6b53dd99431792e107736c601563",
            "76dcd1614e4e4fd48c44ae943ae95ac9",
            "19abd8a981c341f7a379445d47c00678",
            "97378dffec5742bcba643da722311d45",
            "b5dc4ebe18014e45abf6af4ce5377740",
            "f12d07ad22ab481397db0e8736579884",
            "fedb2ad2aeb84cfbb8557e62dc29a0d8",
            "b183060e48794cd8afc2f1696c99d5bd",
            "5f2d6db1d8044b52b998b29edc868b6a",
            "3d46743637a84f3f893390707e28b04d",
            "806a074ef3884c1ab673bf5c9643fd1e",
            "b5a2b165736f4bccb16645eca8571cd2",
            "d534a87acb3e4bc4a8f239b2c5c8b58d",
            "15a1c9e763ec4e01a423b6d1ad32aa1d",
            "13af8dbc8dff45f28ced8d4b2565d426",
            "f7050cb4d71c47b5aaacb5fbe7f638cf",
            "ad3f990645a14c27971468382cc1248e",
            "deb828d5d05848df966d7079a5b345ca",
            "d2bcdce069584f35b8afd9ba5ac02d35",
            "9cacdf8a2165429aa20906f7e8fae7f8",
            "e98514dbbe4747e7a20fc115260e9fca",
            "bf0cd9e4eb4945908b5ce35328457134",
            "4fb934f1ef3c43a781b8daf123f820c1",
            "1a7c7177d4644b6889e9284e6583047a",
            "b30a44b9188540f1b676f74200fe9ae8",
            "3213f3114e124e1dab849055dfb99236",
            "9800d01ca55a429993fca5fe3f46274a",
            "fa16ac0dd4be4d609ddf5a685cbaf7f0",
            "b167b2d660a64fcd93830558319b8825",
            "597d9713266448e8911ba6774914f5cd",
            "9de1f861da034d05bce1e3e4b0134b12",
            "6c29bd62fbcb4c62b84211f6b3478f17",
            "e2b3d2420ade4a0cbcaac25d07a68c65",
            "0c0210abcc4c4363a475784b5d44d9a7",
            "f11c8f993e1a44ae852c58c5215b1e90",
            "953cd0368abb4df7bd8ae3ec58325cdb",
            "2fdf9926313f44889ff76983fa6cb7d1",
            "e4686d632d444410bdef83cfe0512da6"
          ]
        },
        "id": "latest-regression",
        "outputId": "eadab9a8-3837-4003-ac34-733ea2374fcb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaee85e870cf47d59fe68bfd2e5c6367"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4227aa820574412fa35b865904c3bc5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f12d07ad22ab481397db0e8736579884"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad3f990645a14c27971468382cc1248e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa16ac0dd4be4d609ddf5a685cbaf7f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pad token/ID: <|endoftext|> 50256\n",
            "Vocabulary size |V|: 50257\n",
            "Tokens:\n",
            "['The', 'Ġcat', 'Ġsat', 'Ġon', 'Ġthe', 'Ġmat', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>']\n",
            "['A', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog', '!']\n",
            "Input IDs:\n",
            " tensor([[  464,  3797,  3332,   319,   262,  2603, 50256, 50256, 50256, 50256],\n",
            "        [   32,  2068,  7586, 21831, 18045,   625,   262, 16931,  3290,     0]])\n",
            "Attention Mask:\n",
            " tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the GPT-2 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"Pad token/ID:\", tokenizer.pad_token,  tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n",
        "print(\"Vocabulary size |V|:\", tokenizer.vocab_size)\n",
        "\n",
        "# Example batch of texts\n",
        "texts = [\n",
        "    \"The cat sat on the mat\",\n",
        "    \"A quick brown fox jumps over the lazy dog!\"\n",
        "]\n",
        "\n",
        "# Tokenize the batch with padding, L=10\n",
        "encoded = tokenizer(texts, return_tensors=\"pt\", max_length=10 , truncation=True,  padding=\"max_length\" )\n",
        "\n",
        "tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in encoded[\"input_ids\"]]\n",
        "print(\"Tokens:\", *tokens, sep=\"\\n\")\n",
        "print(\"Input IDs:\\n\", encoded[\"input_ids\"])\n",
        "print(\"Attention Mask:\\n\", encoded[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb0614a",
      "metadata": {
        "id": "ccb0614a"
      },
      "source": [
        "Note that Ġ is a special symbol that the particular tokenizer usees to represent a space before a word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "social-safety",
      "metadata": {
        "id": "social-safety"
      },
      "source": [
        "### Embedding Layer\n",
        "\n",
        "The input tokens are discrete and therefore not directly optimizable by gradient-based methods. Thus they need to be converted to continuous, dense vectors that capture semantic meanings and can be learned and optimized by the transformer. This is done by the *embedding layer*.\n",
        "\n",
        "The embedding layer is essentially a trainable look-up table. It takes as input the token IDs and outputs the corresponding rows - which are the *embedding vectors* for the specified token IDs. It has shape ($|V|$, $d_{\\text{model}}$), where $d_{\\text{model}}$ is the dimension of the embedding vectors. Bellow is an example of how it looks in code:\n",
        "\n",
        "\n",
        "```python\n",
        "embedding.weight = [\n",
        "    [e1_1, e1_2, ..., e1_d],   # embedding for token 1\n",
        "    [e2_1, e2_2, ..., e2_d],   # embedding for token 2\n",
        "    ...\n",
        "    [en_1, en_2, ..., en_d],   # embedding for token n\n",
        "]\n",
        "# where n = |V| and d = d_model\n",
        "```\n",
        "\n",
        "Therefore, the embedding layer for an input tensor of shape $[B, L]$ it will output a tensor of shape $[B, L, d_{\\text{model}}]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "reverse-faculty",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reverse-faculty",
        "outputId": "8d87da60-2d7a-40bc-fd37-cbccea4f0262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[  464,  3797,  3332,   319,   262,  2603, 50256, 50256, 50256, 50256],\n",
            "        [   32,  2068,  7586, 21831, 18045,   625,   262, 16931,  3290,     0]])\n",
            "Embedding vectors:\n",
            " tensor([[[ 0.1296,  0.4145,  0.3291],\n",
            "         [ 0.4642,  0.6529,  1.5106],\n",
            "         [ 0.6541, -1.6905, -0.0428],\n",
            "         [ 3.4913,  0.0044,  2.0248],\n",
            "         [-0.5078,  0.0327,  1.3537],\n",
            "         [ 1.4801, -0.6434, -0.6449],\n",
            "         [ 0.0767, -0.6003, -1.3610],\n",
            "         [ 0.0767, -0.6003, -1.3610],\n",
            "         [ 0.0767, -0.6003, -1.3610],\n",
            "         [ 0.0767, -0.6003, -1.3610]],\n",
            "\n",
            "        [[-0.2072,  0.5900,  0.3016],\n",
            "         [-0.9791, -0.9526, -0.3668],\n",
            "         [-0.2680, -0.7087, -1.1556],\n",
            "         [-0.1547,  1.1106, -0.5717],\n",
            "         [ 1.1608, -0.0681,  2.5914],\n",
            "         [ 0.8884,  0.2063, -0.2748],\n",
            "         [-0.5078,  0.0327,  1.3537],\n",
            "         [-1.8141, -0.3699, -0.7468],\n",
            "         [-1.4542,  2.2813,  1.2167],\n",
            "         [-0.5531,  1.1152,  0.3273]]], grad_fn=<EmbeddingBackward0>)\n",
            "Embedding Layer output shape: torch.Size([2, 10, 3])\n"
          ]
        }
      ],
      "source": [
        "V = tokenizer.vocab_size #|V| = 50256\n",
        "d_model = 3 # Small value for illustration purposes. E.g., nanoGPT uses d_model=768\n",
        "\n",
        "embedding = nn.Embedding(num_embeddings=V, embedding_dim=d_model)\n",
        "\n",
        "# Token IDs from previous example.\n",
        "input_ids = encoded[\"input_ids\"]\n",
        "\n",
        "print(\"Token IDs:\\n\", input_ids)\n",
        "\n",
        "embedded_vectors = embedding(input_ids)\n",
        "\n",
        "print(\"Embedding vectors:\\n\", embedded_vectors)\n",
        "print(\"Embedding Layer output shape:\", embedded_vectors.shape) # Output shape [B=2, L=10, d_model=3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "seasonal-choice",
      "metadata": {
        "id": "seasonal-choice"
      },
      "source": [
        "### Self-attention\n",
        "\n",
        "Self-attention is a mechanism that transforms the representation of each token in a sequence by relating it to different tokens of the sequence. This new representation can then be used by the model to e.g., predict the next word of the sequence.\n",
        "\n",
        "For example, lets say we have the sentence \"The cat sat on the mat\". We can assume a simple word tokenizer and an embedding layer which results in one embedding vector for each word:  \n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "| The    | cat   | sat   | on    | the   | mat   |\n",
        "|-------|-------|-------|-------|-------|-------|\n",
        "| $e_1$ | $e_2$ | $e_3$ | $e_4$ | $e_5$ | $e_6$ |\n",
        "\n",
        "</div>\n",
        "\n",
        "If we wanted to create a model to predict the next word, we could directly just use an MLP+softmax (see bellow for more details about softmax) with input one of the embedding vectors like the above and output a probability distribution over the vocabulary.\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input Tokens} \\quad [B, L] \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Embedding Layer}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Token Embeddings} \\quad [B, L, d_{\\text{model}}] \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{MLP (Feed-Forward Network)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{MLP Output} \\quad [B, L, |V|] \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Softmax (next token probabilities)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output Probabilities} \\quad [B, L, |V|]\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "\n",
        "However, currently each embedding $e_i$ contains information only for the particular word it embeds, regardless of the rest of the sequence. So for example given $e_5$ the model would just predict the most probable word after a \"the\", which is certainly not \"mat\". Instead, with a self-attention layer $e_5$ will be transformed into $e_5' = f(e_1, e_2, e_3, e_4, e_5)$, now containing the context. Here $f()$ represents the self-attention transformation that produces the *contextualized* embedding, which we will describe in details in the next part.\n",
        "\n",
        "**More on the Softmax Operator** Given a vector of logits $\\mathbf{z} = [z_1, z_2, \\dots, z_{|V|}] \\in \\mathbb{R}^{|V|} $, where $|V| $ is the vocabulary size, the softmax function is defined component-wise as:\n",
        "\n",
        "$$\n",
        "\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{|V|} e^{z_j}}, \\quad \\text{for } i = 1, \\dots, |V|.\n",
        "$$\n",
        "\n",
        "The output is a probability vector  $\\mathbf{p} = \\text{softmax}(\\mathbf{z}) \\in \\mathbb{R}^{|V|} $ such that:\n",
        "\n",
        "- $ p_i > 0 $ for all $ i $\n",
        "- $ \\sum_{i=1}^{|V|} p_i = 1 $\n",
        "\n",
        "Thus, $\\mathbf{p} \\in \\Delta^{|V|-1} $, the probability simplex.\n",
        "\n",
        "Bellow we will describe how self-attention is computed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "listed-panic",
      "metadata": {
        "id": "listed-panic"
      },
      "source": [
        "### Scaled Dot-Product Attention\n",
        "\n",
        "- Assume batch size B=1\n",
        "- X is the embedding matrix (contains the embedding vectors of $L$ tokens)\n",
        "- Assume single attention layer after the embedding layer\n",
        "\n",
        "Input matrix:\n",
        "\n",
        "$$\n",
        "X =\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "\\vdots \\\\\n",
        "x_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_{\\text{model}}}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "We apply learned projection matrices:\n",
        "\n",
        "$$\n",
        "W_Q \\in \\mathbb{R}^{d_{\\text{model}} \\times d_q}, \\quad\n",
        "W_K \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad\n",
        "W_V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}\n",
        "$$\n",
        "\n",
        "To obtain the queries, keys, and values:\n",
        "\n",
        "\n",
        "                    \n",
        "$$\n",
        "Q = X W_Q =\n",
        "\\begin{bmatrix}\n",
        "q_1 \\\\\n",
        "q_2 \\\\\n",
        "\\vdots \\\\\n",
        "q_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_q}, \\quad\n",
        "K = X W_K =\n",
        "\\begin{bmatrix}\n",
        "k_1 \\\\\n",
        "k_2 \\\\\n",
        "\\vdots \\\\\n",
        "k_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_k}, \\quad\n",
        "V = X W_V =\n",
        "\\begin{bmatrix}\n",
        "v_1 \\\\\n",
        "v_2 \\\\\n",
        "\\vdots \\\\\n",
        "v_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_v}\n",
        "$$\n",
        "\n",
        "Attention logits matrix $QK^T$:\n",
        "\n",
        "$$\n",
        "QK^T \\in \\mathbb{R}^{L \\times L} =\n",
        "\\begin{bmatrix}\n",
        "q_1 \\\\\n",
        "q_2 \\\\\n",
        "\\vdots \\\\\n",
        "q_L\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "k_1^T & k_2^T & \\cdots & k_L^T\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "q_1 k_1^T & q_1 k_2^T & \\cdots & q_1 k_L^T \\\\\n",
        "q_2 k_1^T & q_2 k_2^T & \\cdots & q_2 k_L^T \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "q_L k_1^T & q_L k_2^T & \\cdots & q_L k_L^T \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "Attention weight matrix $A$:\n",
        "\n",
        "\n",
        "$$\n",
        "A = [a_{ij}] \\in \\mathbb{R}^{L \\times L} =\n",
        "\\textrm{Softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) =\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\exp \\left( \\frac{q_1 k_1^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_1 k_j^T}{\\sqrt{d_k}} \\right)} & \\cdots & \\frac{\\exp \\left( \\frac{q_1 k_L^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_1 k_j^T}{\\sqrt{d_k}} \\right)} \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "\\frac{\\exp \\left( \\frac{q_L k_1^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_L k_j^T}{\\sqrt{d_k}} \\right)} & \\cdots & \\frac{\\exp \\left( \\frac{q_L k_L^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_L k_j^T}{\\sqrt{d_k}} \\right)}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Note that $a_{ij}$ is the attention weight of query $q_i$ wrt key $k_j$ and indicates the level of attention that token $i$ pays on token $j$.\n",
        "\n",
        "Attention output $Z$:\n",
        "\n",
        "\n",
        "$$\n",
        "Z \\in \\mathbb{R}^{L \\times d_v} =\n",
        "\\textrm{Softmax} \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) \\cdot V\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "a_{11} & a_{12} & \\cdots & a_{1L} \\\\\n",
        "a_{21} & a_{22} & \\cdots & a_{2L} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "a_{L1} & a_{L2} & \\cdots & a_{LL}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "v_1 \\\\\n",
        "v_2 \\\\\n",
        "\\vdots \\\\\n",
        "v_L\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "\\sum\\limits_{j=1}^{L} a_{1j} v_j \\\\\n",
        "\\sum\\limits_{j=1}^{L} a_{2j} v_j \\\\\n",
        "\\vdots \\\\\n",
        "\\sum\\limits_{j=1}^{L} a_{Lj} v_j\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "$Z$ is the output of the attention layer, which weights the value vectors $v_i$ based on the computed attention weights. Each $z_i$ combines information from different value vectors (corresponding to different tokens) according to the attention given to each key by each query.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "superb-consumer",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "superb-consumer",
        "outputId": "b975caf6-c808-48ce-cf24-6e2daa716545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings:\n",
            " [[0.1 0.2 0.3 0.4]\n",
            " [0.5 0.6 0.7 0.8]\n",
            " [0.9 1.  1.1 1.2]]\n",
            "\n",
            "Query Matrix (Q):\n",
            " [[0.61813107 0.45006872 0.50178942 0.37187442]\n",
            " [1.52446772 1.30629011 1.3495264  1.08329982]\n",
            " [2.43080437 2.1625115  2.19726338 1.79472521]]\n",
            "\n",
            "Key Matrix (K):\n",
            " [[0.49155078 0.63600866 0.40817395 0.53884428]\n",
            " [1.221927   1.77719537 0.94109091 1.37209303]\n",
            " [1.95230322 2.91838209 1.47400787 2.20534178]]\n",
            "\n",
            "Value Matrix (V):\n",
            " [[0.25310593 0.51028359 0.16528225 0.47660737]\n",
            " [0.69089158 1.2593438  0.57305515 1.18998258]\n",
            " [1.12867724 2.00840401 0.98082805 1.90335778]]\n",
            "\n",
            "Attention Logits (Q K^T / sqrt(d_k)):\n",
            " [[0.49764509 1.26882343 2.04000176]\n",
            " [1.35736828 3.47036808 5.58336789]\n",
            " [2.21709146 5.67191274 9.12673401]]\n",
            "\n",
            "Attention Weights (Softmax of Logits):\n",
            " [[1.27585052e-01 2.75878775e-01 5.96536173e-01]\n",
            " [1.28673786e-02 1.06452100e-01 8.80680521e-01]\n",
            " [9.66611603e-04 3.05958005e-02 9.68437588e-01]]\n",
            "\n",
            "Output Z (Weighted Sum of Values):\n",
            " [[0.89619166 1.61061643 0.76428071 1.52452068]\n",
            " [1.07080773 1.90938809 0.92692583 1.80905896]\n",
            " [1.1144365  1.98403781 0.96756359 1.88015239]]\n"
          ]
        }
      ],
      "source": [
        "# Numpy implementation of dot-product attention:\n",
        "\n",
        "# Define embedding vectors for tokens (3 tokens/sq_len, 4-dimensional embeddings)\n",
        "embedding_dim = 4\n",
        "X = np.array([[0.1, 0.2, 0.3, 0.4],   # Embedding for token 1\n",
        "              [0.5, 0.6, 0.7, 0.8],   # Embedding for token 2\n",
        "              [0.9, 1.0, 1.1, 1.2]])  # Embedding for token 3\n",
        "\n",
        "# Define weight matrices for the transformations (W_Q, W_K, W_V)\n",
        "W_Q = np.random.rand(embedding_dim, embedding_dim)  # Query weight matrix\n",
        "W_K = np.random.rand(embedding_dim, embedding_dim)  # Key weight matrix\n",
        "W_V = np.random.rand(embedding_dim, embedding_dim)  # Value weight matrix\n",
        "\n",
        "# Compute the Q, K, V matrices by applying the transformations to the embeddings\n",
        "Q = np.dot(X, W_Q)  # Query matrix (Q)\n",
        "K = np.dot(X, W_K)  # Key matrix (K)\n",
        "V = np.dot(X, W_V)  # Value matrix (V)\n",
        "\n",
        "# Define the scaling factor (sqrt of key dimension)\n",
        "d_k = K.shape[1]\n",
        "scaling_factor = np.sqrt(d_k)\n",
        "\n",
        "# Compute the attention logits (Q K^T / sqrt(d_k))\n",
        "logits = np.dot(Q, K.T) / scaling_factor\n",
        "\n",
        "# Apply softmax to the logits to get attention weights\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "attention_weights = softmax(logits)\n",
        "\n",
        "# Compute the output Z (weighted sum of values)\n",
        "Z = np.dot(attention_weights, V)\n",
        "\n",
        "print(\"Embeddings:\\n\", X)\n",
        "print(\"\\nQuery Matrix (Q):\\n\", Q)\n",
        "print(\"\\nKey Matrix (K):\\n\", K)\n",
        "print(\"\\nValue Matrix (V):\\n\", V)\n",
        "print(\"\\nAttention Logits (Q K^T / sqrt(d_k)):\\n\", logits)\n",
        "print(\"\\nAttention Weights (Softmax of Logits):\\n\", attention_weights)\n",
        "print(\"\\nOutput Z (Weighted Sum of Values):\\n\", Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "moved-poland",
      "metadata": {
        "id": "moved-poland"
      },
      "source": [
        "### Masked (or causal) self-attention\n",
        "\n",
        "In practice, transformers use a version of self-attention called masked or causal self-attention. In contrast to (bidirectional) self-attention that computes attentions scores for all tokens in the sequence, masked self-attention uses a *causal mask* that hides future tokens, so each token can attend to itself and earlier tokens.\n",
        "\n",
        "Example of a casual mask:\n",
        "\n",
        "$$\n",
        "\\begin{array}{c|cccccc}\n",
        "    & \\text{The} & \\text{cat} & \\text{sat} & \\text{on} & \\text{the} & \\text{mat} \\\\\n",
        "\\hline\n",
        "\\text{The} & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
        "\\text{cat} & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n",
        "\\text{sat} & 1 & 1 & 1 & 0 & 0 & 0 \\\\\n",
        "\\text{on}  & 1 & 1 & 1 & 1 & 0 & 0 \\\\\n",
        "\\text{the} & 1 & 1 & 1 & 1 & 1 & 0 \\\\\n",
        "\\text{mat}& 1 & 1 & 1 & 1 & 1 & 1\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Where 1 means the token can attend, 0 means it’s masked out. Note that for simplicity each word represents a token. So,\n",
        "- \"The\" can attend only to itself.\n",
        "- \"cat\" can attend only to \"The\" and \"cat\".\n",
        "- \"mat\" can attend to everything in this sentence.\n",
        "\n",
        "Usually this masking is done by setting the $q_i k_j^T$ with $i < j$ to $-\\infty$ in the $QK^T$ attention logits matrix so that the application of the softmax will give zero attention weights to those positions.\n",
        "\n",
        "In short, using the same notation as scaled-dot product attention where $X$ is the input embedding matrix, masked self attention computes:\n",
        "\n",
        "$$\n",
        "Z_\\text{masked}  \\in  \\mathbb{R}^{L \\times d_v}\n",
        "=\n",
        "\\text{Softmax}\\!\\left(\n",
        "\\frac{QK^{T}}{\\sqrt{d_k}} + \\log M\n",
        "\\right)V,\n",
        "\\quad Q=XW_Q,\\, K=XW_K,\\, V=XW_V.\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "(\\log M)_{ij} =\n",
        "\\begin{cases}\n",
        "0, & j \\le i, \\\\[4pt]\n",
        "-\\infty, & j > i.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Note that $i$ here corresponds to a row (query token index) and $j$ to a column (key token index) of $QK^{T}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "junior-colors",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "junior-colors",
        "outputId": "be3c8e81-1d2e-48d7-e141-6b16d33912af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings:\n",
            " [[0.1 0.2 0.3 0.4]\n",
            " [0.5 0.6 0.7 0.8]\n",
            " [0.9 1.  1.1 1.2]]\n",
            "\n",
            "Query Matrix (Q):\n",
            " [[0.77259122 0.58839732 0.59604137 0.55662128]\n",
            " [1.83517005 1.54039332 1.4282729  1.51596075]\n",
            " [2.89774888 2.49238932 2.26050442 2.47530022]]\n",
            "\n",
            "Key Matrix (K):\n",
            " [[0.49995455 0.38351055 0.70871359 0.4799025 ]\n",
            " [1.26993696 1.05149935 1.71628577 1.43159499]\n",
            " [2.03991936 1.71948815 2.72385795 2.38328749]]\n",
            "\n",
            "Value Matrix (V):\n",
            " [[0.51639347 0.5124138  0.45281154 0.42587846]\n",
            " [1.47375801 1.28631167 1.02240151 1.10464183]\n",
            " [2.43112254 2.06020954 1.59199147 1.7834052 ]]\n",
            "\n",
            "Attention Logits (Q K^T / sqrt(d_k)):\n",
            " [[ 0.65073182  1.70983755  2.76894328]\n",
            " [ 1.62400423  4.28591955  6.94783487]\n",
            " [ 2.59727664  6.86200155 11.12672646]]\n",
            "\n",
            "Mask (1=keep, 0=mask):\n",
            " [[1. 0. 0.]\n",
            " [1. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "\n",
            "Masked Attention Logits:\n",
            " [[ 6.50731817e-01 -1.00000000e+09 -1.00000000e+09]\n",
            " [ 1.62400423e+00  4.28591955e+00 -1.00000000e+09]\n",
            " [ 2.59727664e+00  6.86200155e+00  1.11267265e+01]]\n",
            "\n",
            "Attention Weights (Softmax of Masked Logits):\n",
            " [[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [6.52584020e-02 9.34741598e-01 0.00000000e+00]\n",
            " [1.94787275e-04 1.38582081e-02 9.85947005e-01]]\n",
            "\n",
            "Output Z (Weighted Sum of Values):\n",
            " [[0.51639347 0.5124138  0.45281154 0.42587846]\n",
            " [1.41128193 1.23580833 0.98523098 1.06034682]\n",
            " [2.41748222 2.04918321 1.58387608 1.77373432]]\n"
          ]
        }
      ],
      "source": [
        "# Numpy implementation of masked self-attention:\n",
        "\n",
        "# Define embedding vectors for tokens (3 tokens/sq_len, 4-dimensional embeddings)\n",
        "embedding_dim = 4\n",
        "X = np.array([[0.1, 0.2, 0.3, 0.4],   # Embedding for token 1\n",
        "              [0.5, 0.6, 0.7, 0.8],   # Embedding for token 2\n",
        "              [0.9, 1.0, 1.1, 1.2]])  # Embedding for token 3\n",
        "\n",
        "# Define weight matrices for the transformations (W_Q, W_K, W_V)\n",
        "W_Q = np.random.rand(embedding_dim, embedding_dim)  # Query weight matrix\n",
        "W_K = np.random.rand(embedding_dim, embedding_dim)  # Key weight matrix\n",
        "W_V = np.random.rand(embedding_dim, embedding_dim)  # Value weight matrix\n",
        "\n",
        "# Compute the Q, K, V matrices by applying the transformations to the embeddings\n",
        "Q = np.dot(X, W_Q)  # Query matrix (Q)\n",
        "K = np.dot(X, W_K)  # Key matrix (K)\n",
        "V = np.dot(X, W_V)  # Value matrix (V)\n",
        "\n",
        "# Define the scaling factor (sqrt of key dimension)\n",
        "d_k = K.shape[1]\n",
        "scaling_factor = np.sqrt(d_k)\n",
        "\n",
        "# Compute the attention logits (Q K^T / sqrt(d_k))\n",
        "logits = np.dot(Q, K.T) / scaling_factor\n",
        "\n",
        "# Create causal mask: shape (seq_len, seq_len)\n",
        "seq_len = X.shape[0]\n",
        "mask = np.tril(np.ones((seq_len, seq_len)))  # Lower triangular matrix including diagonal\n",
        "\n",
        "# Apply mask: set logits where mask==0 to very large negative value (simulate -inf)\n",
        "logits_masked = np.where(mask == 1, logits, -1e9)\n",
        "\n",
        "# Apply softmax to the masked logits to get attention weights\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # for numerical stability\n",
        "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
        "\n",
        "attention_weights = softmax(logits_masked)\n",
        "\n",
        "# Compute the output Z (weighted sum of values)\n",
        "Z = np.dot(attention_weights, V)\n",
        "\n",
        "print(\"Embeddings:\\n\", X)\n",
        "print(\"\\nQuery Matrix (Q):\\n\", Q)\n",
        "print(\"\\nKey Matrix (K):\\n\", K)\n",
        "print(\"\\nValue Matrix (V):\\n\", V)\n",
        "print(\"\\nAttention Logits (Q K^T / sqrt(d_k)):\\n\", logits)\n",
        "print(\"\\nMask (1=keep, 0=mask):\\n\", mask)\n",
        "print(\"\\nMasked Attention Logits:\\n\", logits_masked)\n",
        "print(\"\\nAttention Weights (Softmax of Masked Logits):\\n\", attention_weights)\n",
        "print(\"\\nOutput Z (Weighted Sum of Values):\\n\", Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diagnostic-coaching",
      "metadata": {
        "id": "diagnostic-coaching"
      },
      "source": [
        "### Multi-Head Attention:\n",
        "\n",
        "$$\n",
        "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W^O\n",
        "\\quad \\text{where} \\quad \\\\\n",
        "\\text{head}_i = \\text{Attention}(Q W_i^Q, \\; K W_i^K, \\; V W_i^V)\n",
        "$$\n",
        "\n",
        "where the projection matrices are:\n",
        "$\n",
        "\\quad\n",
        "W_i^Q \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad\n",
        "W_i^K \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad\n",
        "W_i^V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}, \\quad\n",
        "\\text{and} \\quad\n",
        "W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text{model}}}\n",
        "$\n",
        "\n",
        "\n",
        "In short, multi-head attention allows the model to attend to different aspects of the input sequence simultaneously (e.g., some heads might focus on different context type than others) and is found to be beneficial in practice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "complete-rabbit",
      "metadata": {
        "id": "complete-rabbit"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation of causal self-attention (multi-head)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        # ! n_embd = d_model, c_attn acts as all three W_q, W_k, W_v at once and all have output dim n_embd.\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "driving-extraction",
      "metadata": {
        "id": "driving-extraction"
      },
      "source": [
        "### LayerNorm\n",
        "\n",
        "*Layer Normalization* (LayerNorm) is used to stabilize and accelerate training by normalizing the input across features.\n",
        "\n",
        "Given input vector $x \\in \\mathbb{R}^d$ (e.g., the hidden state of one token), compute:\n",
        "\n",
        "$$\\mu = \\frac{1}{d} \\sum_{i=1}^{d} x_i,  \\  \\ \\sigma^2 = \\frac{1}{d} \\sum_{i=1}^{d} (x_i - \\mu)^2$$\n",
        "\n",
        "Then Layer Normalization is applied as:\n",
        "\n",
        "$$  \\textrm{LayerNorm}(x)_i =   \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\cdot \\gamma_i + \\beta_i, $$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\gamma \\in \\mathbb{R}^d$: learnable scale\n",
        "\n",
        "- $\\beta \\in \\mathbb{R}^d$: learnable bias\n",
        "\n",
        "Given an input $X \\in \\mathbb{R}^{B \\times L \\times d_{\\textrm{model}}}$, LayerNorm($X$) will be applied independently for each token's hidden state, $x_{b,t} \\in \\mathbb{R}^{d_{\\textrm{model}}}$, unlike BatchNorm which normalizes across a batch. Note that $\\gamma$ and $\\beta$ dimensions will remain $d_{\\textrm{model}}$ as they are shared across tokens for all sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "personal-palestine",
      "metadata": {
        "id": "personal-palestine"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation of Layer Normalization\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
        "\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "other-configuration",
      "metadata": {
        "id": "other-configuration"
      },
      "source": [
        "### MLP Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "studied-exploration",
      "metadata": {
        "id": "studied-exploration"
      },
      "source": [
        "\n",
        "#### MLP diagram:\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input } x \\quad (B \\times L \\times d_{\\text{model}}) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Linear } (d_{\\text{model}} \\rightarrow 4 d_{\\text{model}}) \\\\\n",
        "(\\text{c\\_fc})\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{GELU Activation}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Linear } (4 d_{\\text{model}} \\rightarrow d_{\\text{model}}) \\\\\n",
        "(\\text{c\\_proj})\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Dropout}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output } x \\quad (B \\times L \\times d_{\\text{model}})\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "#### Block Layer diagram:\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input } x \\quad (B \\times L \\times d_{\\text{model}}) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{LayerNorm (ln\\_1)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Causal Self-Attention} \\\\\n",
        "\\text{(attn)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Residual: } x = x + \\text{Attention Output} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{LayerNorm (ln\\_2)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{MLP (diagram above)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Residual: } x = x + \\text{MLP Output} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output of Block } (B \\times L \\times d_{\\text{model}})\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "incomplete-turner",
      "metadata": {
        "id": "incomplete-turner"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation of MLP Layer\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conceptual-server",
      "metadata": {
        "id": "conceptual-server"
      },
      "source": [
        "### Decoder-only transformer (nanoGPT)\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input Tokens (indices)} \\quad (B \\times L) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Token Embedding (wte)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "+ \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Learned Positional Embedding (wpe)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Token Embeddings + Positional Embeddings (with Dropout)} \\quad (B \\times L \\times d_{\\text{model}}) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Block 1:} \\\\\n",
        "x = x + \\text{Causal Self-Attention}(\\text{LayerNorm}(x)) \\\\\n",
        "x = x + \\text{MLP}(\\text{LayerNorm}(x))\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Block 2:} \\\\\n",
        "x = x + \\text{Causal Self-Attention}(\\text{LayerNorm}(x)) \\\\\n",
        "x = x + \\text{MLP}(\\text{LayerNorm}(x))\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\vdots \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Block N:} \\\\\n",
        "x = x + \\text{Causal Self-Attention}(\\text{LayerNorm}(x)) \\\\\n",
        "x = x + \\text{MLP}(\\text{LayerNorm}(x))\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Final LayerNorm (ln\\_f)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Linear Projection (lm\\_head)} \\\\\n",
        "\\text{(weights tied with token embeddings)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output Logits} \\quad (B \\times L \\times |V|) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Softmax (next token probabilities)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output Probabilities} \\quad (B \\times L \\times |V|)\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "split-projection",
      "metadata": {
        "id": "split-projection"
      },
      "outputs": [],
      "source": [
        "# Pytorch implemenation of nanoGPT\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
        "\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
        "\n",
        "        # init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        \"\"\"\n",
        "        Return the number of parameters in the model.\n",
        "        For non-embedding count (default), the position embeddings get subtracted.\n",
        "        The token embeddings would too, except due to the parameter sharing these\n",
        "        params are actually used as weights in the final layer, so we include them.\n",
        "        \"\"\"\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # if we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-100)\n",
        "        else:\n",
        "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
        "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
        "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # if the sequence context is growing too long we must crop it at block_size\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            # forward the model to get the logits for the index in the sequence\n",
        "            logits, _ = self(idx_cond)\n",
        "            # pluck the logits at the final step and scale by desired temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            # optionally crop the logits to only the top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            # apply softmax to convert logits to (normalized) probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "governmental-destiny",
      "metadata": {
        "id": "governmental-destiny"
      },
      "source": [
        "## LLM Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6839d0bc",
      "metadata": {
        "id": "6839d0bc"
      },
      "source": [
        "Now that we have implemented the model, we move to the training part of the tutorial. Our goal is to take the randomly initialized model and train it on a large text dataset.\n",
        "\n",
        "This is the first (and most expensive) stage of model training and it is known as *pre-training*, as we beging with a completely untrained model and train it on a large, generic dataset. Next, the model is usualy *fine-tuned* on more specialized or task-oriented datasets much smaller in size, and finally the model is trained to align with human preferences (*alignment*).\n",
        "\n",
        "For our tutorial, we will use a subset of the cleaned english part (en) of the C4 (Colossal Clean Crawled Corpus) dataset. In particular, C4/en consists of 305GB of english sentences. After tokenization, it roughly produces 150B tokens (although the exact value will depend on the tokenizer being used). More details about C4 can be found in this link: https://huggingface.co/datasets/allenai/c4.\n",
        "\n",
        "Next, we will go though our basic pre-training pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "thrown-evanescence",
      "metadata": {
        "id": "thrown-evanescence"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from torch.utils.data import IterableDataset, get_worker_info"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7391d721",
      "metadata": {
        "id": "7391d721"
      },
      "source": [
        "### Training parameters\n",
        "\n",
        "Bellow we define our training parameters. For some of them we include more details here:\n",
        "\n",
        "`device=f\"cuda:0\"`: The ID of our GPU. Note that this simple training code does not support multi-GPU training as it is intended for training small models on relatively small amounts of data. However, in practice training LLMs entails the use of multiple GPUs using parallelization techniques. Such an implementation could be included in a future version of the tutorial.\n",
        "\n",
        "`device_batch_size=64`: The number of token sequences processed simultaneously on one GPU.\n",
        "\n",
        "`total_batch_size=256`: The number of token sequences the model \"sees\" at each training iteration. For our single GPU set-up:\n",
        "\n",
        "<p align=\"center\"><code>gradient_accumulation = total_batch_size / device_batch_size</code></p>\n",
        "\n",
        "(4 in this case) means that before the model weights are updated, the gradients from `gradient_accumulation=4` mini-batches (each having `device_batch_size=64` token sequences) are summed (accumulated) and averaged, so the update reflects the effect of all `total_batch_size=256` sequences together.\n",
        "\n",
        "`num_training_steps = 100`: The number of training steps (model updates) that will be performed. Note that it is set to 100 just for code testing purposes. In practice, for pretraining a good guideline is the *Chinchilla compute-optimal ratio*, i.e. using about 20 tokens per (non-embedding) model parameter. So, since our model has 124M trainable parameters, this corresponds to about 2.5B tokens needed for training. Given that we use `total_batch_size=256` and `max_length=256` (the maximum sequence length), each batch size will have 65,536 tokens (or in rare cases less if some sequences are smaller than the `max_length`), so roughly we need 2.5B / 65,536 $\\approx 38,000$ steps. For more details about compute optimal training and the Chinchilla ratio see: https://arxiv.org/abs/2203.15556."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "characteristic-scholarship",
      "metadata": {
        "id": "characteristic-scholarship"
      },
      "outputs": [],
      "source": [
        "# Environment parameters:\n",
        "device = f\"cuda:0\" # Our GPU id\n",
        "workers = 4 # CPU workers\n",
        "# Data parameters:\n",
        "device_batch_size = 64\n",
        "# Tokenization parameters:\n",
        "max_length = 256  # sequence length L\n",
        "# Optimizer parameters\n",
        "lr = 1e-3\n",
        "weight_decay = 0.0\n",
        "# LR scheduler parameters\n",
        "warmup_steps = 1000\n",
        "# Training parameters:\n",
        "num_training_steps = 5_000 # 38_000\n",
        "total_batch_size = 256\n",
        "grad_clipping = 0.0\n",
        "print_freq = 100\n",
        "# Evaluation parameters\n",
        "eval_every = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b01740",
      "metadata": {
        "id": "e2b01740"
      },
      "source": [
        "### C4 Dataset Streaming and Preprocessing\n",
        "\n",
        "1. **Load the dataset**\n",
        "   - Streams the C4/en dataset:\n",
        "     ```python\n",
        "     data = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
        "     val_data = load_dataset(\"allenai/c4\", \"en\", split=\"validation\", streaming=True)\n",
        "     ```\n",
        "   - The data are streamed on-the-fly without downloading the full dataset on disk.\n",
        "\n",
        "2. **Preprocessing**\n",
        "   - `PreprocessedIterableDataset` tokenizes each text example using the GPT-2 tokenizer.\n",
        "   - Examples are truncated and padded to `max_length`.\n",
        "   - Tokenized examples are collected into batches of size `device_batch_size`.\n",
        "   - Finally, each batch is converted into a single tensor of input IDs:\n",
        "     ```python\n",
        "     input_ids = torch.stack([item[\"input_ids\"].squeeze(0) for item in batch])\n",
        "     ```\n",
        "\n",
        "3. **DataLoader**\n",
        "   - Using PyTorch `DataLoader`:\n",
        "     ```python\n",
        "     dataloader = torch.utils.data.DataLoader(dataset, batch_size=None, num_workers=workers)\n",
        "     ```\n",
        "   - Batching is done inside the dataset iterator `PreprocessedIterableDataset`, so here set `batch_size=None` as the dataloader does not need to do additional batching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "regional-jerusalem",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "ccb3142c6148411ca038b1ab24d149bc",
            "5ad3ccbaabb042639b5a9dea1b705dcb",
            "20f8ba60976a4da69b9f8ecdbbfee1d7",
            "9887782b6f2c409abfeae5594be766ca",
            "9132e199de5f4161829aa035d83ff25c",
            "fd3dfcb533f74fa78d6d295e992a8043",
            "ed784516b3fd49279412daa03bd17057",
            "8a4d82dc90a846ff9fc78af4bbcabcb7",
            "2ac93e37112a45eb8f25b855ea3f3f11",
            "67d4e82df8b34308bb0619b56bf509da",
            "7d7931a0b03c4d1bb5e141ba2b17a177",
            "4f98ed06f4df430d9b43a322345166b9",
            "05d2475126b245f58415913daadac6e4",
            "3e59e9fff8784e90bbc6d7395f50318c",
            "c1d8ca0f36e947feb2b67a7d1a5b4fe1",
            "9f65cae127454e76b6f07a1de0cd345d",
            "43fc20630c5f49d08294accfd2b3ed63",
            "7040424a42594d30a297f63f9018eb70",
            "f8ec16b8cfb04af2bfffa337643d06d6",
            "7283d05676fb47658a70bb53f5950c48",
            "cd5095556c634b0888e9c657ab96455f",
            "e7a2b9f885024bb588fc691837b63b54",
            "9a921fb569cb422aa8f8426abb7aaec2",
            "e8e4aae2a5404b108b89a9a20dc5c981",
            "71ecbfdb44674eaabb5f71bb16279834",
            "21c28abb0681465ab9babba2f33500d6",
            "bd4096919b7e4dc4aed8292e04b212e6",
            "9713c7f9b5684221b124330d6a8380bb",
            "40c7d1ac09754bafb7a49c0f84d86008",
            "a90729b4f86f4b8c87398feff4dc758f",
            "76db9a5dc7d048e0a8c0bac28d6840df",
            "41afe3bb0673490eb66b65d69cd7ddf5",
            "466c587a3272436885f4b725d69ef631",
            "c09bb648daca48b2a223ea788bf70c5b",
            "18504d4b21f2428d94ba9c82c9a9a5fd",
            "dd6fccd8e72e4c7baaa52492ceef2915",
            "c3e13d6e8b4d46ca8c2e93b344de3214",
            "29201687179f443ba5c9e20f70e5fa6f",
            "06cc5908329948559f8e8cdd5c9c0efe",
            "d2f8d68ca1d946338188047f76b00a3e",
            "ed7bf690fe964b9e8094522e8b93ab80",
            "87784bba62d0453f9eb68b3bf2414fec",
            "ce9cb516e3cf4e3e83202a9841205eec",
            "20ff0ad5c659495a9ede2e0d166cde5e",
            "4cb2454931e943d5b2c26754797409e4",
            "22f54e8bf37749ecac65acc58fce09f0",
            "ae80531f0e0f4d7099f0f2f969fb749f",
            "8db936b3803644e68739e96e3813fc81",
            "c83285f1f4de42cf8259bc4abd4c9550",
            "4ff6a75b90334d8eb7c16f343c4a4d1b",
            "86b387f390e84798adb088702906748f",
            "ca896404845947debedd701c8ab32aad",
            "26e936723f5e4c1ab7b1491594f582a2",
            "92e4902a9529457cb378934505ee167d",
            "acba8a786c294e0086941d56e39559e7"
          ]
        },
        "id": "regional-jerusalem",
        "outputId": "9d021de6-645f-4711-a2a4-2c6f0f95a35f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccb3142c6148411ca038b1ab24d149bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f98ed06f4df430d9b43a322345166b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a921fb569cb422aa8f8426abb7aaec2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c09bb648daca48b2a223ea788bf70c5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cb2454931e943d5b2c26754797409e4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = load_dataset(\n",
        "            \"allenai/c4\", \"en\", split=\"train\", streaming=True\n",
        "        )\n",
        "val_data = load_dataset(\n",
        "            \"allenai/c4\", \"en\", split=\"validation\", streaming=True\n",
        "        )\n",
        "\n",
        "class PreprocessedIterableDataset(IterableDataset):\n",
        "    def __init__(self, data, tokenizer, device_batch_size, max_length):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device_batch_size = device_batch_size\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __iter__(self):\n",
        "        iter_data = iter(self.data)\n",
        "\n",
        "        batch = []\n",
        "        for example in iter_data:\n",
        "            tokenized_example = self.tokenizer(\n",
        "                example[\"text\"],\n",
        "                max_length=self.max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "            batch.append(tokenized_example)\n",
        "\n",
        "            if len(batch) == self.device_batch_size:\n",
        "                yield self._format_batch(batch)\n",
        "                batch = []\n",
        "\n",
        "        if batch:\n",
        "            yield self._format_batch(batch)\n",
        "\n",
        "    def _format_batch(self, batch):\n",
        "        input_ids = torch.stack([item[\"input_ids\"].squeeze(0) for item in batch])\n",
        "        return input_ids\n",
        "\n",
        "# GPT-2 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "dataset = PreprocessedIterableDataset(\n",
        "                data, tokenizer, device_batch_size=device_batch_size, max_length=max_length\n",
        "            )\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=None, num_workers=workers,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f458b3",
      "metadata": {
        "id": "65f458b3"
      },
      "source": [
        "### Model parameters and loading\n",
        "\n",
        "Bellow we define nanoGPT using standard parameters. It will consist of 12 transformer layers, each having embedding dimension $d_{\\textrm{model}}=768$. It has a total of 123.55M trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "friendly-leonard",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "friendly-leonard",
        "outputId": "c77dcd01-bcc2-43a3-d83c-7ffb130a07ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 123.55M\n"
          ]
        }
      ],
      "source": [
        "# model parameters:\n",
        "n_layer = 12\n",
        "n_head = 12\n",
        "n_embd = 768\n",
        "dropout = 0.0\n",
        "bias = False\n",
        "block_size = 1024 # the maximum sequence length the model can handle\n",
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n",
        "                  bias=bias, vocab_size=vocab_size, dropout=dropout)\n",
        "\n",
        "gptconf = GPTConfig(**model_args)\n",
        "model = GPT(gptconf).to(device)\n",
        "\n",
        "model = torch.compile(model) # for faster training\n",
        "\n",
        "n_total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04abeb85",
      "metadata": {
        "id": "04abeb85"
      },
      "source": [
        "### Optimizer and LR scheduler\n",
        "\n",
        "Bellow we define the standard Adam optimizer class (code based on transformers.optimization library) and a learning rate scheduler that consists of a linear warmup and a cosine decay phase.\n",
        "\n",
        "Note that ee define the optimizer class here so it can serve as a foundation for creating other optimizer classes. Alternatively, you could use a predefined optimizer, for example:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(\n",
        "            params=trainable_params, lr=lr, weight_decay=weight_decay\n",
        "        )\n",
        "```\n",
        "\n",
        "We encourage experimenting with different optimizers and learning rate schedules. You can implement your own or try existing ones, for example from:  \n",
        "- https://docs.pytorch.org/docs/stable/optim.html\n",
        "- https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules#transformers.SchedulerType\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4ee4b074",
      "metadata": {
        "id": "4ee4b074"
      },
      "outputs": [],
      "source": [
        "class Adam(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Implements Adam algorithm with weight decay fix as introduced in [Decoupled Weight Decay\n",
        "    Regularization](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "    Parameters:\n",
        "        params (`Iterable[nn.parameter.Parameter]`):\n",
        "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
        "        lr (`float`, *optional*, defaults to 0.001):\n",
        "            The learning rate to use.\n",
        "        betas (`Tuple[float,float]`, *optional*, defaults to `(0.9, 0.999)`):\n",
        "            Adam's betas parameters (b1, b2).\n",
        "        eps (`float`, *optional*, defaults to 1e-06):\n",
        "            Adam's epsilon for numerical stability.\n",
        "        weight_decay (`float`, *optional*, defaults to 0.0):\n",
        "            Decoupled weight decay to apply.\n",
        "        correct_bias (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not to correct bias in Adam (for instance, in Bert TF repository they use `False`).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params: Iterable[nn.parameter.Parameter],\n",
        "        lr: float = 1e-3,\n",
        "        betas: Tuple[float, float] = (0.9, 0.999),\n",
        "        eps: float = 1e-6,\n",
        "        weight_decay: float = 0.0,\n",
        "        correct_bias: bool = True,\n",
        "    ):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr} - should be >= 0.0\")\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[0]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[1]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps} - should be >= 0.0\")\n",
        "        defaults = {\"lr\": lr, \"betas\": betas, \"eps\": eps, \"weight_decay\": weight_decay, \"correct_bias\": correct_bias}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure: Callable = None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (`Callable`, *optional*): A closure that reevaluates the model and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if \"step\" not in state:\n",
        "                    state[\"step\"] = 0\n",
        "\n",
        "                # State initialization\n",
        "                if \"exp_avg\" not in state:\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(grad)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(grad)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
        "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
        "\n",
        "                step_size = group[\"lr\"]\n",
        "\n",
        "                if group[\"correct_bias\"]:\n",
        "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
        "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
        "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # Adam update\n",
        "                u = exp_avg / denom\n",
        "\n",
        "                p.add_(u, alpha=-step_size)\n",
        "\n",
        "                if group[\"weight_decay\"] > 0.0:\n",
        "                    p.add_(p, alpha=(-group[\"lr\"] * group[\"weight_decay\"]))\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSProp(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    A simple implementation of RMSProp.\n",
        "\n",
        "    Keeps an exponential moving average of squared gradients and uses it\n",
        "    to normalize the current gradient.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, alpha=0.99, eps=1e-8, weight_decay=0.0):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
        "        if not 0.0 <= alpha < 1.0:\n",
        "            raise ValueError(f\"Invalid alpha value: {alpha}\")\n",
        "        if eps < 0.0:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps}\")\n",
        "\n",
        "        defaults = {\n",
        "            \"lr\": lr,\n",
        "            \"alpha\": alpha,   # decay for moving average of squared grads\n",
        "            \"eps\": eps,\n",
        "            \"weight_decay\": weight_decay,\n",
        "        }\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group[\"lr\"]\n",
        "            alpha = group[\"alpha\"]\n",
        "            eps = group[\"eps\"]\n",
        "            weight_decay = group[\"weight_decay\"]\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "\n",
        "                state = self.state[p]\n",
        "                if len(state) == 0:\n",
        "                    state[\"square_avg\"] = torch.zeros_like(p)\n",
        "\n",
        "                square_avg = state[\"square_avg\"]\n",
        "\n",
        "                # L2-style weight decay: g <- g + wd * p\n",
        "                if weight_decay != 0.0:\n",
        "                    grad = grad.add(p, alpha=weight_decay)\n",
        "\n",
        "\n",
        "                square_avg.mul_(alpha).addcmul_(grad, grad, value=1.0 - alpha)\n",
        "\n",
        "                # RMSProp update\n",
        "                denom = square_avg.sqrt().add_(eps)\n",
        "                p.addcdiv_(grad, denom, value=-lr)\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "k6rxTdNVGkMz"
      },
      "id": "k6rxTdNVGkMz",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SignSGD(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    A simple implementation of signSGD.\n",
        "\n",
        "    Parameter update: p <- p - lr * sign(grad)\n",
        "    Optionally with L2-style weight decay.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, weight_decay=0.0):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
        "        defaults = {\"lr\": lr, \"weight_decay\": weight_decay}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group[\"lr\"]\n",
        "            weight_decay = group[\"weight_decay\"]\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "\n",
        "                # L2-style weight decay\n",
        "                if weight_decay != 0.0:\n",
        "                    grad = grad.add(p, alpha=weight_decay)\n",
        "\n",
        "                # gradient\n",
        "                d_p = grad.sign()\n",
        "                p.add_(d_p, alpha=-lr)\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "AnG5euB3JV0X"
      },
      "id": "AnG5euB3JV0X",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_optimizer(name, params, lr, weight_decay):\n",
        "    name = name.lower()\n",
        "    if name == \"adam\":\n",
        "        return Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    elif name == \"rmsprop\":\n",
        "        return RMSProp(params, lr=lr, weight_decay=weight_decay)\n",
        "    elif name == \"signsgd\":\n",
        "        return SignSGD(params, lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer name: {name}\")\n"
      ],
      "metadata": {
        "id": "C6a9P03kJ_pI"
      },
      "id": "C6a9P03kJ_pI",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fresh-connectivity",
      "metadata": {
        "id": "fresh-connectivity"
      },
      "outputs": [],
      "source": [
        "# optimizer using our Adam class defined above\n",
        "optimizer = Adam(trainable_params, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# learning rate scheduler\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=num_training_steps,\n",
        "    last_epoch=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6611360",
      "metadata": {
        "id": "c6611360"
      },
      "source": [
        "### Main Training Code\n",
        "\n",
        "Before the training loop:\n",
        "\n",
        "- **Initialization**: Initialize `global_step`, `update_step`, and `tokens_seen`. Set up `gradient_accumulation` based on `total_batch_size` and `device_batch_size`. Note that `update_step` counts the actual number of updates performed, while `global_step = update_step * gradient_accumulation`.\n",
        "\n",
        "Inside the training loop:\n",
        "\n",
        "\n",
        "\n",
        "1. **Batch Processing**\n",
        "   - Load a batch from the `dataloader` and move it to the device.\n",
        "   - Prepare labels by shifting input tokens left (next-token prediction) and masking padding (`-100` for ignored positions):\n",
        "\n",
        "      ```python\n",
        "        input_ids = batch.to(device)\n",
        "        labels = input_ids.clone()\n",
        "        labels[:, :-1] = input_ids[:, 1:]   # shift left\n",
        "        labels[:, -1] = pad_idx             # pad the last token\n",
        "        labels[labels == pad_idx] = -100    # mask out padding\n",
        "        labels = labels.to(device)\n",
        "      ```\n",
        "\n",
        "2. **Forward and Backward Pass**:\n",
        "   - Compute logits and loss after passing the input and labels to the model (forward pass). Then scale the loss by `gradient_accumulation` and call `.backward()` for the backward pass.\n",
        "        ```python\n",
        "        logits, loss = model(input_ids, targets=labels)\n",
        "        scaled_loss = loss / gradient_accumulation\n",
        "        scaled_loss.backward()\n",
        "        ```\n",
        "   - Accumulate gradients over multiple mini-batches if needed:\n",
        "   \n",
        "        ```python\n",
        "        if global_step % gradient_accumulation != 0:\n",
        "            continue\n",
        "        ```\n",
        "     \n",
        "3. **Optimizer Step**:\n",
        "   - Apply gradient clipping if configured.\n",
        "   - Update model parameters with `optimizer.step()` and learning rate scheduler `scheduler.step()`.\n",
        "   - Reset gradients with `optimizer.zero_grad()`.\n",
        "   - Increment `update_step`.\n",
        "\n",
        "      ```python\n",
        "      if grad_clipping != 0.0:\n",
        "          torch.nn.utils.clip_grad_norm_(trainable_params, grad_clipping)\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "          \n",
        "      update_step += 1\n",
        "      ```\n",
        "\n",
        "4. **Logging**: Print progress every `print_freq` updates.  \n",
        "\n",
        "5. **Termination**: Stop training when `num_training_steps` is reached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c509366a",
      "metadata": {
        "id": "c509366a"
      },
      "outputs": [],
      "source": [
        "# Evaluation code\n",
        "\n",
        "def collate_fn(batch_list):\n",
        "    batch =  torch.stack([torch.Tensor(example[\"input_ids\"]).long() for example in batch_list])\n",
        "    return batch\n",
        "\n",
        "def batch_fn(dataset, batch_size):\n",
        "    batch = []\n",
        "    for example in dataset:\n",
        "        batch.append(example)\n",
        "        if len(batch) == batch_size:\n",
        "            batch = collate_fn(batch)\n",
        "            yield batch\n",
        "            batch = []\n",
        "    if len(batch) > 0:\n",
        "        yield batch\n",
        "\n",
        "def preprocess_batched(batch):\n",
        "    batch = tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return batch\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(\n",
        "    model, val_data, preprocess_batched, pad_idx, device, batch_size\n",
        "):\n",
        "\n",
        "    val_data = val_data.shuffle(seed=42)\n",
        "\n",
        "    val_data_mapped = val_data.map(\n",
        "        preprocess_batched,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\", \"timestamp\", \"url\"],\n",
        "    )\n",
        "    val_data_mapped.batch = lambda batch_size: batch_fn(\n",
        "        val_data_mapped, batch_size\n",
        "    )\n",
        "\n",
        "    target_eval_tokens = 1_000_000 #10_000_000\n",
        "    evaluated_on_tokens = 0\n",
        "    total_loss = torch.tensor(0.0).to(device)\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch in val_data_mapped.batch(batch_size=batch_size):\n",
        "        if evaluated_on_tokens > target_eval_tokens:\n",
        "            break\n",
        "        total_batches += 1\n",
        "\n",
        "        input_ids = batch.to(device)\n",
        "        labels = input_ids.clone()\n",
        "        labels[:, :-1] = input_ids[:, 1:]   # shift left\n",
        "        labels[:, -1] = pad_idx             # pad the last token\n",
        "        labels[labels == pad_idx] = -100    # mask out padding\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        _, loss = model(input_ids, targets=labels)\n",
        "        total_loss += loss.detach()\n",
        "\n",
        "        evaluated_on_tokens += (batch != pad_idx).sum().item()\n",
        "\n",
        "    total_loss = total_loss / total_batches\n",
        "\n",
        "    return total_loss, evaluated_on_tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad_idx = tokenizer.pad_token_id\n",
        "\n",
        "world_size = 1  # The number of GPUs we will use, here is set to 1 as multi-GPU training is not implemented.\n",
        "\n",
        "gradient_accumulation = None\n",
        "\n",
        "if total_batch_size is not None:\n",
        "    if gradient_accumulation is None:\n",
        "        assert (\n",
        "            total_batch_size % world_size == 0\n",
        "        ), \"total_batch_size must be divisible by world_size\"\n",
        "        gradient_accumulation = total_batch_size // (\n",
        "            device_batch_size * world_size\n",
        "        )\n",
        "        assert (\n",
        "            gradient_accumulation > 0\n",
        "        ), \"gradient_accumulation must be greater than 0\"\n",
        "\n",
        "assert (\n",
        "    gradient_accumulation * device_batch_size * world_size\n",
        "    == total_batch_size\n",
        "), \"gradient_accumulation * device_batch_size * world_size must be equal to total_batch_size\"\n"
      ],
      "metadata": {
        "id": "RJMiZHtLOEAg"
      },
      "id": "RJMiZHtLOEAg",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(optimizer_name, lr, weight_decay, num_training_steps, seed=42):\n",
        "    import random\n",
        "\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    gptconf = GPTConfig(**model_args)\n",
        "    model = GPT(gptconf).to(device)\n",
        "    model = torch.compile(model)\n",
        "\n",
        "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "\n",
        "    optimizer = create_optimizer(\n",
        "        optimizer_name,\n",
        "        trainable_params,\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "    )\n",
        "\n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=num_training_steps,\n",
        "        last_epoch=-1,\n",
        "    )\n",
        "\n",
        "    global_step = 0  # = update_step * gradient_accumulation\n",
        "    update_step = 0\n",
        "    tokens_seen = 0  # = global_step / gradient_accumulation\n",
        "    tokens_seen_before = 0\n",
        "\n",
        "    losses = []\n",
        "    eval_losses = []\n",
        "\n",
        "    # ========== 4. training loop ==========\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        if batch_idx == 0:\n",
        "            tokens_seen_before = tokens_seen\n",
        "        if update_step >= num_training_steps:\n",
        "            print(\n",
        "                f\"[{optimizer_name} | lr={lr}] Reached max number of update steps ({num_training_steps}). Stopping training.\"\n",
        "            )\n",
        "            break\n",
        "\n",
        "        global_step += 1\n",
        "\n",
        "        input_ids = batch.to(device)\n",
        "        labels = input_ids.clone()\n",
        "        labels[:, :-1] = input_ids[:, 1:]   # shift left\n",
        "        labels[:, -1] = pad_idx             # pad the last token\n",
        "        labels[labels == pad_idx] = -100    # mask out padding\n",
        "        labels = labels.to(device)\n",
        "        tokens_seen += (input_ids != pad_idx).sum().item()\n",
        "\n",
        "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):  # Automatic mixed precision\n",
        "            logits, loss = model(input_ids, targets=labels)\n",
        "            scaled_loss = loss / gradient_accumulation\n",
        "\n",
        "        scaled_loss.backward()\n",
        "\n",
        "\n",
        "        if global_step % gradient_accumulation != 0:\n",
        "            continue\n",
        "\n",
        "        losses.append((loss.item(), update_step))\n",
        "\n",
        "        if update_step % print_freq == 0:\n",
        "            print(\n",
        "                f\"[{optimizer_name} | lr={lr}] \"\n",
        "                f\"Update step: {update_step}/{num_training_steps} | loss: {loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "\n",
        "        if grad_clipping != 0.0:\n",
        "            torch.nn.utils.clip_grad_norm_(trainable_params, grad_clipping)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        update_step += 1\n",
        "\n",
        "        if eval_every > 0 and ((update_step % eval_every == 0) or (update_step == num_training_steps)):\n",
        "            total_loss, evaluated_on_tokens = evaluate_model(\n",
        "                model, val_data, preprocess_batched, pad_idx, device, device_batch_size,\n",
        "            )\n",
        "\n",
        "            total_loss_val = total_loss.detach().cpu().item()\n",
        "            eval_losses.append((total_loss_val, update_step))\n",
        "\n",
        "            print(\n",
        "                f\"[Eval Step {update_step} | {optimizer_name} | lr={lr}] \"\n",
        "                f\"Loss: {total_loss_val:.4f}, PPL: {np.exp(total_loss_val):.2f}, \"\n",
        "                f\"Eval tokens {evaluated_on_tokens}\"\n",
        "            )\n",
        "\n",
        "    print(f\"Training finished for optimizer={optimizer_name}, lr={lr}\")\n",
        "    return model, losses, eval_losses\n"
      ],
      "metadata": {
        "id": "mq6Pb7S8OFPH"
      },
      "id": "mq6Pb7S8OFPH",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training test\n",
        "model_test, losses_test, eval_losses_test = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=100,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vha94swJONQ2",
        "outputId": "548a2137-f8e1-4100-cb14-93e7399f8d6b"
      },
      "id": "Vha94swJONQ2",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 123.55M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[adam | lr=0.001] Update step: 0/100 | loss: 10.9855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py:312: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval Step 100 | adam | lr=0.001] Loss: 7.3908, PPL: 1621.08, Eval tokens 1002149\n",
            "[adam | lr=0.001] Reached max number of update steps (100). Stopping training.\n",
            "Training finished for optimizer=adam, lr=0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_config = {\n",
        "    \"adam\":    [1e-4, 3e-4, 1e-3],\n",
        "    \"rmsprop\": [3e-4, 1e-3, 3e-3],\n",
        "    \"signsgd\": [1e-4, 3e-4, 1e-3],\n",
        "}\n"
      ],
      "metadata": {
        "id": "lvhrzkKlO3UE"
      },
      "id": "lvhrzkKlO3UE",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Adam ----\n",
        "model_a1, losses_a1, eval_a1 = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_a2, losses_a2, eval_a2 = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_a3, losses_a3, eval_a3 = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf_6mzfgPg6O",
        "outputId": "c2a12c76-274c-4eab-ac41-3f14ef7eb7fa"
      },
      "id": "Gf_6mzfgPg6O",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 123.55M\n",
            "[adam | lr=0.0001] Update step: 0/5000 | loss: 10.9855\n",
            "[adam | lr=0.0001] Update step: 100/5000 | loss: 9.2167\n",
            "[adam | lr=0.0001] Update step: 200/5000 | loss: 8.0705\n",
            "[adam | lr=0.0001] Update step: 300/5000 | loss: 7.4215\n",
            "[adam | lr=0.0001] Update step: 400/5000 | loss: 6.9483\n",
            "[adam | lr=0.0001] Update step: 500/5000 | loss: 6.7479\n",
            "[adam | lr=0.0001] Update step: 600/5000 | loss: 6.4176\n",
            "[adam | lr=0.0001] Update step: 700/5000 | loss: 6.2606\n",
            "[adam | lr=0.0001] Update step: 800/5000 | loss: 5.9692\n",
            "[adam | lr=0.0001] Update step: 900/5000 | loss: 6.0153\n",
            "[Eval Step 1000 | adam | lr=0.0001] Loss: 5.7858, PPL: 325.65, Eval tokens 1002149\n",
            "[adam | lr=0.0001] Update step: 1000/5000 | loss: 5.7484\n",
            "[adam | lr=0.0001] Update step: 1100/5000 | loss: 5.5989\n",
            "[adam | lr=0.0001] Update step: 1200/5000 | loss: 5.5794\n",
            "[adam | lr=0.0001] Update step: 1300/5000 | loss: 5.4867\n",
            "[adam | lr=0.0001] Update step: 1400/5000 | loss: 5.4640\n",
            "[adam | lr=0.0001] Update step: 1500/5000 | loss: 5.2411\n",
            "[adam | lr=0.0001] Update step: 1600/5000 | loss: 5.2180\n",
            "[adam | lr=0.0001] Update step: 1700/5000 | loss: 5.0496\n",
            "[adam | lr=0.0001] Update step: 1800/5000 | loss: 4.8353\n",
            "[adam | lr=0.0001] Update step: 1900/5000 | loss: 4.8834\n",
            "[Eval Step 2000 | adam | lr=0.0001] Loss: 4.8914, PPL: 133.14, Eval tokens 1002149\n",
            "[adam | lr=0.0001] Update step: 2000/5000 | loss: 5.0043\n",
            "[adam | lr=0.0001] Update step: 2100/5000 | loss: 4.7553\n",
            "[adam | lr=0.0001] Update step: 2200/5000 | loss: 4.7046\n",
            "[adam | lr=0.0001] Update step: 2300/5000 | loss: 4.9192\n",
            "[adam | lr=0.0001] Update step: 2400/5000 | loss: 4.8389\n",
            "[adam | lr=0.0001] Update step: 2500/5000 | loss: 4.7159\n",
            "[adam | lr=0.0001] Update step: 2600/5000 | loss: 4.4483\n",
            "[adam | lr=0.0001] Update step: 2700/5000 | loss: 4.6304\n",
            "[adam | lr=0.0001] Update step: 2800/5000 | loss: 4.6336\n",
            "[adam | lr=0.0001] Update step: 2900/5000 | loss: 4.3071\n",
            "[Eval Step 3000 | adam | lr=0.0001] Loss: 4.5400, PPL: 93.69, Eval tokens 1002149\n",
            "[adam | lr=0.0001] Update step: 3000/5000 | loss: 4.5253\n",
            "[adam | lr=0.0001] Update step: 3100/5000 | loss: 4.5699\n",
            "[adam | lr=0.0001] Update step: 3200/5000 | loss: 4.4810\n",
            "[adam | lr=0.0001] Update step: 3300/5000 | loss: 4.4620\n",
            "[adam | lr=0.0001] Update step: 3400/5000 | loss: 4.6002\n",
            "[adam | lr=0.0001] Update step: 3500/5000 | loss: 4.4371\n",
            "[adam | lr=0.0001] Update step: 3600/5000 | loss: 4.3811\n",
            "[adam | lr=0.0001] Update step: 3700/5000 | loss: 4.5080\n",
            "[adam | lr=0.0001] Update step: 3800/5000 | loss: 4.5688\n",
            "[adam | lr=0.0001] Update step: 3900/5000 | loss: 4.3241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 0bd8609b-bd6d-49b9-94f0-3ba5de42e2ab)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 0bd8609b-bd6d-49b9-94f0-3ba5de42e2ab)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval Step 4000 | adam | lr=0.0001] Loss: 4.3943, PPL: 80.99, Eval tokens 1002149\n",
            "[adam | lr=0.0001] Update step: 4000/5000 | loss: 4.5387\n",
            "[adam | lr=0.0001] Update step: 4100/5000 | loss: 4.2573\n",
            "[adam | lr=0.0001] Update step: 4200/5000 | loss: 4.4330\n",
            "[adam | lr=0.0001] Update step: 4300/5000 | loss: 4.4958\n",
            "[adam | lr=0.0001] Update step: 4400/5000 | loss: 4.3268\n",
            "[adam | lr=0.0001] Update step: 4500/5000 | loss: 4.4665\n",
            "[adam | lr=0.0001] Update step: 4600/5000 | loss: 4.3977\n",
            "[adam | lr=0.0001] Update step: 4700/5000 | loss: 4.3826\n",
            "[adam | lr=0.0001] Update step: 4800/5000 | loss: 4.3752\n",
            "[adam | lr=0.0001] Update step: 4900/5000 | loss: 4.2561\n",
            "[Eval Step 5000 | adam | lr=0.0001] Loss: 4.3576, PPL: 78.07, Eval tokens 1002149\n",
            "[adam | lr=0.0001] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=adam, lr=0.0001\n",
            "number of parameters: 123.55M\n",
            "[adam | lr=0.0003] Update step: 0/5000 | loss: 10.9855\n",
            "[adam | lr=0.0003] Update step: 100/5000 | loss: 8.5155\n",
            "[adam | lr=0.0003] Update step: 200/5000 | loss: 7.1428\n",
            "[adam | lr=0.0003] Update step: 300/5000 | loss: 6.8249\n",
            "[adam | lr=0.0003] Update step: 400/5000 | loss: 6.3958\n",
            "[adam | lr=0.0003] Update step: 500/5000 | loss: 6.1973\n",
            "[adam | lr=0.0003] Update step: 600/5000 | loss: 5.8506\n",
            "[adam | lr=0.0003] Update step: 700/5000 | loss: 5.6842\n",
            "[adam | lr=0.0003] Update step: 800/5000 | loss: 5.4143\n",
            "[adam | lr=0.0003] Update step: 900/5000 | loss: 5.4472\n",
            "[Eval Step 1000 | adam | lr=0.0003] Loss: 5.2085, PPL: 182.82, Eval tokens 1002149\n",
            "[adam | lr=0.0003] Update step: 1000/5000 | loss: 5.1263\n",
            "[adam | lr=0.0003] Update step: 1100/5000 | loss: 5.0015\n",
            "[adam | lr=0.0003] Update step: 1200/5000 | loss: 4.8873\n",
            "[adam | lr=0.0003] Update step: 1300/5000 | loss: 4.8544\n",
            "[adam | lr=0.0003] Update step: 1400/5000 | loss: 4.8105\n",
            "[adam | lr=0.0003] Update step: 1500/5000 | loss: 4.6595\n",
            "[adam | lr=0.0003] Update step: 1600/5000 | loss: 4.5978\n",
            "[adam | lr=0.0003] Update step: 1700/5000 | loss: 4.4869\n",
            "[adam | lr=0.0003] Update step: 1800/5000 | loss: 4.3334\n",
            "[adam | lr=0.0003] Update step: 1900/5000 | loss: 4.3609\n",
            "[Eval Step 2000 | adam | lr=0.0003] Loss: 4.3956, PPL: 81.09, Eval tokens 1002149\n",
            "[adam | lr=0.0003] Update step: 2000/5000 | loss: 4.5166\n",
            "[adam | lr=0.0003] Update step: 2100/5000 | loss: 4.2535\n",
            "[adam | lr=0.0003] Update step: 2200/5000 | loss: 4.2195\n",
            "[adam | lr=0.0003] Update step: 2300/5000 | loss: 4.4738\n",
            "[adam | lr=0.0003] Update step: 2400/5000 | loss: 4.4274\n",
            "[adam | lr=0.0003] Update step: 2500/5000 | loss: 4.3027\n",
            "[adam | lr=0.0003] Update step: 2600/5000 | loss: 4.0147\n",
            "[adam | lr=0.0003] Update step: 2700/5000 | loss: 4.2118\n",
            "[adam | lr=0.0003] Update step: 2800/5000 | loss: 4.1921\n",
            "[adam | lr=0.0003] Update step: 2900/5000 | loss: 3.8584\n",
            "[Eval Step 3000 | adam | lr=0.0003] Loss: 4.1388, PPL: 62.72, Eval tokens 1002149\n",
            "[adam | lr=0.0003] Update step: 3000/5000 | loss: 4.1156\n",
            "[adam | lr=0.0003] Update step: 3100/5000 | loss: 4.1883\n",
            "[adam | lr=0.0003] Update step: 3200/5000 | loss: 4.0708\n",
            "[adam | lr=0.0003] Update step: 3300/5000 | loss: 4.0461\n",
            "[adam | lr=0.0003] Update step: 3400/5000 | loss: 4.2043\n",
            "[adam | lr=0.0003] Update step: 3500/5000 | loss: 4.0517\n",
            "[adam | lr=0.0003] Update step: 3600/5000 | loss: 4.0065\n",
            "[adam | lr=0.0003] Update step: 3700/5000 | loss: 4.0879\n",
            "[adam | lr=0.0003] Update step: 3800/5000 | loss: 4.1973\n",
            "[adam | lr=0.0003] Update step: 3900/5000 | loss: 3.9453\n",
            "[Eval Step 4000 | adam | lr=0.0003] Loss: 4.0018, PPL: 54.70, Eval tokens 1002149\n",
            "[adam | lr=0.0003] Update step: 4000/5000 | loss: 4.1529\n",
            "[adam | lr=0.0003] Update step: 4100/5000 | loss: 3.8728\n",
            "[adam | lr=0.0003] Update step: 4200/5000 | loss: 4.0551\n",
            "[adam | lr=0.0003] Update step: 4300/5000 | loss: 4.1018\n",
            "[adam | lr=0.0003] Update step: 4400/5000 | loss: 3.9129\n",
            "[adam | lr=0.0003] Update step: 4500/5000 | loss: 4.0952\n",
            "[adam | lr=0.0003] Update step: 4600/5000 | loss: 3.9783\n",
            "[adam | lr=0.0003] Update step: 4700/5000 | loss: 3.9880\n",
            "[adam | lr=0.0003] Update step: 4800/5000 | loss: 3.9885\n",
            "[adam | lr=0.0003] Update step: 4900/5000 | loss: 3.8327\n",
            "[Eval Step 5000 | adam | lr=0.0003] Loss: 3.9600, PPL: 52.46, Eval tokens 1002149\n",
            "[adam | lr=0.0003] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=adam, lr=0.0003\n",
            "number of parameters: 123.55M\n",
            "[adam | lr=0.001] Update step: 0/5000 | loss: 10.9855\n",
            "[adam | lr=0.001] Update step: 100/5000 | loss: 7.4935\n",
            "[adam | lr=0.001] Update step: 200/5000 | loss: 6.5678\n",
            "[adam | lr=0.001] Update step: 300/5000 | loss: 6.2840\n",
            "[adam | lr=0.001] Update step: 400/5000 | loss: 5.8675\n",
            "[adam | lr=0.001] Update step: 500/5000 | loss: 5.6725\n",
            "[adam | lr=0.001] Update step: 600/5000 | loss: 5.3327\n",
            "[adam | lr=0.001] Update step: 700/5000 | loss: 5.1426\n",
            "[adam | lr=0.001] Update step: 800/5000 | loss: 4.9384\n",
            "[adam | lr=0.001] Update step: 900/5000 | loss: 4.8581\n",
            "[Eval Step 1000 | adam | lr=0.001] Loss: 4.7175, PPL: 111.89, Eval tokens 1002149\n",
            "[adam | lr=0.001] Update step: 1000/5000 | loss: 4.5807\n",
            "[adam | lr=0.001] Update step: 1100/5000 | loss: 4.5925\n",
            "[adam | lr=0.001] Update step: 1200/5000 | loss: 4.4972\n",
            "[adam | lr=0.001] Update step: 1300/5000 | loss: 4.5382\n",
            "[adam | lr=0.001] Update step: 1400/5000 | loss: 4.4824\n",
            "[adam | lr=0.001] Update step: 1500/5000 | loss: 4.4206\n",
            "[adam | lr=0.001] Update step: 1600/5000 | loss: 4.3471\n",
            "[adam | lr=0.001] Update step: 1700/5000 | loss: 4.2754\n",
            "[adam | lr=0.001] Update step: 1800/5000 | loss: 4.1569\n",
            "[adam | lr=0.001] Update step: 1900/5000 | loss: 4.1696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: bfe8e4ee-bb40-4acd-85a4-321ee41a0e4c)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: bfe8e4ee-bb40-4acd-85a4-321ee41a0e4c)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval Step 2000 | adam | lr=0.001] Loss: 4.2080, PPL: 67.22, Eval tokens 1002149\n",
            "[adam | lr=0.001] Update step: 2000/5000 | loss: 4.3406\n",
            "[adam | lr=0.001] Update step: 2100/5000 | loss: 4.0651\n",
            "[adam | lr=0.001] Update step: 2200/5000 | loss: 4.0481\n",
            "[adam | lr=0.001] Update step: 2300/5000 | loss: 4.3044\n",
            "[adam | lr=0.001] Update step: 2400/5000 | loss: 4.2648\n",
            "[adam | lr=0.001] Update step: 2500/5000 | loss: 4.1287\n",
            "[adam | lr=0.001] Update step: 2600/5000 | loss: 3.8529\n",
            "[adam | lr=0.001] Update step: 2700/5000 | loss: 4.0591\n",
            "[adam | lr=0.001] Update step: 2800/5000 | loss: 4.0072\n",
            "[adam | lr=0.001] Update step: 2900/5000 | loss: 3.7076\n",
            "[Eval Step 3000 | adam | lr=0.001] Loss: 3.9789, PPL: 53.46, Eval tokens 1002149\n",
            "[adam | lr=0.001] Update step: 3000/5000 | loss: 3.9500\n",
            "[adam | lr=0.001] Update step: 3100/5000 | loss: 4.0488\n",
            "[adam | lr=0.001] Update step: 3200/5000 | loss: 3.9050\n",
            "[adam | lr=0.001] Update step: 3300/5000 | loss: 3.8636\n",
            "[adam | lr=0.001] Update step: 3400/5000 | loss: 4.0436\n",
            "[adam | lr=0.001] Update step: 3500/5000 | loss: 3.8836\n",
            "[adam | lr=0.001] Update step: 3600/5000 | loss: 3.8406\n",
            "[adam | lr=0.001] Update step: 3700/5000 | loss: 3.9109\n",
            "[adam | lr=0.001] Update step: 3800/5000 | loss: 4.0240\n",
            "[adam | lr=0.001] Update step: 3900/5000 | loss: 3.7877\n",
            "[Eval Step 4000 | adam | lr=0.001] Loss: 3.8255, PPL: 45.86, Eval tokens 1002149\n",
            "[adam | lr=0.001] Update step: 4000/5000 | loss: 3.9807\n",
            "[adam | lr=0.001] Update step: 4100/5000 | loss: 3.7025\n",
            "[adam | lr=0.001] Update step: 4200/5000 | loss: 3.8962\n",
            "[adam | lr=0.001] Update step: 4300/5000 | loss: 3.9086\n",
            "[adam | lr=0.001] Update step: 4400/5000 | loss: 3.7179\n",
            "[adam | lr=0.001] Update step: 4500/5000 | loss: 3.9182\n",
            "[adam | lr=0.001] Update step: 4600/5000 | loss: 3.7866\n",
            "[adam | lr=0.001] Update step: 4700/5000 | loss: 3.8002\n",
            "[adam | lr=0.001] Update step: 4800/5000 | loss: 3.8043\n",
            "[adam | lr=0.001] Update step: 4900/5000 | loss: 3.6471\n",
            "[Eval Step 5000 | adam | lr=0.001] Loss: 3.7729, PPL: 43.51, Eval tokens 1002149\n",
            "[adam | lr=0.001] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=adam, lr=0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_r1, losses_r1, eval_r1 = run_experiment(\n",
        "    optimizer_name=\"rmsprop\",\n",
        "    lr=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_r2, losses_r2, eval_r2 = run_experiment(\n",
        "    optimizer_name=\"rmsprop\",\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_r3, losses_r3, eval_r3 = run_experiment(\n",
        "    optimizer_name=\"rmsprop\",\n",
        "    lr=3e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWdpqNGxlyTq",
        "outputId": "32503553-a051-40cc-915b-62c082a13790"
      },
      "id": "ZWdpqNGxlyTq",
      "execution_count": 27,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 123.55M\n",
            "[rmsprop | lr=0.0003] Update step: 0/5000 | loss: 10.9855\n",
            "[rmsprop | lr=0.0003] Update step: 100/5000 | loss: 8.0746\n",
            "[rmsprop | lr=0.0003] Update step: 200/5000 | loss: 7.1383\n",
            "[rmsprop | lr=0.0003] Update step: 300/5000 | loss: 6.9146\n",
            "[rmsprop | lr=0.0003] Update step: 400/5000 | loss: 6.6874\n",
            "[rmsprop | lr=0.0003] Update step: 500/5000 | loss: 6.5482\n",
            "[rmsprop | lr=0.0003] Update step: 600/5000 | loss: 6.3016\n",
            "[rmsprop | lr=0.0003] Update step: 700/5000 | loss: 6.2040\n",
            "[rmsprop | lr=0.0003] Update step: 800/5000 | loss: 6.0670\n",
            "[rmsprop | lr=0.0003] Update step: 900/5000 | loss: 6.0844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 90252cf3-f62f-4ccd-b217-969f98747ad9)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 90252cf3-f62f-4ccd-b217-969f98747ad9)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Eval Step 1000 | rmsprop | lr=0.0003] Loss: 6.1669, PPL: 476.68, Eval tokens 1002149\n",
            "[rmsprop | lr=0.0003] Update step: 1000/5000 | loss: 6.1297\n",
            "[rmsprop | lr=0.0003] Update step: 1100/5000 | loss: 5.7584\n",
            "[rmsprop | lr=0.0003] Update step: 1200/5000 | loss: 5.6661\n",
            "[rmsprop | lr=0.0003] Update step: 1300/5000 | loss: 5.6000\n",
            "[rmsprop | lr=0.0003] Update step: 1400/5000 | loss: 5.5663\n",
            "[rmsprop | lr=0.0003] Update step: 1500/5000 | loss: 5.3518\n",
            "[rmsprop | lr=0.0003] Update step: 1600/5000 | loss: 5.3501\n",
            "[rmsprop | lr=0.0003] Update step: 1700/5000 | loss: 5.1947\n",
            "[rmsprop | lr=0.0003] Update step: 1800/5000 | loss: 4.9531\n",
            "[rmsprop | lr=0.0003] Update step: 1900/5000 | loss: 4.9603\n",
            "[Eval Step 2000 | rmsprop | lr=0.0003] Loss: 4.9717, PPL: 144.27, Eval tokens 1002149\n",
            "[rmsprop | lr=0.0003] Update step: 2000/5000 | loss: 5.0982\n",
            "[rmsprop | lr=0.0003] Update step: 2100/5000 | loss: 4.8143\n",
            "[rmsprop | lr=0.0003] Update step: 2200/5000 | loss: 4.7146\n",
            "[rmsprop | lr=0.0003] Update step: 2300/5000 | loss: 4.9438\n",
            "[rmsprop | lr=0.0003] Update step: 2400/5000 | loss: 4.8053\n",
            "[rmsprop | lr=0.0003] Update step: 2500/5000 | loss: 4.6503\n",
            "[rmsprop | lr=0.0003] Update step: 2600/5000 | loss: 4.3877\n",
            "[rmsprop | lr=0.0003] Update step: 2700/5000 | loss: 4.5216\n",
            "[rmsprop | lr=0.0003] Update step: 2800/5000 | loss: 4.4971\n",
            "[rmsprop | lr=0.0003] Update step: 2900/5000 | loss: 4.1681\n",
            "[Eval Step 3000 | rmsprop | lr=0.0003] Loss: 4.4020, PPL: 81.61, Eval tokens 1002149\n",
            "[rmsprop | lr=0.0003] Update step: 3000/5000 | loss: 4.3732\n",
            "[rmsprop | lr=0.0003] Update step: 3100/5000 | loss: 4.4411\n",
            "[rmsprop | lr=0.0003] Update step: 3200/5000 | loss: 4.3126\n",
            "[rmsprop | lr=0.0003] Update step: 3300/5000 | loss: 4.2947\n",
            "[rmsprop | lr=0.0003] Update step: 3400/5000 | loss: 4.4284\n",
            "[rmsprop | lr=0.0003] Update step: 3500/5000 | loss: 4.2572\n",
            "[rmsprop | lr=0.0003] Update step: 3600/5000 | loss: 4.2127\n",
            "[rmsprop | lr=0.0003] Update step: 3700/5000 | loss: 4.3058\n",
            "[rmsprop | lr=0.0003] Update step: 3800/5000 | loss: 4.3853\n",
            "[rmsprop | lr=0.0003] Update step: 3900/5000 | loss: 4.1292\n",
            "[Eval Step 4000 | rmsprop | lr=0.0003] Loss: 4.1977, PPL: 66.54, Eval tokens 1002149\n",
            "[rmsprop | lr=0.0003] Update step: 4000/5000 | loss: 4.3502\n",
            "[rmsprop | lr=0.0003] Update step: 4100/5000 | loss: 4.0621\n",
            "[rmsprop | lr=0.0003] Update step: 4200/5000 | loss: 4.2405\n",
            "[rmsprop | lr=0.0003] Update step: 4300/5000 | loss: 4.2987\n",
            "[rmsprop | lr=0.0003] Update step: 4400/5000 | loss: 4.1174\n",
            "[rmsprop | lr=0.0003] Update step: 4500/5000 | loss: 4.2857\n",
            "[rmsprop | lr=0.0003] Update step: 4600/5000 | loss: 4.1818\n",
            "[rmsprop | lr=0.0003] Update step: 4700/5000 | loss: 4.1776\n",
            "[rmsprop | lr=0.0003] Update step: 4800/5000 | loss: 4.1900\n",
            "[rmsprop | lr=0.0003] Update step: 4900/5000 | loss: 4.0359\n",
            "[Eval Step 5000 | rmsprop | lr=0.0003] Loss: 4.1548, PPL: 63.74, Eval tokens 1002149\n",
            "[rmsprop | lr=0.0003] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=rmsprop, lr=0.0003\n",
            "number of parameters: 123.55M\n",
            "[rmsprop | lr=0.001] Update step: 0/5000 | loss: 10.9855\n",
            "[rmsprop | lr=0.001] Update step: 100/5000 | loss: 7.7638\n",
            "[rmsprop | lr=0.001] Update step: 200/5000 | loss: 7.0931\n",
            "[rmsprop | lr=0.001] Update step: 300/5000 | loss: 6.8580\n",
            "[rmsprop | lr=0.001] Update step: 400/5000 | loss: 6.6248\n",
            "[rmsprop | lr=0.001] Update step: 500/5000 | loss: 7.3934\n",
            "[rmsprop | lr=0.001] Update step: 600/5000 | loss: 6.2188\n",
            "[rmsprop | lr=0.001] Update step: 700/5000 | loss: 6.1612\n",
            "[rmsprop | lr=0.001] Update step: 800/5000 | loss: 6.0003\n",
            "[rmsprop | lr=0.001] Update step: 900/5000 | loss: 6.0671\n",
            "[Eval Step 1000 | rmsprop | lr=0.001] Loss: 5.9600, PPL: 387.60, Eval tokens 1002149\n",
            "[rmsprop | lr=0.001] Update step: 1000/5000 | loss: 5.9236\n",
            "[rmsprop | lr=0.001] Update step: 1100/5000 | loss: 5.8042\n",
            "[rmsprop | lr=0.001] Update step: 1200/5000 | loss: 5.7378\n",
            "[rmsprop | lr=0.001] Update step: 1300/5000 | loss: 5.6099\n",
            "[rmsprop | lr=0.001] Update step: 1400/5000 | loss: 5.6758\n",
            "[rmsprop | lr=0.001] Update step: 1500/5000 | loss: 5.3266\n",
            "[rmsprop | lr=0.001] Update step: 1600/5000 | loss: 5.3287\n",
            "[rmsprop | lr=0.001] Update step: 1700/5000 | loss: 5.1473\n",
            "[rmsprop | lr=0.001] Update step: 1800/5000 | loss: 5.0178\n",
            "[rmsprop | lr=0.001] Update step: 1900/5000 | loss: 4.9764\n",
            "[Eval Step 2000 | rmsprop | lr=0.001] Loss: 5.0164, PPL: 150.86, Eval tokens 1002149\n",
            "[rmsprop | lr=0.001] Update step: 2000/5000 | loss: 5.1378\n",
            "[rmsprop | lr=0.001] Update step: 2100/5000 | loss: 4.8724\n",
            "[rmsprop | lr=0.001] Update step: 2200/5000 | loss: 4.7965\n",
            "[rmsprop | lr=0.001] Update step: 2300/5000 | loss: 4.9957\n",
            "[rmsprop | lr=0.001] Update step: 2400/5000 | loss: 4.8224\n",
            "[rmsprop | lr=0.001] Update step: 2500/5000 | loss: 4.6656\n",
            "[rmsprop | lr=0.001] Update step: 2600/5000 | loss: 4.3769\n",
            "[rmsprop | lr=0.001] Update step: 2700/5000 | loss: 4.5028\n",
            "[rmsprop | lr=0.001] Update step: 2800/5000 | loss: 4.4816\n",
            "[rmsprop | lr=0.001] Update step: 2900/5000 | loss: 4.1434\n",
            "[Eval Step 3000 | rmsprop | lr=0.001] Loss: 4.3628, PPL: 78.48, Eval tokens 1002149\n",
            "[rmsprop | lr=0.001] Update step: 3000/5000 | loss: 4.3312\n",
            "[rmsprop | lr=0.001] Update step: 3100/5000 | loss: 4.3859\n",
            "[rmsprop | lr=0.001] Update step: 3200/5000 | loss: 4.2604\n",
            "[rmsprop | lr=0.001] Update step: 3300/5000 | loss: 4.2176\n",
            "[rmsprop | lr=0.001] Update step: 3400/5000 | loss: 4.3479\n",
            "[rmsprop | lr=0.001] Update step: 3500/5000 | loss: 4.1863\n",
            "[rmsprop | lr=0.001] Update step: 3600/5000 | loss: 4.1496\n",
            "[rmsprop | lr=0.001] Update step: 3700/5000 | loss: 4.2173\n",
            "[rmsprop | lr=0.001] Update step: 3800/5000 | loss: 4.3155\n",
            "[rmsprop | lr=0.001] Update step: 3900/5000 | loss: 4.0543\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 2efb06e4-3caa-4694-a178-e896f40dbb87)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 2efb06e4-3caa-4694-a178-e896f40dbb87)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Eval Step 4000 | rmsprop | lr=0.001] Loss: 4.1144, PPL: 61.21, Eval tokens 1002149\n",
            "[rmsprop | lr=0.001] Update step: 4000/5000 | loss: 4.2639\n",
            "[rmsprop | lr=0.001] Update step: 4100/5000 | loss: 3.9773\n",
            "[rmsprop | lr=0.001] Update step: 4200/5000 | loss: 4.1588\n",
            "[rmsprop | lr=0.001] Update step: 4300/5000 | loss: 4.2028\n",
            "[rmsprop | lr=0.001] Update step: 4400/5000 | loss: 4.0250\n",
            "[rmsprop | lr=0.001] Update step: 4500/5000 | loss: 4.1946\n",
            "[rmsprop | lr=0.001] Update step: 4600/5000 | loss: 4.0704\n",
            "[rmsprop | lr=0.001] Update step: 4700/5000 | loss: 4.0921\n",
            "[rmsprop | lr=0.001] Update step: 4800/5000 | loss: 4.0958\n",
            "[rmsprop | lr=0.001] Update step: 4900/5000 | loss: 3.9381\n",
            "[Eval Step 5000 | rmsprop | lr=0.001] Loss: 4.0617, PPL: 58.07, Eval tokens 1002149\n",
            "[rmsprop | lr=0.001] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=rmsprop, lr=0.001\n",
            "number of parameters: 123.55M\n",
            "[rmsprop | lr=0.003] Update step: 0/5000 | loss: 10.9855\n",
            "[rmsprop | lr=0.003] Update step: 100/5000 | loss: 7.7676\n",
            "[rmsprop | lr=0.003] Update step: 200/5000 | loss: 6.8380\n",
            "[rmsprop | lr=0.003] Update step: 300/5000 | loss: 6.7836\n",
            "[rmsprop | lr=0.003] Update step: 400/5000 | loss: 6.5512\n",
            "[rmsprop | lr=0.003] Update step: 500/5000 | loss: 7.3975\n",
            "[rmsprop | lr=0.003] Update step: 600/5000 | loss: 6.2882\n",
            "[rmsprop | lr=0.003] Update step: 700/5000 | loss: 6.2695\n",
            "[rmsprop | lr=0.003] Update step: 800/5000 | loss: 6.1338\n",
            "[rmsprop | lr=0.003] Update step: 900/5000 | loss: 6.2861\n",
            "[Eval Step 1000 | rmsprop | lr=0.003] Loss: 6.1612, PPL: 473.99, Eval tokens 1002149\n",
            "[rmsprop | lr=0.003] Update step: 1000/5000 | loss: 6.1099\n",
            "[rmsprop | lr=0.003] Update step: 1100/5000 | loss: 6.1820\n",
            "[rmsprop | lr=0.003] Update step: 1200/5000 | loss: 6.3520\n",
            "[rmsprop | lr=0.003] Update step: 1300/5000 | loss: 6.3822\n",
            "[rmsprop | lr=0.003] Update step: 1400/5000 | loss: 6.7182\n",
            "[rmsprop | lr=0.003] Update step: 1500/5000 | loss: 6.5837\n",
            "[rmsprop | lr=0.003] Update step: 1600/5000 | loss: 7.2441\n",
            "[rmsprop | lr=0.003] Update step: 1700/5000 | loss: 7.0129\n",
            "[rmsprop | lr=0.003] Update step: 1800/5000 | loss: 6.9646\n",
            "[rmsprop | lr=0.003] Update step: 1900/5000 | loss: 7.2561\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 28fb7047-504d-4d9b-a049-23ce222bcb93)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 28fb7047-504d-4d9b-a049-23ce222bcb93)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Eval Step 2000 | rmsprop | lr=0.003] Loss: 7.2497, PPL: 1407.62, Eval tokens 1002149\n",
            "[rmsprop | lr=0.003] Update step: 2000/5000 | loss: 7.3554\n",
            "[rmsprop | lr=0.003] Update step: 2100/5000 | loss: 7.3534\n",
            "[rmsprop | lr=0.003] Update step: 2200/5000 | loss: 7.3039\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: d8969da2-53fd-4c2d-8c87-6f1aff519555)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-train.00002-of-01024.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: d8969da2-53fd-4c2d-8c87-6f1aff519555)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-train.00002-of-01024.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[rmsprop | lr=0.003] Update step: 2300/5000 | loss: 7.3959\n",
            "[rmsprop | lr=0.003] Update step: 2400/5000 | loss: 7.2927\n",
            "[rmsprop | lr=0.003] Update step: 2500/5000 | loss: 7.3434\n",
            "[rmsprop | lr=0.003] Update step: 2600/5000 | loss: 7.3223\n",
            "[rmsprop | lr=0.003] Update step: 2700/5000 | loss: 7.3327\n",
            "[rmsprop | lr=0.003] Update step: 2800/5000 | loss: 7.4558\n",
            "[rmsprop | lr=0.003] Update step: 2900/5000 | loss: 7.1200\n",
            "[Eval Step 3000 | rmsprop | lr=0.003] Loss: 7.2610, PPL: 1423.66, Eval tokens 1002149\n",
            "[rmsprop | lr=0.003] Update step: 3000/5000 | loss: 7.2754\n",
            "[rmsprop | lr=0.003] Update step: 3100/5000 | loss: 7.3153\n",
            "[rmsprop | lr=0.003] Update step: 3200/5000 | loss: 7.1797\n",
            "[rmsprop | lr=0.003] Update step: 3300/5000 | loss: 7.2577\n",
            "[rmsprop | lr=0.003] Update step: 3400/5000 | loss: 7.2460\n",
            "[rmsprop | lr=0.003] Update step: 3500/5000 | loss: 7.1840\n",
            "[rmsprop | lr=0.003] Update step: 3600/5000 | loss: 7.0764\n",
            "[rmsprop | lr=0.003] Update step: 3700/5000 | loss: 7.2210\n",
            "[rmsprop | lr=0.003] Update step: 3800/5000 | loss: 7.1198\n",
            "[rmsprop | lr=0.003] Update step: 3900/5000 | loss: 7.0120\n",
            "[Eval Step 4000 | rmsprop | lr=0.003] Loss: 7.0915, PPL: 1201.73, Eval tokens 1002149\n",
            "[rmsprop | lr=0.003] Update step: 4000/5000 | loss: 7.1235\n",
            "[rmsprop | lr=0.003] Update step: 4100/5000 | loss: 6.9703\n",
            "[rmsprop | lr=0.003] Update step: 4200/5000 | loss: 7.0424\n",
            "[rmsprop | lr=0.003] Update step: 4300/5000 | loss: 7.1873\n",
            "[rmsprop | lr=0.003] Update step: 4400/5000 | loss: 7.0256\n",
            "[rmsprop | lr=0.003] Update step: 4500/5000 | loss: 7.0567\n",
            "[rmsprop | lr=0.003] Update step: 4600/5000 | loss: 7.1845\n",
            "[rmsprop | lr=0.003] Update step: 4700/5000 | loss: 7.0331\n",
            "[rmsprop | lr=0.003] Update step: 4800/5000 | loss: 7.0427\n",
            "[rmsprop | lr=0.003] Update step: 4900/5000 | loss: 7.1677\n",
            "[Eval Step 5000 | rmsprop | lr=0.003] Loss: 7.0365, PPL: 1137.44, Eval tokens 1002149\n",
            "[rmsprop | lr=0.003] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=rmsprop, lr=0.003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- SignSGD:\n",
        "\n",
        "# 1) lr = 1e-5\n",
        "model_s1, losses_s1, eval_s1 = run_experiment(\n",
        "    optimizer_name=\"signsgd\",\n",
        "    lr=1e-5,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 2) lr = 3e-5\n",
        "model_s2, losses_s2, eval_s2 = run_experiment(\n",
        "    optimizer_name=\"signsgd\",\n",
        "    lr=3e-5,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 3) lr = 1e-4\n",
        "model_s3, losses_s3, eval_s3 = run_experiment(\n",
        "    optimizer_name=\"signsgd\",\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTJyRNv86FaK",
        "outputId": "b553733d-247c-465c-c6d6-9205c2848ea9"
      },
      "id": "KTJyRNv86FaK",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 123.55M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[signsgd | lr=1e-05] Update step: 0/5000 | loss: 10.9855\n",
            "[signsgd | lr=1e-05] Update step: 100/5000 | loss: 9.7718\n",
            "[signsgd | lr=1e-05] Update step: 200/5000 | loss: 9.3228\n",
            "[signsgd | lr=1e-05] Update step: 300/5000 | loss: 9.0545\n",
            "[signsgd | lr=1e-05] Update step: 400/5000 | loss: 8.7004\n",
            "[signsgd | lr=1e-05] Update step: 500/5000 | loss: 8.3886\n",
            "[signsgd | lr=1e-05] Update step: 600/5000 | loss: 7.9730\n",
            "[signsgd | lr=1e-05] Update step: 700/5000 | loss: 7.6905\n",
            "[signsgd | lr=1e-05] Update step: 800/5000 | loss: 7.2998\n",
            "[signsgd | lr=1e-05] Update step: 900/5000 | loss: 7.3071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py:312: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval Step 1000 | signsgd | lr=1e-05] Loss: 7.0856, PPL: 1194.62, Eval tokens 1002149\n",
            "[signsgd | lr=1e-05] Update step: 1000/5000 | loss: 7.0686\n",
            "[signsgd | lr=1e-05] Update step: 1100/5000 | loss: 6.9148\n",
            "[signsgd | lr=1e-05] Update step: 1200/5000 | loss: 7.0339\n",
            "[signsgd | lr=1e-05] Update step: 1300/5000 | loss: 6.8628\n",
            "[signsgd | lr=1e-05] Update step: 1400/5000 | loss: 6.8928\n",
            "[signsgd | lr=1e-05] Update step: 1500/5000 | loss: 6.6006\n",
            "[signsgd | lr=1e-05] Update step: 1600/5000 | loss: 6.8494\n",
            "[signsgd | lr=1e-05] Update step: 1700/5000 | loss: 6.5279\n",
            "[signsgd | lr=1e-05] Update step: 1800/5000 | loss: 6.4032\n",
            "[signsgd | lr=1e-05] Update step: 1900/5000 | loss: 6.5379\n",
            "[Eval Step 2000 | signsgd | lr=1e-05] Loss: 6.5771, PPL: 718.48, Eval tokens 1002149\n",
            "[signsgd | lr=1e-05] Update step: 2000/5000 | loss: 6.6518\n",
            "[signsgd | lr=1e-05] Update step: 2100/5000 | loss: 6.5402\n",
            "[signsgd | lr=1e-05] Update step: 2200/5000 | loss: 6.5266\n",
            "[signsgd | lr=1e-05] Update step: 2300/5000 | loss: 6.6547\n",
            "[signsgd | lr=1e-05] Update step: 2400/5000 | loss: 6.4785\n",
            "[signsgd | lr=1e-05] Update step: 2500/5000 | loss: 6.4198\n",
            "[signsgd | lr=1e-05] Update step: 2600/5000 | loss: 6.4338\n",
            "[signsgd | lr=1e-05] Update step: 2700/5000 | loss: 6.4796\n",
            "[signsgd | lr=1e-05] Update step: 2800/5000 | loss: 6.5622\n",
            "[signsgd | lr=1e-05] Update step: 2900/5000 | loss: 6.2532\n",
            "[Eval Step 3000 | signsgd | lr=1e-05] Loss: 6.3912, PPL: 596.59, Eval tokens 1002149\n",
            "[signsgd | lr=1e-05] Update step: 3000/5000 | loss: 6.4195\n",
            "[signsgd | lr=1e-05] Update step: 3100/5000 | loss: 6.4908\n",
            "[signsgd | lr=1e-05] Update step: 3200/5000 | loss: 6.3014\n",
            "[signsgd | lr=1e-05] Update step: 3300/5000 | loss: 6.3744\n",
            "[signsgd | lr=1e-05] Update step: 3400/5000 | loss: 6.3847\n",
            "[signsgd | lr=1e-05] Update step: 3500/5000 | loss: 6.3080\n",
            "[signsgd | lr=1e-05] Update step: 3600/5000 | loss: 6.2180\n",
            "[signsgd | lr=1e-05] Update step: 3700/5000 | loss: 6.5359\n",
            "[signsgd | lr=1e-05] Update step: 3800/5000 | loss: 6.3651\n",
            "[signsgd | lr=1e-05] Update step: 3900/5000 | loss: 6.1185\n",
            "[Eval Step 4000 | signsgd | lr=1e-05] Loss: 6.2983, PPL: 543.66, Eval tokens 1002149\n",
            "[signsgd | lr=1e-05] Update step: 4000/5000 | loss: 6.3361\n",
            "[signsgd | lr=1e-05] Update step: 4100/5000 | loss: 6.1129\n",
            "[signsgd | lr=1e-05] Update step: 4200/5000 | loss: 6.2602\n",
            "[signsgd | lr=1e-05] Update step: 4300/5000 | loss: 6.4590\n",
            "[signsgd | lr=1e-05] Update step: 4400/5000 | loss: 6.2802\n",
            "[signsgd | lr=1e-05] Update step: 4500/5000 | loss: 6.3256\n",
            "[signsgd | lr=1e-05] Update step: 4600/5000 | loss: 6.4703\n",
            "[signsgd | lr=1e-05] Update step: 4700/5000 | loss: 6.3456\n",
            "[signsgd | lr=1e-05] Update step: 4800/5000 | loss: 6.2768\n",
            "[signsgd | lr=1e-05] Update step: 4900/5000 | loss: 6.4219\n",
            "[Eval Step 5000 | signsgd | lr=1e-05] Loss: 6.2818, PPL: 534.75, Eval tokens 1002149\n",
            "[signsgd | lr=1e-05] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=signsgd, lr=1e-05\n",
            "number of parameters: 123.55M\n",
            "[signsgd | lr=3e-05] Update step: 0/5000 | loss: 10.9855\n",
            "[signsgd | lr=3e-05] Update step: 100/5000 | loss: 9.4792\n",
            "[signsgd | lr=3e-05] Update step: 200/5000 | loss: 8.8880\n",
            "[signsgd | lr=3e-05] Update step: 300/5000 | loss: 8.3911\n",
            "[signsgd | lr=3e-05] Update step: 400/5000 | loss: 7.7404\n",
            "[signsgd | lr=3e-05] Update step: 500/5000 | loss: 7.3518\n",
            "[signsgd | lr=3e-05] Update step: 600/5000 | loss: 7.0354\n",
            "[signsgd | lr=3e-05] Update step: 700/5000 | loss: 6.9332\n",
            "[signsgd | lr=3e-05] Update step: 800/5000 | loss: 6.6625\n",
            "[signsgd | lr=3e-05] Update step: 900/5000 | loss: 6.8407\n",
            "[Eval Step 1000 | signsgd | lr=3e-05] Loss: 6.6724, PPL: 790.28, Eval tokens 1002149\n",
            "[signsgd | lr=3e-05] Update step: 1000/5000 | loss: 6.6414\n",
            "[signsgd | lr=3e-05] Update step: 1100/5000 | loss: 6.5147\n",
            "[signsgd | lr=3e-05] Update step: 1200/5000 | loss: 6.6558\n",
            "[signsgd | lr=3e-05] Update step: 1300/5000 | loss: 6.5159\n",
            "[signsgd | lr=3e-05] Update step: 1400/5000 | loss: 6.5733\n",
            "[signsgd | lr=3e-05] Update step: 1500/5000 | loss: 6.2922\n",
            "[signsgd | lr=3e-05] Update step: 1600/5000 | loss: 6.5102\n",
            "[signsgd | lr=3e-05] Update step: 1700/5000 | loss: 6.2049\n",
            "[signsgd | lr=3e-05] Update step: 1800/5000 | loss: 6.0788\n",
            "[signsgd | lr=3e-05] Update step: 1900/5000 | loss: 6.1933\n",
            "[Eval Step 2000 | signsgd | lr=3e-05] Loss: 6.2324, PPL: 508.96, Eval tokens 1002149\n",
            "[signsgd | lr=3e-05] Update step: 2000/5000 | loss: 6.3174\n",
            "[signsgd | lr=3e-05] Update step: 2100/5000 | loss: 6.1793\n",
            "[signsgd | lr=3e-05] Update step: 2200/5000 | loss: 6.1560\n",
            "[signsgd | lr=3e-05] Update step: 2300/5000 | loss: 6.3017\n",
            "[signsgd | lr=3e-05] Update step: 2400/5000 | loss: 6.1259\n",
            "[signsgd | lr=3e-05] Update step: 2500/5000 | loss: 6.0447\n",
            "[signsgd | lr=3e-05] Update step: 2600/5000 | loss: 6.0258\n",
            "[signsgd | lr=3e-05] Update step: 2700/5000 | loss: 6.0826\n",
            "[signsgd | lr=3e-05] Update step: 2800/5000 | loss: 6.1749\n",
            "[signsgd | lr=3e-05] Update step: 2900/5000 | loss: 5.8642\n",
            "[Eval Step 3000 | signsgd | lr=3e-05] Loss: 6.0004, PPL: 403.58, Eval tokens 1002149\n",
            "[signsgd | lr=3e-05] Update step: 3000/5000 | loss: 6.0166\n",
            "[signsgd | lr=3e-05] Update step: 3100/5000 | loss: 6.0736\n",
            "[signsgd | lr=3e-05] Update step: 3200/5000 | loss: 5.9071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 75fc4299-e3ed-4796-94ff-8e1246027f5e)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-train.00002-of-01024.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 75fc4299-e3ed-4796-94ff-8e1246027f5e)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-train.00002-of-01024.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[signsgd | lr=3e-05] Update step: 3300/5000 | loss: 5.9628\n",
            "[signsgd | lr=3e-05] Update step: 3400/5000 | loss: 5.9920\n",
            "[signsgd | lr=3e-05] Update step: 3500/5000 | loss: 5.9019\n",
            "[signsgd | lr=3e-05] Update step: 3600/5000 | loss: 5.8144\n",
            "[signsgd | lr=3e-05] Update step: 3700/5000 | loss: 6.1446\n",
            "[signsgd | lr=3e-05] Update step: 3800/5000 | loss: 5.9854\n",
            "[signsgd | lr=3e-05] Update step: 3900/5000 | loss: 5.6981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: c684fd74-d0a2-4b95-8dd6-5541ae194be4)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: c684fd74-d0a2-4b95-8dd6-5541ae194be4)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval Step 4000 | signsgd | lr=3e-05] Loss: 5.8947, PPL: 363.10, Eval tokens 1002149\n",
            "[signsgd | lr=3e-05] Update step: 4000/5000 | loss: 5.9525\n",
            "[signsgd | lr=3e-05] Update step: 4100/5000 | loss: 5.6774\n",
            "[signsgd | lr=3e-05] Update step: 4200/5000 | loss: 5.8525\n",
            "[signsgd | lr=3e-05] Update step: 4300/5000 | loss: 6.0635\n",
            "[signsgd | lr=3e-05] Update step: 4400/5000 | loss: 5.8891\n",
            "[signsgd | lr=3e-05] Update step: 4500/5000 | loss: 5.9218\n",
            "[signsgd | lr=3e-05] Update step: 4600/5000 | loss: 6.0567\n",
            "[signsgd | lr=3e-05] Update step: 4700/5000 | loss: 5.9349\n",
            "[signsgd | lr=3e-05] Update step: 4800/5000 | loss: 5.8621\n",
            "[signsgd | lr=3e-05] Update step: 4900/5000 | loss: 6.0055\n",
            "[Eval Step 5000 | signsgd | lr=3e-05] Loss: 5.8748, PPL: 355.94, Eval tokens 1002149\n",
            "[signsgd | lr=3e-05] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=signsgd, lr=3e-05\n",
            "number of parameters: 123.55M\n",
            "[signsgd | lr=0.0001] Update step: 0/5000 | loss: 10.9855\n",
            "[signsgd | lr=0.0001] Update step: 100/5000 | loss: 9.1013\n",
            "[signsgd | lr=0.0001] Update step: 200/5000 | loss: 7.9575\n",
            "[signsgd | lr=0.0001] Update step: 300/5000 | loss: 7.3451\n",
            "[signsgd | lr=0.0001] Update step: 400/5000 | loss: 6.9732\n",
            "[signsgd | lr=0.0001] Update step: 500/5000 | loss: 6.8636\n",
            "[signsgd | lr=0.0001] Update step: 600/5000 | loss: 6.6286\n",
            "[signsgd | lr=0.0001] Update step: 700/5000 | loss: 6.5989\n",
            "[signsgd | lr=0.0001] Update step: 800/5000 | loss: 6.3801\n",
            "[signsgd | lr=0.0001] Update step: 900/5000 | loss: 6.5652\n",
            "[Eval Step 1000 | signsgd | lr=0.0001] Loss: 6.4171, PPL: 612.21, Eval tokens 1002149\n",
            "[signsgd | lr=0.0001] Update step: 1000/5000 | loss: 6.3763\n",
            "[signsgd | lr=0.0001] Update step: 1100/5000 | loss: 6.2743\n",
            "[signsgd | lr=0.0001] Update step: 1200/5000 | loss: 6.3709\n",
            "[signsgd | lr=0.0001] Update step: 1300/5000 | loss: 6.2409\n",
            "[signsgd | lr=0.0001] Update step: 1400/5000 | loss: 6.3088\n",
            "[signsgd | lr=0.0001] Update step: 1500/5000 | loss: 6.0397\n",
            "[signsgd | lr=0.0001] Update step: 1600/5000 | loss: 6.2310\n",
            "[signsgd | lr=0.0001] Update step: 1700/5000 | loss: 5.9514\n",
            "[signsgd | lr=0.0001] Update step: 1800/5000 | loss: 5.7975\n",
            "[signsgd | lr=0.0001] Update step: 1900/5000 | loss: 5.9201\n",
            "[Eval Step 2000 | signsgd | lr=0.0001] Loss: 5.9529, PPL: 384.86, Eval tokens 1002149\n",
            "[signsgd | lr=0.0001] Update step: 2000/5000 | loss: 6.0418\n",
            "[signsgd | lr=0.0001] Update step: 2100/5000 | loss: 5.8811\n",
            "[signsgd | lr=0.0001] Update step: 2200/5000 | loss: 5.8846\n",
            "[signsgd | lr=0.0001] Update step: 2300/5000 | loss: 6.0325\n",
            "[signsgd | lr=0.0001] Update step: 2400/5000 | loss: 5.8655\n",
            "[signsgd | lr=0.0001] Update step: 2500/5000 | loss: 5.7781\n",
            "[signsgd | lr=0.0001] Update step: 2600/5000 | loss: 5.7039\n",
            "[signsgd | lr=0.0001] Update step: 2700/5000 | loss: 5.7875\n",
            "[signsgd | lr=0.0001] Update step: 2800/5000 | loss: 5.8755\n",
            "[signsgd | lr=0.0001] Update step: 2900/5000 | loss: 5.5449\n",
            "[Eval Step 3000 | signsgd | lr=0.0001] Loss: 5.7001, PPL: 298.91, Eval tokens 1002149\n",
            "[signsgd | lr=0.0001] Update step: 3000/5000 | loss: 5.7092\n",
            "[signsgd | lr=0.0001] Update step: 3100/5000 | loss: 5.7578\n",
            "[signsgd | lr=0.0001] Update step: 3200/5000 | loss: 5.5924\n",
            "[signsgd | lr=0.0001] Update step: 3300/5000 | loss: 5.6314\n",
            "[signsgd | lr=0.0001] Update step: 3400/5000 | loss: 5.6952\n",
            "[signsgd | lr=0.0001] Update step: 3500/5000 | loss: 5.5774\n",
            "[signsgd | lr=0.0001] Update step: 3600/5000 | loss: 5.5016\n",
            "[signsgd | lr=0.0001] Update step: 3700/5000 | loss: 5.8344\n",
            "[signsgd | lr=0.0001] Update step: 3800/5000 | loss: 5.6881\n",
            "[signsgd | lr=0.0001] Update step: 3900/5000 | loss: 5.3737\n",
            "[Eval Step 4000 | signsgd | lr=0.0001] Loss: 5.5662, PPL: 261.45, Eval tokens 1002149\n",
            "[signsgd | lr=0.0001] Update step: 4000/5000 | loss: 5.6628\n",
            "[signsgd | lr=0.0001] Update step: 4100/5000 | loss: 5.3482\n",
            "[signsgd | lr=0.0001] Update step: 4200/5000 | loss: 5.5396\n",
            "[signsgd | lr=0.0001] Update step: 4300/5000 | loss: 5.7488\n",
            "[signsgd | lr=0.0001] Update step: 4400/5000 | loss: 5.5617\n",
            "[signsgd | lr=0.0001] Update step: 4500/5000 | loss: 5.6013\n",
            "[signsgd | lr=0.0001] Update step: 4600/5000 | loss: 5.7069\n",
            "[signsgd | lr=0.0001] Update step: 4700/5000 | loss: 5.5972\n",
            "[signsgd | lr=0.0001] Update step: 4800/5000 | loss: 5.5169\n",
            "[signsgd | lr=0.0001] Update step: 4900/5000 | loss: 5.6355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 2cb32634-c5b9-4fe4-b92a-31880fbcd488)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 2cb32634-c5b9-4fe4-b92a-31880fbcd488)')' thrown while requesting GET https://huggingface.co/datasets/allenai/c4/resolve/1588ec454efa1a09f29cd18ddd04fe05fc8653a2/en/c4-validation.00003-of-00008.json.gz\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval Step 5000 | signsgd | lr=0.0001] Loss: 5.5361, PPL: 253.70, Eval tokens 1002149\n",
            "[signsgd | lr=0.0001] Reached max number of update steps (5000). Stopping training.\n",
            "Training finished for optimizer=signsgd, lr=0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4623dcf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "4623dcf2",
        "outputId": "58df0645-026a-4724-d72b-4346fe0e6d1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW+JJREFUeJzt3XdYk1f7B/BvCCGAbFCGAuLEvUXcVnBWrW3VqrVq7bDq62ptta2to1Vrf7Vau9/21S61to5atSp14Ma9FReIG1EhDIGQnN8fkUBMGIEMQr6f6/Jq8jznOblzRL17pkQIIUBERERkoxysHQARERFReTCZISIiIpvGZIaIiIhsGpMZIiIismlMZoiIiMimMZkhIiIim8ZkhoiIiGyao7UDMDe1Wo1bt27B3d0dEonE2uEQERFRKQghkJ6ejqCgIDg4FN/3UumTmVu3biE4ONjaYRAREVEZXL9+HTVq1Ci2TKVPZtzd3QFoGsPDw8OkdSuVSmzbtg09evSATCYzad1UgO1sGWxny2A7Wwbb2TLM2c4KhQLBwcHaf8eLU+mTmfyhJQ8PD7MkM66urvDw8OAfFjNiO1sG29ky2M6WwXa2DEu0c2mmiHACMBEREdk0JjNERERk05jMEBERkU1jMkNEREQ2jckMERER2TQmM0RERGTTmMwQERGRTWMyQ0RERDbNqsnM7t270a9fPwQFBUEikWD9+vU699euXYsePXrA19cXEokEJ06csEqcREREVHFZNZnJzMxEs2bN8NVXXxV5v2PHjvjkk08sHBkRERHZCqseZ9C7d2/07t27yPsjRowAACQmJlooIiIiIrI1le5sppycHOTk5GjfKxQKAJrzI5RKpUk/K78+U9dLutjOlsF2tgy2s2WwnS3DnO1sTJ2VLpmZP38+Zs+erXd927ZtcHV1NelnXU4DargBMTExJq2XDGM7Wwbb2TLYzpbBdrYMc7RzVlZWqctWumRmxowZmDp1qvZ9/hHiPXr0MOmp2Qu2xOPHc9fQs4Yan7/cnaeympFSqURMTAyio6PZzmbEdrYMtrNlsJ0tw5ztnD+yUhqVLpmRy+WQy+V612UymUkbuoZPFQBAUobp6ybD2M6WwXa2DLazZbCdLcMc7WxMfdxnpox8qjgBAPLUVg6EiIjIzlm1ZyYjIwOXL1/Wvk9ISMCJEyfg4+ODkJAQPHjwAElJSbh16xYAID4+HgAQEBCAgIAAq8ScT+6oyQPzhMSqcRAREdk7q/bMHDlyBC1atECLFi0AAFOnTkWLFi3wwQcfAAA2bNiAFi1aoG/fvgCAF154AS1atMC3335rtZjzOeUnM+yZISIisiqr9sx07doVQogi748aNQqjRo2yXEBGkEnze2asHAgREZGd45yZMnJ6nMyo2DNDRERkVUxmykjmyJ4ZIiKiioDJTBmxZ4aIiKhiYDJTRlIHzSom5jJERETWxWSmjBwfJzMqDjMRERFZFZOZMnJ8PMykZjJDRERkVUxmyii/Z4bJDBERkXUxmSkjKYeZiIiIKgQmM2XEnhkiIqKKgclMGeX3zAhIoGZGQ0REZDVMZsrI0aGg6VTFHMlARERE5sVkpowcpQWnZedx4gwREZHVMJkpo/xhJgDI4zATERGR1TCZKSPHQsmMiskMERGR1TCZKSOpTjLDQw2IiIishclMGUkkEm1Cw2EmIiIi62EyUw7ajfOYzBAREVkNk5lykLFnhoiIyOqYzJQDe2aIiIisj8lMOWjnzHCfGSIiIqthMlMOjhxmIiIisjomM+XAYSYiIiLrYzJTDgU9M9xnhoiIyFqYzJSD9PFhk+yZISIish4mM+WQf9gk58wQERFZD5OZcnDknBkiIiKrYzJTDpwATEREZH1MZsohv2dGyWSGiIjIapjMlIO2Z4ab5hEREVkNk5lykHJpNhERkdUxmSkHmZRLs4mIiKyNyUw5cAIwERGR9TGZKQcpJwATERFZHZOZcuA+M0RERNZn1WRm9+7d6NevH4KCgiCRSLB+/Xqd+0IIfPDBBwgMDISLiwuioqJw6dIl6wRrAE/NJiIisj6rJjOZmZlo1qwZvvrqK4P3Fy5ciC+++ALffvst4uLiUKVKFfTs2RPZ2dkWjtQwR57NREREZHWO1vzw3r17o3fv3gbvCSGwePFivP/++xgwYAAA4Oeff4a/vz/Wr1+PF154wZKhGqRdmq3i0mwiIiJrsWoyU5yEhATcuXMHUVFR2muenp6IiIjAgQMHikxmcnJykJOTo32vUCgAAEqlEkql0qQxOkg0PTK5yjyT100F8tuWbWxebGfLYDtbBtvZMszZzsbUWWGTmTt37gAA/P39da77+/tr7xkyf/58zJ49W+/6tm3b4OrqatIY7952AOCACxcvYXPWRZPWTfpiYmKsHYJdYDtbBtvZMtjOlmGOds7Kyip12QqbzJTVjBkzMHXqVO17hUKB4OBg9OjRAx4eHib9rK2rTgDJyZD71kCfPk1MWjcVUCqViImJQXR0NGQymbXDqbTYzpbBdrYMtrNlmLOd80dWSqPCJjMBAQEAgLt37yIwMFB7/e7du2jevHmRz8nlcsjlcr3rMpnM5A29+WwyAGDtidtY9EJLk9ZN+szxe0j62M6WwXa2DLazZZijnY2pr8LuMxMWFoaAgABs375de02hUCAuLg6RkZFWjKxA38aahKu+v5uVIyEiIrJfVu2ZycjIwOXLl7XvExIScOLECfj4+CAkJASTJ0/GRx99hLp16yIsLAwzZ85EUFAQnnnmGesFXUjrml7YdOYOavlVsXYoREREdsuqycyRI0fQrVs37fv8uS4jR47E8uXL8fbbbyMzMxOvvfYaUlNT0bFjR2zZsgXOzs7WClmH3FHTsZWTx6XZRERE1mLVZKZr164QougN5yQSCebMmYM5c+ZYMKrSc5IymSEiIrK2CjtnxhY4aXtmVFaOhIiIyH4xmSkHuUwKAMjlDsBERERWw2SmHPLnzOQqmcwQERFZC5OZcsifM3PtQel3KSQiIiLTYjJTDo6PD5p8pFQjW8l5M0RERNbAZKYc/NydtK8fZOZaMRIiIiL7xWSmHIK9Cw6uTM/Os2IkRERE9ovJjIlsv3DX2iEQERHZJSYzJrJwS7y1QyAiIrJLTGZMZHDrGtYOgYiIyC4xmSmnboGaPWa8XJ1KKElERETmwGSmnORSzdlSmTmcAExERGQNTGbKSa450QBZudxnhoiIyBqYzJST8+NkJj1bad1AiIiI7BSTmXKq4qj5731umkdERGQVTGbKKX+Y6dLdDOsGQkREZKeYzJSTePzfDE4AJiIisgomM+UU5Cq0r9Mecd4MERGRpTGZKSd3WcHrhJRM6wVCRERkp5jMlJODBKjlpzlwMkfJ5dlERESWxmTGBK6mZAEAftibYOVIiIiI7A+TGROKOceTs4mIiCyNyQwRERHZNCYzREREZNOYzBAREZFNYzJjAv2aBlg7BCIiIrvFZMYEejfSJDMtQrysGwgREZEdYjJjAk6OEgDA8aRU6wZCRERkh5jMmMD1h4+0r5UqtRUjISIisj9MZkygf9NA7etMHjhJRERkUUxmTMDDRQYnqaYps3J5pAEREZElMZkxERcnKQAmM0RERJbGZMZEXLXJDIeZiIiILInJjIm4yDTJzCP2zBAREVlUhU9m0tPTMXnyZISGhsLFxQXt27fH4cOHrR2WHvnjZCY7j6uZiIiILKnCJzOvvPIKYmJi8Msvv+D06dPo0aMHoqKicPPmTWuHpsNZpmnKbCV7ZoiIiCypQiczjx49wpo1a7Bw4UJ07twZderUwaxZs1CnTh1888031g5PR/4wE5MZIiIiy3K0dgDFycvLg0qlgrOzs851FxcX7N271+AzOTk5yMnJ0b5XKBQAAKVSCaVSadL48utTKpVwkmp2Ac7MNv3n2LvC7Uzmw3a2DLazZbCdLcOc7WxMnRIhhDB5BCbUvn17ODk5YcWKFfD398fKlSsxcuRI1KlTB/Hx8XrlZ82ahdmzZ+tdX7FiBVxdXc0W5+enpUjMkKBzgBrPhXHeDBERUXlkZWVh2LBhSEtLg4eHR7FlK3wyc+XKFbz88svYvXs3pFIpWrZsiXr16uHo0aM4f/68XnlDPTPBwcFISUkpsTGMpVQqERMTg+joaDScs1N7/dLcHib9HHtXuJ1lMpm1w6m02M6WwXa2DLazZZiznRUKBfz8/EqVzFToYSYAqF27NmJjY5GZmQmFQoHAwEAMGTIEtWrVMlheLpdDLpfrXZfJZGb7gX6yXv7BMQ9z/h5SAbazZbCdLYPtbBnmaGdj6qvQE4ALq1KlCgIDA/Hw4UNs3boVAwYMsHZIOp5rWcPaIRAREdmlCt8zs3XrVgghUL9+fVy+fBnTpk1DeHg4Ro8ebe3QdMQl3Ld2CERERHapwvfMpKWlYfz48QgPD8dLL72Ejh07YuvWrRWu29DJscI3JRERUaVU4XtmBg8ejMGDB1s7jBI5O0qtHQIREZFdYneCieSfmk1ERESWxWTGRKb3Dte+ruCr3YmIiCoVJjMmUs/fXftaqWIyQ0REZClMZkxEXmgCcK6KOwATERFZCpMZE3GSFjQlD5skIiKyHCYzJuLgING+XnUoyYqREBER2RcmM2aw9exda4dARERkN5jMmEFWbp61QyAiIrIbTGbMoH6Ae8mFiIiIyCSYzJhQm5reAIBGQZ5WjoSIiMh+MJkxIW9XJwDAsn0JVo6EiIjIfjCZMaFt5zQTf1Mycq0cCRERkf1gMkNEREQ2jcmMCbWr5WPtEIiIiOwOkxkTeqVjLQBAsxqcAExERGQpTGZMSPp4F2AeM0lERGQ5TGZMSPL4RINTN9KsGwgREZEdYTJjQmmPlNrXuXk8OZuIiMgSmMyY0MPMgiXZKjUHm4iIiCyByYwJZRfqjVEJJjNERESWwGTGhKT5k2bAnhkiIiJLYTJjQoPbBGtfq5nMEBERWQSTGRPycHbUvuYwExERkWUwmTEhSaFhpiOJD6wYCRERkf1gMmMm288nWzsEIiIiu8BkxkzWHb9p7RCIiIjsApMZM+GMGSIiIstgMmMmYzqGWTsEIiIiu8BkxsQGt64BADh5PdW6gRAREdkJJjMmtvrIDQBAXAJXMxEREVkCkxkiIiKyaUxmiIiIyKaVO5lRKBRYv349zp8/b4p4bN7TTQOtHQIREZFdMTqZGTx4ML788ksAwKNHj9C6dWsMHjwYTZs2xZo1a0weoK0Z26W2tUMgIiKyK0YnM7t370anTp0AAOvWrYMQAqmpqfjiiy/w0UcfmTxAW+PqJNW+jr+TbsVIiIiI7IPRyUxaWhp8fHwAAFu2bMFzzz0HV1dX9O3bF5cuXTJpcCqVCjNnzkRYWBhcXFxQu3ZtzJ07F6ICH+LoLCtIZs7dTrNiJERERPbBseQiuoKDg3HgwAH4+Phgy5YtWLVqFQDg4cOHcHZ2Nmlwn3zyCb755hv89NNPaNSoEY4cOYLRo0fD09MTEydONOlnmUrhnhlnR2kxJYmIiMgUjE5mJk+ejOHDh8PNzQ2hoaHo2rUrAM3wU5MmTUwa3P79+zFgwAD07dsXAFCzZk2sXLkShw4dKvKZnJwc5OTkaN8rFAoAgFKphFKpNGl8+fUVrreKrODk7Oxc03+mPTLUzmR6bGfLYDtbBtvZMszZzsbUKRFlGLM5cuQIrl+/jujoaLi5uQEANm3aBC8vL3To0MHY6oo0b948fP/999i2bRvq1auHkydPokePHli0aBGGDx9u8JlZs2Zh9uzZetdXrFgBV1dXk8VWnO8vOODsQwe8UEuFSP+KOyRGRERUUWVlZWHYsGFIS0uDh4dHsWXLlMwUplKpcPr0aYSGhsLb27s8VelRq9V49913sXDhQkilUqhUKnz88ceYMWNGkc8Y6pkJDg5GSkpKiY1hLKVSiZiYGERHR0Mmk2mvT1x1Ev+cvYsPnw7HixEhJv1Me1RUO5NpsZ0tg+1sGWxnyzBnOysUCvj5+ZUqmSnTMFOTJk0wZswYqFQqdOnSBfv374erqys2btyoHXYyhdWrV+O3337DihUr0KhRI5w4cQKTJ09GUFAQRo4cafAZuVwOuVyud10mk5ntB/rJul2cNM2ap5bwD5EJmfP3kAqwnS2D7WwZbGfLMEc7G1Of0auZ/vzzTzRr1gwA8PfffyMhIQEXLlzAlClT8N577xlbXbGmTZuG6dOn44UXXkCTJk0wYsQITJkyBfPnzzfp55iaXKZp1mylysqREBERVX5GJzMpKSkICAgAAGzevBmDBg1CvXr18PLLL+P06dMmDS4rKwsODrohSqVSqNVqk36Oqckfr2LKyavYcRIREVUGRicz/v7+OHfuHFQqFbZs2YLo6GgAmsRDKjXtUuR+/frh448/xqZNm5CYmIh169Zh0aJFGDhwoEk/x9TkjppmzcljzwwREZG5GT1nZvTo0Rg8eDACAwMhkUgQFRUFAIiLi0N4eLhJg1u6dClmzpyJcePGITk5GUFBQXj99dfxwQcfmPRzTK0gmWHPDBERkbkZnczMmjULjRs3xvXr1zFo0CDtZFupVIrp06ebNDh3d3csXrwYixcvNmm95iZ/vAtwjpLJDBERkbkZncwAwPPPP693rajVRfYo/0iDjJw8K0dCRERU+Rk9ZwYAYmNj0a9fP9SpUwd16tRB//79sWfPHlPHZrMCPDTHOmw6fRtqNTfNIyIiMiejk5lff/0VUVFRcHV1xcSJEzFx4kS4uLige/fuWLFihTlitDluzgUdXjsuJFsxEiIiosrP6GGmjz/+GAsXLsSUKVO01yZOnIhFixZh7ty5GDZsmEkDtEVu8oJVXSkZOcWUJCIiovIyumfm6tWr6Nevn971/v37IyEhwSRB2TpXp4IckaNMRERE5mV0MhMcHIzt27frXf/3338RHBxskqBsnUxacHK2qnxHXxEREVEJjB5mevPNNzFx4kScOHEC7du3BwDs27cPy5cvx5IlS0weoC3yqVJwNpRTocSGiIiITM/oZOaNN95AQEAAPvvsM6xevRoA0KBBA/z+++8YMGCAyQO0RT5VnCCTSqBUsVeGiIjI3Mq0z8zAgQMr/JEC1tapblXsuJCM3RdTMKRNiLXDISIiqrTKtM8MlSx/Sfam07etHAkREVHlVqqeGW9vb0gkpZv78eDBg3IFRERERGSMUiUztnY2UkUjhCh1MkhERETGKVUyw3OXykelFnDkqiYiIiKz4JwZC+BeM0RERObDZMYC1h67ae0QiIiIKi0mMxYwY+1p5KnU1g6DiIioUmIyYyYLn2uq8/6bXVesFAkREVHlxmTGTJ5rVUPn/WcxF3FXkW2laIiIiCovo3cAHjhwoMFlxhKJBM7OzqhTpw6GDRuG+vXrmyRAW+VgYPHSkcSH6Ns00PLBEBERVWJG98x4enpix44dOHbsGCQSCSQSCY4fP44dO3YgLy8Pv//+O5o1a4Z9+/aZI16bYSjhE+CqJiIiIlMzumcmICAAw4YNw5dffgkHB00upFarMWnSJLi7u2PVqlUYO3Ys3nnnHezdu9fkARMREREVZnTPzI8//ojJkydrExkAcHBwwH/+8x98//33kEgkmDBhAs6cOWPSQCsDCbhxHhERkakZnczk5eXhwoULetcvXLgAlUoFAHB2dub2/QZwmImIiMj0jB5mGjFiBMaMGYN3330Xbdq0AQAcPnwY8+bNw0svvQQAiI2NRaNGjUwbaSWQ9khp7RCIiIgqHaOTmc8//xz+/v5YuHAh7t69CwDw9/fHlClT8M477wAAevTogV69epk20krgvXVnMDwi1NphEBERVSpGJzNSqRTvvfce3nvvPSgUCgCAh4eHTpmQkBDTRGfjWod648i1h9YOg4iIqFIr16Z5Hh4eeokMFZjVn0NtRERE5mZ0MnP37l2MGDECQUFBcHR0hFQq1flFBYK9XfWuqdScBExERGRKRg8zjRo1CklJSZg5cyYCAwO5aqkYnq4yvWt5ajWkDkz6iIiITMXoZGbv3r3Ys2cPmjdvboZwKr88lYDc6FYnIiKiohg9zBQcHAwhOFRSVrfTHlk7BCIiokrF6GRm8eLFmD59OhITE80QTuW34J94a4dARERUqRg94DFkyBBkZWWhdu3acHV1hUymOy/kwYMHJguuMrqakmHtEIiIiCoVo5OZxYsXmyEM+3H1Xqa1QyAiIqpUjE5mRo4caY44ilSzZk1cu3ZN7/q4cePw1VdfWTSWstg3/Sl0WLBD55paLeDgwFVgREREplCqZEahUGg3x8vf9bcopt5E7/Dhw9oDLAHgzJkziI6OxqBBg0z6OeZS3csF1dzlSE7P0V6bsPIY3u/bEEFeLlaMjIiIqHIoVTLj7e2N27dvo1q1avDy8jK4t4wQAhKJRCfxMIWqVavqvF+wYAFq166NLl26GCyfk5ODnJyCxCE/+VIqlVAqTXvQY359JdX7VnRdvL32jPb95tN3cO1+Jta/EWnSeCqr0rYzlQ/b2TLYzpbBdrYMc7azMXVKRCnWWcfGxqJDhw5wdHREbGxssWWLSjJMITc3F0FBQZg6dSreffddg2VmzZqF2bNn611fsWIFXF31d+S1hDw18Gacft64JDLPCtEQERFVfFlZWRg2bBjS0tJKHPUpVTJTUaxevRrDhg1DUlISgoKCDJYx1DMTHByMlJQUkw+BKZVKxMTEIDo6Wm9V15Pe+vM0/jp5W+fapbk9TBpPZWVMO1PZsZ0tg+1sGWxnyzBnOysUCvj5+ZUqmSnTXrSpqak4dOgQkpOToVarde699NJLZamyVH788Uf07t27yEQGAORyOeRyud51mUxmth/o0tTtaODcKv4BM445fw+pANvZMtjOlsF2tgxztLMx9RmdzPz9998YPnw4MjIy4OHhoTN/RiKRmC2ZuXbtGv7991+sXbvWLPWbm7Rc55MTERFRUYz+J/bNN9/Eyy+/jIyMDKSmpuLhw4faX+bcMG/ZsmWoVq0a+vbta7bPMCcHA5Omc/PUBkoSERGRMYxOZm7evImJEydadDKtWq3GsmXLMHLkSDg62uYpjU1qeOpdO3KNuyUTERGVl9HJTM+ePXHkyBFzxFKkf//9F0lJSXj55Zct+rmm9EKbEL1rjg4ceyIiIiovo7s5+vbti2nTpuHcuXNo0qSJ3gSd/v37myy4fD169LD5k7qlBnb8PXj1PtqG+WD/lRQoHuWhV+MAK0RGRERk24xOZl599VUAwJw5c/TumWPTvMpk8ZDmmPz7Ce37RTEXUbuqG8avOAYAODDjKQR6cldgIiIiYxg9zqFWq4v8xUSmeIGeznrX8hMZALifkWvJcIiIiCoFTtqwoLZhPqjmrr8HDhEREZVdqYaZvvjiC7z22mtwdnbGF198UWzZiRMnmiSwykgikWBo2xAs2X7J2qEQERFVGqVKZj7//HMMHz4czs7O+Pzzz4ssJ5FImMyUIE/NvWWIiIhMqVTJTEJCgsHXZLwGgaY9H4qIiMjecc6MhfVoGABHA8u0iYiIqGzKtJ3ujRs3sGHDBiQlJSE3V3cFzqJFi0wSWGXl5OiAix/1Rq13N1s7FCIiokrB6GRm+/bt6N+/P2rVqoULFy6gcePGSExMhBACLVu2NEeMlY5DET0z0/48hc0TO+oc3klERETFM3qYacaMGXjrrbdw+vRpODs7Y82aNbh+/Tq6dOmCQYMGmSPGSunnl9vqXTt/W4GwGZtxOJFnNhEREZWW0cnM+fPn8dJLLwEAHB0d8ejRI7i5uWHOnDn45JNPTB5gZdW5XlW0q+Vj8N6gbw9YOBoiIiLbZXQyU6VKFe08mcDAQFy5ckV7LyUlxXSR2YE8lW2fN0VERFQRGJ3MtGvXDnv37gUA9OnTB2+++SY+/vhjvPzyy2jXrp3JA6zMlOqik5kvuLEeERFRqRg9AXjRokXIyMgAAMyePRsZGRn4/fffUbduXa5kMlKequgN9BbFXESTGp7oVr+aBSMiIiKyPUYlMyqVCjdu3EDTpk0BaIacvv32W7MEZg9KGmYavewwEhf0tVA0REREtsmoYSapVIoePXrg4cOH5orHrnAFNhERUfkZPWemcePGuHr1qjlisTv/N6gZ/NzkaFLd09qhEBER2Syjk5mPPvoIb731FjZu3Ijbt29DoVDo/KLSa1zdE4ff644gL+ciy3y187IFIyIiIrI9pU5m5syZg8zMTPTp0wcnT55E//79UaNGDXh7e8Pb2xteXl7w9vY2Z6yVkkQiwcnraUXe/3RrPB5k5hZ5n4iIyN6VegLw7NmzMXbsWOzcudOc8dglaQkHTyqLWfVERERk70qdzAihWXnTpUsXswVjr0pKZjhPmIiIqGhGzZnhAYjm8ePI1sXe33DyloUiISIisj1G7TNTr169EhOaBw94SKKx6vq7Y0zHMPy4N8Hg/Y82nceNh49Qz98dwyJCLBwdERFRxWZUMjN79mx4enIZsTkMjwgpMpkBgOX7EwEAbcN8UKeam4WiIiIiqviMSmZeeOEFVKvG7fXNoVZVN5ye1QPbzydj8u8niix3Lz2HyQwREVEhpZ4zw/ky5ufuLEOor2uxZTafvm2haIiIiGxDqZOZ/NVMZF2/HLyGP4/eQHJ6NtTFnLpNRERkL0o9zKRWc6+TiuKtP04CAHo1CsC3I1pZORoiIiLrMvo4AzIvY4bztpy9Y8ZIiIiIbAOTmQrGt4qTtUMgIiKyKUxmKphgH1d8+nxTLHy+qbVDISIisglGLc0myxjUOhgAMLh1MH7cm4C5G88VWTbu6n04y6RoFuxloeiIiIgqFvbMVHBjOoYVe3/I9wcx4Kt9OJLInZeJiMg+MZmpJHZfSrF2CERERFZR4ZOZmzdv4sUXX4Svry9cXFzQpEkTHDlyxNphWVT72r4lluGWhkREZK8qdDLz8OFDdOjQATKZDP/88w/OnTuHzz77DN7e3tYOzaKWDm1RYhlu0ExERPaqQk8A/uSTTxAcHIxly5Zpr4WFFT+HpDLydZNjWs/6+HRrfJFlsnJVFoyIiIio4qjQycyGDRvQs2dPDBo0CLGxsahevTrGjRuHV199tchncnJykJOTo32vUCgAAEqlEkql0qTx5ddn6noNea1jaLHJzPe7r2JadB2zx2ENlmxne8Z2tgy2s2WwnS3DnO1sTJ0SUYEPXXJ2dgYATJ06FYMGDcLhw4cxadIkfPvttxg5cqTBZ2bNmoXZs2frXV+xYgVcXYs/xLGim3Sg+Nzz5XoqNPOtsL+dREREpZaVlYVhw4YhLS0NHh4exZat0MmMk5MTWrdujf3792uvTZw4EYcPH8aBAwcMPmOoZyY4OBgpKSklNoaxlEolYmJiEB0dDZlMZtK6DZm98Tx+jbtebJlVr7SBp4sMdaq5mT0eS7F0O9srtrNlsJ0tg+1sGeZsZ4VCAT8/v1IlMxV6mCkwMBANGzbUudagQQOsWbOmyGfkcjnkcrnedZlMZrYfaHPWXViob8kJygs/HAYAJC7oa+5wLM5S7Wzv2M6WwXa2DLazZZijnY2pr0KvZurQoQPi43XniVy8eBGhoaFWisi6XmxX+u/99a7LeOl/h5Cbx9POiYiocqvQycyUKVNw8OBBzJs3D5cvX8aKFSvw/fffY/z48dYOzSpcnKTwc9McROksK/63buGWeOy+eA8bTt6yRGhERERWU6GTmTZt2mDdunVYuXIlGjdujLlz52Lx4sUYPny4tUOzmt9eaYfu4dXw59j2pSqflZuHZEU23l13GuduKcwcHRERkeVV6DkzAPD000/j6aeftnYYFUb9AHf8OKpNqcur1QJv/nESey6lYEVcUqWcS0NERPatQvfMUPll5qpw4U66tcMgIiIymwrfM0PlU9xGe0RERJUBe2Zs2IDmQUY/k5mThwq8tRAREZHRmMzYsEWDm+Po+1FGPdPow62YsOK4mSIiIiKyPCYzNkzqIIGvmxx/jI006rlNp28DAI4kPsCRxAfmCI2IiMhimMxUAm1q+uDgjO6o7+9e6md+3JuA5789gOe/PYCs3DwzRkdERGReTGYqiQBPZ2yd0hkf9mtYcmEAczee075OzeKpskREZLuYzFQyozuEGf1M+wU7sPEUdwomIiLbxGSGAICTgomIyGYxmSEiIiKbxmSGiIiIbBqTmUpufLfa1g6BiIjIrJjMVEItQ7wAAB8PbIxpPcOx8PmmRj3/8aZz+GrnZTNERkREZHo8m6kS+vWVCJy/nY4WwV4AgO7h1Ur9bGJKJv67JwEAMK5rbUgkEnOESEREZDLsmamEXJ0c0SrUGw4OmkTE102OBoEeJT5Xc/omfLHjkva9Ss0znIiIqOJjMmMn2tT0LlW5tcdual/nqQXyVGp8vesyTt1INVNkRERE5cNhJipS+Mwt8PeQ464iBwsRj2Wj2qCbEUNWRERElsCeGTvh5SIr03N3FTna16OXH8bl5Ay88tMR7L+SYqrQiIiIyoXJjJ14tXMt7evvR7Qqcz1Ri2Lx7/m7GPbfOFOERUREVG4cZrIT7s4yfPtiK+TkqdCjUQAkEkBwfi8REVUCTGbsSK/GAdYOgYiIyOQ4zGSnuHsMERFVFkxm7NTU6HrWDoGIiMgkmMzYqfHd6qBRUMFGeokL+loxGiIiorJjMmOnJBIJ6lZzM0ldSfezoOZuwUREZCVMZuxYDW9XnfeLhzQ36vk9l+7h14PX0PnTnZi+9pQJIyMiIio9rmayY+O61cb9zFz0aaJZ5fRMi+qY/PuJUj8/4sdD2terj9xAqG8VDGgepJckERERmRN7ZuyYq5Mj5j/bBJ3qVtVeW/hc0zLX9+nWeDz/zQFThEZERFRqTGZIx+A2wdj7TjcsHdqiTM/fUWSjy6c78c2uKyaOjIiIyDAmM6Snhrcr+jULKvPz1+5n4ZMtF0wYERERUdGYzFCRvF3Ldjhlvv/uvop/Tt82UTRERESGMZmhIv36SkS5nv9483m88dsxCB4CRUREZsRkhorUKMgTlz/uXe4N9VYfuW6iiIiIiPQxmaFiOUo1PyKH34tCsxqeZarjnTWncVeRDQDIzVMjLUtpsviIiIgqfDIza9YsSCQSnV/h4eHWDsvuVHWX468JHXFqVo8yPR8xbzsu3U1H90W70GzONqRk5Jg4QiIislc2sWleo0aN8O+//2rfOzraRNiVkoezDGF+VZCQkmn0s9Gf79a+3n/lPjrV8YN3FSdThkdERHaowvfMAJrkJSAgQPvLz8/P2iHZNVNM6P1m1xW0mBuDXw5eM0FERERkz2yii+PSpUsICgqCs7MzIiMjMX/+fISEhBgsm5OTg5ycgiEMhUIBAFAqlVAqTTtXI78+U9db0alNkMycv635fZm5/gw61fZGdS+XIsvaaztbGtvZMtjOlsF2tgxztrMxdUpEBV83+88//yAjIwP169fH7du3MXv2bNy8eRNnzpyBu7u7XvlZs2Zh9uzZetdXrFgBV1eeGWQKc45JcT9HYtI6l0TmmbQ+IiKybVlZWRg2bBjS0tLg4eFRbNkKn8w8KTU1FaGhoVi0aBHGjBmjd99Qz0xwcDBSUlJKbAxjKZVKxMTEIDo6GjJZ+TaYsyXL9l/DvH/i0bGOL/Zevm+SOrvV98PrncLQINAdDhIJnGVS7T17bWdLYztbBtvZMtjOlmHOdlYoFPDz8ytVMmMTw0yFeXl5oV69erh8+bLB+3K5HHK5XO+6TCYz2w+0OeuuiF7pVBttwnzRINADf5+8hd/iknDiemq56twZn4Kd8SkAACdHB1yY0wsODrq9P/bWztbCdrYMtrNlsJ0twxztbEx9NjEBuLCMjAxcuXIFgYGB1g7Fbjk4SNAixBvOMikGtQ7G+vEdUN9ff8ivrHLz1Ei4n4k/j95AnkptsnqJiKhyqvDJzFtvvYXY2FgkJiZi//79GDhwIKRSKYYOHWrt0KiQ8h598KTun8XirT9OoteSPdh69q7BMrl5THSIiMgGkpkbN25g6NChqF+/PgYPHgxfX18cPHgQVatWtXZoVEhVdzkuzO2FkZGhJq33cnIGJqw6iV8v6f6oHrx6H/Vn/oMf9lxFTp7KpJ9JRES2pcLPmVm1apW1Q6BScpZJMXtAYwxoUR3Pfr3fpHUfTnHA7I3n0bleNey5lKLdn+ajTefx0abzWPFqBH7an4hejQMwsEUNk342ERFVbBU+mSHbk6cyzwK5X+Ou49c4w4dWDvtvHABg69m7TGaIiOxMhR9mItvDSbtERGRJTGbI5JoGe+lde66l5XpL/rv7qt61u4ps/HXiJpRMtIiIKh0OM5HJuckdsfE/HTHtz1MY17U2OtX1g4ezDGuO3bDI53+8+Txe7VwLAJCcno0+S/ZqT+m+8fARxnerY5E4iIjIMpjMkFk0ru6JfyZ1strnP8zMxYpDSfh0a7zO9a1n7zCZISKqZDjMRBazf/pTmPtMY4t81pt/nNRLZADg1I00bD17x+j6spUqXH+QZYrQiIjIxJjMkMUEeblgRLtQvNwhTOf6H2MjTf5ZOy4kF3nv9V+OQq3WXXElhIBSpcaAL/fi7T9P6j3Tc/FudFq4E2dvpZk8ViIiKh8mM2Rx47vV1nnfpqYPejUKsGgM/9uXoH29dPslhM3YjC4Ld+LkjTSsPqI/t+fafU2vzD+nNb06arVA3NX7yMzJQ0JKJjfuIyKyIs6ZIYvzddPsFtx54U7U8HYBAHw1vCXO31bg6aV7LRLDR5vO43DiA52jEm6lZWtfCyEgkUj0nst73KOzbH8i5m48p3Pv6PtR8HXTP+SUiIjMiz0zZBXOMin2TX8Kf45tDwCQOkjQuLonqrlbLhko6swnAPjnzB3su5yC5YV6cABApdYs7f7jiP7mfa/9ctS0ARIRUamwZ4asRibVz6XXjmuPv07cgqeLDO+vP2OFqDTG/XZM+zrtUZ729eXkDMzacBZ3FNl6zxy99lDn/a3URzielIrejQPg4KDfy0NERKbBnhmqUGp4u2J8tzpwd644efaOCwU9ODvj72H5/kSkZimLfUYIgfYLdmD8imP43UAvTlESUzIx/rdjOHOTE42JiEqr4vyLQVSIb5WC4SaJBPCQCaTlWqd34+QN4xOLT7YULAvfc+keBrcOxuy/z0KpUiPYxxWeLjIMj9A9Yfz8bQV6L9kDANh0+jYSF/QtX+BERHaCyQxVSB3q+GJS97oID3BHVLgfNm/ejEkHKv6PqxACD7OU+Db2SqFrwMZTt/DzgWs6ZXPz1GhT0wc5eSr4ezhrE5nizFh7CunZeVg6tIXBCcpERPao4v/rQHZJIpFgSnQ9AIBSqTuk0yjIAz+ObIN287dbI7Ri/XzgGj7ccFbnWrZShd8OJumVnf33Ob1rxclWqrDykGbI6p1e4Qj2cS17oERElQjnzJDNWDSoCV5oE4y/xndAgKczLsztZe2Q9DyZyACaeTaHEh+Uq16VWuDPozd03gOanqAXf4jDqGWHIIQo6nGTyslTYfB3B/DZNv0dlomIrIE9M2Qz+jUNxLOtQrTvnWVSBHo643aa/sqiymT232ex9thNtAjx0l7LT1uS03Ow93IKAECRnQdPF5nOs0Xtl/Okf07fxq74ZLSVlhzPP6fv4FDCAxxKeIA3e9Qv7dcgIjIb9syQTftsUDMA0Nuf5uJHvRHs44Kejfz1nulU188isZXXzvhkpD1SYtm+RKQ9UmJX/D3tve3n7+Lvk7cwY+3pggee6JjJU6nR94u9ePXnI8hTqXGniKRv29k7eOO3Y/j9yA3MO6HJZu4qsvH97itIzcrVK69UqUuMPe2REgev3tc7NoKIyBzYM0M2rX0dP1z8qDecHB1Qc/om7XUnRwfsntYNEolE5zoAdKtfDXsupVg6VKONXna4yHsfbTqvd+39v87gw34N4fd4F+KztxQ4d1vza/gPcYhLeIDVr0eibZiP9hkhhM5mf/dzJDhxPRUz1p/D5eQMxF19gB9HtdH5HAcDPT0qtcDDrFztZz/79T5cuZeJhc81xeA2wcZ9cSIiIzGZIZvn5Gi4gzF/eGXduPbYdzkF8Xcz4OUiQ3iguyXDs5i/T97Cwav3MaJdKPo3C9K5F5egmbOz6lCSNpn5v63xOHD1vl49D7OUuJycAUDTO/QkBwPNPWrZIey5lIJlo9vAXe6IK/cyAQAbTt5iMkNEZsdkhiq9FiHeaBHibe0wLOJeeg4WxVzEku2XsG5ce/0CEuDXg9cgk0rw5c7LButQFRoayn+VmZOHV38+guiG/vB2ddJ7Jr+nq7jeJCIic2EyQ5XGf19qjbf/PInPhzQvseyxmdHYfyUFE1Yc17l+ZV4f1H53s5kitByVWqD/l/v0rq89dhNrj90s9tk3VpzQvhYC+OvETZy8nob9V+5j/xX9nhxzSc3KhYezjEdBEFGJOAGYKo3ohv44NjMaXetXK7GsTxUnPN20YChmRu9wnJ7VA9IS/uF0dSrFcp9KZtKqE/jfEwdu5itpOfiTk4Vz8wrep2bl4q8TN5GtVOk9d+6WAs3nxOC1X47o3cvIycPRaw+L/ezvd1/RO9WciCov9sxQpWLsrrgb/9MRZ2+lYXDr4FI9u2FCB0Qt2l3W8Cqdw4kPsfn07SLvF843Vh1KwvS1p/H18JYACg7zHNo2BPOfbaLz3M8HEgEA/57Xn7Pz/Df7ceFOOhYNboZnW9Yw+LnzNl/QlG1VAw0CPUr9fYjINrFnhuxa4+qeGNImpMhEJu7d7jrva3hz193CBn93AMv3JxZ5/1DiA/RbuheKbCWmP15GPu63Yzqnkq8/rjvsdSctG1vO3tG+F0LgXnqO9v2FO+kAgHWPn8vIyYMi2/DBn48M9PoQUeXDZIaoCMMjQuDv4ax9P7pDTTjLpFjzRiSWDm2Bs7N7Gl3niQ+iTRmiTTh9Mw1NZ20r8v4jpQq5eWpsO3sHKRk5aDd/u86p5D0X70abj//FmqM39JIWtVqg5ZwYNJ21zeBwlaFl5KVxOTkdOXlMhIhsBYeZiIqQ/++gh7MjFNl5GNulNgCgVagPWoUW82AxvAysBCJgyPcHcDwpFbWrVtG7d/GuZpn4m3+cBP4ouC4EkJ2nQu7jeTk3HmahTjV3nY36jiQ+QINAd+TkqeHoIIGrU8Ffef+eu4uwqlVQu6qbzudtPHULE1YcR9swH6x+PdKUX5OIzITJDNETWoR44XhSKp5vpdkfJe7dKKTnKFHN3Vmv7LyBTfDuutN618k4x5NSAUC7P01p7L2cgl6LC04a/+PoDcTfSceCZ5tqr3206Tw+3RqPnDw1pA4SXJnXBwBw8Op9vPKzZnJx4oK+2vInr6dqV7gdSij+PK3SHhWx6dRtTFx1HI2DPPDlsJYIcJcVW14IgWylGi52ONmcqKw4zET0hNWvR+LgjO5oHuwFAHBxkhpMZACgfW1f7etWod6IalANG//TUadMeIDuJn1Pnp9EZZf0IEv7+rvYq9gVfw8z1p7SKZPzeAWVSi2w84JmQvHJ66na+++tO60dUhrwlf5y9sLO3EzD/YwcXL2XgZZzY/DVzsv4bFs8Zhk4YDTf+BXHoFILnLyRhk4Ld+LpL/cjK6/oz5iw8jgafLAF1+5rEjseCUFUMvbMED1BJnVAgKfh5OVJNf0KhkXe7lkfEbV89coseK4pBn93AG/1qAcA2DalM+ISHmDiyuN6ZQHg/wY1w1t/nCxD5ARoTikvyujlh9G3SSCCvAp+f3+LS8LDrFzMH9hUr/yIH+Mwb2ATVPOQ4/ztdDzz1T5IHSToXNcPD7OU+HRrwcnhr3QKQw1vV2w8dQuZOXk4nPgQ3q76iWv83QzEyiR4Hprzs3bF34OTowM61fWDRCLBplOa1WE/H7gGPzc5PtlyAevGtbebjR+JyoLJDJGJFN7cbdVr7fDC9wfxft8GaB7shXOze8JRqukI9fdwRv9mQWhS3RPd/m+XTh0DW1RHr8YBRSYz3cOrIcTXFcv2JZrra1R6mwwsJd98+g62nLmjd33PpRR0WrgTADAlSpOMqtRCe1J5YYcTH2D6mtMG7z3pYLIDui3ag7rV3LTJ13cjWqFnowBtmV8PXtP2Kg357iAuftwbgGYYSqUW2p+nwnLyVBACkDs6FFmmPEo7tEZkaUxmiEyk8F/x7Wr5ImF+H+1f/Ib+UQnzq4Jzc3oiIycPbT/eDgCo5+8ON7kj1o1rj/TsPKiFwH9WHkd6tmZc4sdRbZCtVJUqmRkWEYIVcUnl/l72oqTRnHsZBaeOK1X6haf8XvretNRcCVJzH+HGw0faa6//clRn/k5OoQ0GcwttPjjku4M4lPgA1dzleLdPAzzTojrSs5VQZOeh1+LdyMjJw9NNg7DzQjJip3WFr5vuifL5Lt1Nh4uTtNTbDcTfScfwHw5iYve6eCmyZqm/K5ElcM4MkYk8+X+spfk/WFcnR535OOrHu8y1CPFG53pV0bV+NTg+sSuxs6x0E0PnDWyCeQObwF3O/2cxhV8Pmj8xNHSw55MOJWomJien52Dy7ycAAG0+/hcdFuxAenYehNAcOpqRk4dRyw4j7up9CCHw84FErD5yHQDwIDMX0Z/vRsdPdpY6tulrTyElIxcf/KWZH/QoV4XUrFyjvp9aLXDxbnqp5gFlK1Ul7jD90/5E7QaLZN+YzBCZSHmOEMpPOLrUq2qg3uIrdpc7Ys0buodKnp7VA4Cmd+Z0GfbDAWBwmTSZV0kHde6/YngIK1upNnj99M00DPn+IFYeuo4P/jqLt/88hVM3UvHfPVe1ZfIThiePnniS6okEpMXcbWg+J0Zn75/4O+lYti/B4J4/ALAo5iJ6fL4bH206X+xn3U57hPCZW3Q2VwSAh5m52iMxUrNy8eGGs/jgr7PIyNGfUV1SIkSVi00lMwsWLIBEIsHkyZOtHQqRVr9mQWgZ4oWmNbzKXMfe6U9h25TOaFzdU++eoYMWO9TRTDSe3b8Rjn0QjVah3vh1TARahXpjy+ROcHcu34qpFa9EYN7AJiUXJIsa9t+4Mj23/kTBLsv9v9yHb3Zd0b7/93wyjiU9RIOZW3SuF6bIVuLUjTTt+9HLDmkTqDOFrvdcvBuz/z6H8JlbDO7KnH9S+//2JUCtFhjxYxwmrdKdCL/lzG1Ezt8BAPjn8TwmIQRupj5Ci7kxiFoUCwDIyi1ImNRPJC6XkzPQ8dPd2H1b/8/OrdRH+C72CtIeGd412hg5eaoid5+2tjVHbyDuquUOhrU2m+l/Pnz4ML777js0baq/4oDImpYObVHuOjxdZEUu2ZYZSGZ+HNkG8XfS0aS6pzbZ6VjXDx3r+hmso10tHxy8qhmeeKdXOD7ZckHn/oW5vRA+c4v2ffs6fjqHQhalqrtc56gBMp8Xvj9g8HrN6ZtKfLa4PXNe/bngMM9PtlxA/QDNJoJxCQ/wn6fqwk3uiJd+PKTzTOEVY7/GXUP7Ovo/d/svp6BX48AiP/f8HQX2XNL0NE3sXhe1q7ohLUuJsb/q9sa8/edJ7L9yXzu/KH85fuGeoif/hExfcwrJ6TlYky7FgkLXYy/ew8j/ab7LqRtp+OrxOWFl1e3TXbiVlo0TH0RXqA0xT99I02wyCd19lCozm+iZycjIwPDhw/Hf//4X3t5cnkj25avhLeFbxQmfDWqmveYsk6JZsJfBXhtDfh0TgZ1vdUXigr54o2ttnXsf9muoMw9nQtdaAAAnx5L/ehjRLhRX5/XBG11r44eXWms3pSvOl8PKn/zZo/xk1NxeXn4ELy8/gu9ir6LDgh24cEeBE4X25XlS/OOzsp50Jy3b4PV8hZOR7p9peluOX3+oV271kRs6E6UBTY9I4ecL98vkqdQ4cq2gnp3x9zB51XGkZyu1iQwA7L5keAl/erYSyQr92H/YcxX/V2gpPgDcevwdjyTqx21qTw7zFafw/ktnb6UhT6Wu9MNuNtEzM378ePTt2xdRUVH46KOPii2bk5ODnJyC/1NUKBQAAKVSCaXStN2B+fWZul7SZe/t3DjQDQfe6QKJRFKuNqjh6WTw+cEtg3Suq9Vq7fsXI4Lxa9z1IusM9HCCSpWHqd01CZJalYdDM7oi5lwy3vvrnMFnouob7j2iiiftkVJnl2VDrtzLxEs/HsSYDjV1rs/6+xxq+bkg8vHeSzue2P+n/5e6GxRevpMGZV4xuwkW8tnWC3i2RXXte2WuEsrH+fiy/dd0yr72q2YYq5q7bs+JBPp/p+QoVWgyR7Oy8NvhzTHp91N4r099vNC6hnaez8GrKXi/TzgaBRWcxp6Vk1vkn02lSg21AK7dz0QVuSOqe7mU6jsWlng/E/2+OoDGQR5YPrIV5CUsAlCpCtqx7xd7ta//N7IlOhnoRSsPc/79bEydElHB07VVq1bh448/xuHDh+Hs7IyuXbuiefPmWLx4scHys2bNwuzZs/Wur1ixAq6uPPGYCAC+POuASwoHDK6lQgd/zV8Bkw5o/t+mVw01egdrhpiEAJaclSIhXb8HqFcNNXrWUBuc+HwrC/jkpOH/V1oSmYePj0uRnF2+/UrqeqhxLUOCXDX3PanIhtRSobWfwLRDJf+/s6NEIE+U/PvpAIG3m6mw4PHP2PNhKqgE0L6awOIzUtzM0q+jbVU1Dt3T7W18u2keqhea557/Z+BJn7bN04t/SWSetvyLdVSo5S7g6QTkd2juui2BvzOw4ooDFMqCeF4LVyEpQ2Lwz45KaIZLnpzz/794B5x8oKm4jZ8aL9YtGAJ+kAMkpkvQ3Fdo6ztxX4JlFw0nPJ+3y8MVhQQKJdDKr+Cf/zw1IJXofrZSDWQqAS+5ZuuC21lAjgrwcAL8SrevaLlkZWVh2LBhSEtLg4eHR7FlK3TPzPXr1zFp0iTExMTA2bl0LTdjxgxMnTpV+16hUCA4OBg9evQosTGMpVQqERMTg+joaMhk3KLeXNjOpte7t0BOnlpneGnSAc3J1rVr10KfxxvEAUCHbkq8teY0nmsRhIm/FxwVsPT1XkXWH38nHZ+c1Mzx+HZYc2QpVZj6h+YMqz59+mDJpb1IztZ0ha9+tS0G//eQXh3V3OVILmY+zvopPXD42kOMWn60NF+ZrOT3q1JcVHoCSCuxbGkSGQBQQ4IjOYEANL09fyZofo7XJRb9TGhIMA7du6lzbeEpR1yYHY2TN9IQ6usKHNhl8Fn3uq2BQyd0rnnWjwAOaH72pFXDMOdAErrU80PHOr7IUwmsO3DRYF3fX9DE+nTHFujZyF97PT07D9GL96JdmA8WD9GdG/rb7cPAA81Q1uEUB6yYVPBnr+5MzZ9biV8I3usTrnl95g6WXdQ91iNfs/ZdMWWRprfmlrQqrtzLxLCIYMz7Jx79mgSidU0vXLiTjllPN8BTn+/FjYePsHZsBP49fw9fHyxYBTe2cxgia/mgTYiH2f5+zh9ZKY0KncwcPXoUycnJaNmyYJKWSqXC7t278eWXXyInJwdSqW72KZfLIZfrbxIlk8nM9g+hOeumAmxn03J6Yr7i000CsPnMbQxtG6LTzlU9Zfjp5Qio1UKbzDg5OhT7e+EoK/irJbpxEKQOEnhXcYanq+b3cN6zTfHC9wcxrWd9tK1dFR/2a4jZf2uGpeYNbIJnWgTB1ckR3f5vFxJSCg6flEkl2g3rXJ2d0DU8AM2CvXTOWvp+RCu89gsTnIrk+PWSExlj/Xuh6GMrDPnj6E2D18M/jCnx2e0X9JfEF06ifzqg2YMo9mIKYi+WvAM0ACRnKJGSlYdJq07g1U618CAzB/czc7HpzB18/kILnTlrh56Yk2Poz97yA0loGOSF6Ib+cJAWPQz1w76C/ZLy2/DjzZq5QBtO3caGx8dp1Krqrp2r9Oy3+qvovt2dgG93JyC6QTU0kprn72dj6qvQyUz37t1x+rTuicSjR49GeHg43nnnHb1EhojKbtGgJujmegP+HoZ7QQt3P698tV2p683v+u4WXk17rV0tX8R/1AtyR82f4dEdwhDs7YrM3DwMaF4wF+KlyFBtkuNbxQlSB4m2tyZ/U8KGgR46yUzzEK9Sx2YMiUQz7Eb2J+b8XZPXOWfjOSzZfglpj5Q4lPAAzWoUbMswZfUJLB7SHDKpQ5HL5QHNxoWFvb3mFLCm+M8t7a7gJe0FlC/mfDJi4IjxQ0pV3GwqdDLj7u6Oxo0b61yrUqUKfH199a4TUflIJBIUt4BJIpHg/b4NoMjOQ6vQ4lcVehdaplrUTsj5iUy+qIb+emVGRtZE0xqeqFPVHS5OUny06Rx+PnBNMySgpZthyEvxPzllWVL+y8sRyMzNw+vs9bE7qVnmWXxQeK+bk4X269l06jZ2nE/G0ZlRetsoAJoVV01mbTNLTLaqQiczRFSxvNKpVqnK+Xs448thLVDFqXx/xTg4SNAq1Ef7fkbvBmgU5IFu9asZLD+jdzg8XWX49sVWGPtr0UnH4feitPuzdKlXFZeTM3Az9VGR5Z2kDkXu4WPIU+HVsONCyUcTEBXlkVKFv0/eMniPiYw+m9hnprBdu3YVuZKJiCqOp5sG6QwtmYKLkxRD2oSgWqGhsCbVvbSvX++iWSLes5E/Fj7fFJsndiqyrgMznsLbvepjyQvNiyyzb/pTGNy6Bjb8p4P2WkRYQXK18DnDm3gOalUDH/ZrqHd94lN1EOhZ/GKGd3qF281GZ1S8d9acLrlQBbH/inV3G2bPDBHZtCFtgqFSq9E2zFd7TSKRYHDrYADA6tcjkZmTh4krjyO90Bk+gZ4uGNe1DgCgUZCHtmdmRu9wxF68hwlP1UF1LxcsfL4ZCuvdOABxj3fUbVXT8HCbRCLB6A5h2HEhGXsupWBsl9qY8FQduMkd8Ubnmpj361b8cll3OGx4RAhqV3XD6Mf7tcx8uiHmbjS8Vw9RRfO/fdfQJTzAap/PZIaIbJrUQYIRkTWLvN+2UE9KUeY/2wRBXi4Y0iYYDQI9tD08hrzYLhRuzjJEhPkg2McVozvUxLJ9iTpl8qcJ/fxyW+SpBWTSgk5wR6kDGvvozyT++ImzsHo28i9zMlPNXQ4nRwe82aMepvx+skx1EBkj9lLpVnGZi80NMxERlcXojmEAgGgDE4193eSY1b8RGgSWvBeVo9QBz7eqgWAfzSTk8AB3vTL5J51LJBKdRCafsxRoHeqlff/kqecAUMPbFZO61zUYw5Soeqj1xKnmvRsHIGZKZ1yd1weH3ovC3neewsAWNfSeNRQvka1jzwwR2YVJ3euiU10/NDFwMnl5GFquXZqt31a+0haHrqUhxMdVmxg9qfAy+ZGRofjpgGar/klRdTEpqi6afLgV6Tl5qOVXBd+82KrEz+zXLAjzn20CxSMl2i/YgUBPZ8wd0Bj+Hs744+h1/HzgWol1EBlS0lwwc2MyQ0R2QeogQZuaJQ85GcvQ1jMOpezz7lDCOTmd6xXcn9W/EbqGV0OYb0GPzJYpnbF8XwJeKmaYLd/vr7VDxONzktzkjjj6fhTcnB21S+Sb1PBE4yBPxN9Nx3t9GuDGw0c4lPgAb/1R8jDVkxsXkv0Z1LJ6yYXMiMkMEVE5dK1fFQBQw9tFu2NqUXvrGKuGtysOvdcdHs4ySCQSvSXp1b1c8F5f/VVThU2JqoebqVl6c4d83fR3Sh/cJlj7OsTXFYcTiz+pO8DDGV+/2BItgr3w68Fr8HCRYdKqEyV8K6qMxnYJs+rnc84MEVE5BHq64NjMaOx4s6v2mimPvqzm7qxzhpaxJkXVxcLnm5UpwSpuw+OOdfzwx9hItAzxhkSimYRdePfmonSpVxUb/9NR+37TxI7FlC4db1f9be+HtqmBNlXVBkqTORiaG2ZJTGaIiMrJp4oTnBwdUKeaGwCUuENyZbBoSDODc33y99eZ98TqrHwLn28KN3nBoEDtqm7a1690LP3/3bep6Y1QX1esH98B26Z00bvv6iTFi3XUBhMdc/t7QvkTNDIOh5mIiExky6ROUKoEXJwq37lxk6Pq4nDiA+y7rNkczbGIiUGjO4ThuVY14OEsw7vr9Dd9y5/U/HqXWvB2dYKzTIpPn28KpUpgaNtg/LA3Qaf8+G61kfZIiV8PFjogcWoXbeKYL3ZaV5y+mYYJK44DKBjqU6n1+5c2/qcjPvjrDI4lpZby2xvHu0rpE6hejQKw5eydMn1ORJiPds8je8eeGSIiE3GUOlTKRAYAJkfVw2+vtMOo9jUxMjIUPlWciizr4az5x/z9vg0wLCIE7/QK1yszo3cDjH28n8+g1sEYFhGiMxS26rV2SFzQF9N6huOjZ5pg2eg2CPJ0xqrX2uklMgAQ6lsFTzcNQlQDzdL7F1prlqWrCi03+3xIM+ye1g2Nq3viuxGtdZ7v3ywIIYV6msY+sdfQgOZBOu8NLfHPl6cq3YmkJz/ogcnRBcvv143TX6JfFCdHBywd2gKDW9dA28cT24N9XIos71BolFHqoD/k2LRG8av8lo9ug6ru+vOsAGBcQ5XB65bEZIaIiEptVv9GmD2gdAf9vtKpFuYNbIJhbUMQ7ONi1DDSk7rVr4b9M7qjXS3fYsv996VWODu7p/YwUnWhnpmBLWog5PH1qu5yxL3bHQDg5ybHF0Nb4PuXNMvb+zYJxPTe4Vj9eiT6NQvCyQ96YMkLLbT7EP0zqRP++5JuMtQ82Ev7Oq/QZx55P6rIWD1dZQgotPy+RYg3hrYNKfb75RvRLhTVPJyx8PlmWD02EokL+iKm0HBb+9oF7fTv1M469e59p5vePkXNg70wo7cm6ezbJFDv86QOErgaSNS/Htoc9T2tf5w8h5mIiMggLxfTzDfxdJVh97RuJlvlVRyJRIIqckcolZoTqYvrJPH3cMb5Ob20PRXhAR44PauHdk5P2zAfnVVgf43vgIdZuTr7/+T7aXRbfL/nCp5pXh3OsoJ+At8qTpg3sInOkNv3I1ppe5e8XJ3w94SO2mfe7ROO3RfvoVNdPyx4ril2xidj9LLDep9noHNFZ6L4gmeb4uLddLg4SVGnmu5GiYGeLtg2uTM6frITdxTZADT7Jb3epTZGtq8JZ5kUryQ9xGfbLmLv5eJ39lUZ2mjJCpjMEBGRQU+FV8OIdqFoUsIQRGlYIpExpG1Nb+y9fL/IIZInhwXdnYtO4JwcHXQSmTEdw/Dj3gTtae3TehYMp03rWR8eLpol9cMiQnSSmR6NdM8wKty+7s4y7H2nIPFrWGhX6ibVPfEgMxc3Ux+ht4HeEwBY8WoEHmYqEeLrqu2FAgp2pc7nKHXAwXe747lv9uPotYcY9HhYLj8hahHijV9fidCeLg8Y3iBSMJkhIqKKzMFBgrnPlG5IqaL6v+ca47fDN7UHj5rS+30bYES7UO2QVmHju9Ux+Iy7c8n/7BZO/Pw9nPHv1C44dSMVUQ394eggwe20bJ1VYIW1r214I8YJT9VBzLm7OnsJAZrNFB9k5aKae/E7+Nb0rYI3e9TDpFUn8EKbYKw6fB2AZoJ1RZivwmSGiIgqjFBfV1y7n2WyYyd83eR4s0d9k9T1JIlEgpp+VUouCOC3VyLw0abzmP+s4SXrxalTzU1n0nNRiUxx/D2ccWDGU3o9ZI5Sh2ITmZgpnfEwS4ngx8duRIT5wt9Drk1mnuzxsRYmM0REVGFsn9qlUi5v71DHD/9M6mTVGMoy1FfXX3e+TcDjM5hGd6iJo9ceonuDath+3SThlQuTGSIiqjAcpQ5wrFx5TKX0Yb9GAKCdaG1tFWGoi4iIiKjMmMwQERGRTWMyQ0RERDaNyQwRERHZNCYzREREZNOYzBAREZFNYzJDRERENo3JDBEREdk0JjNERERk05jMEBERkU1jMkNEREQ2jckMERER2TQmM0RERGTTmMwQERGRTXO0dgDmJoQAACgUCpPXrVQqkZWVBYVCAZlMZvL6SYPtbBlsZ8tgO1sG29kyzNnO+f9u5/87XpxKn8ykp6cDAIKDg60cCRERERkrPT0dnp6exZaRiNKkPDZMrVbj1q1bcHd3h0QiMWndCoUCwcHBuH79Ojw8PExaNxVgO1sG29ky2M6WwXa2DHO2sxAC6enpCAoKgoND8bNiKn3PjIODA2rUqGHWz/Dw8OAfFgtgO1sG29ky2M6WwXa2DHO1c0k9Mvk4AZiIiIhsGpMZIiIismlMZspBLpfjww8/hFwut3YolRrb2TLYzpbBdrYMtrNlVJR2rvQTgImIiKhyY88MERER2TQmM0RERGTTmMwQERGRTWMyQ0RERDaNyUwZffXVV6hZsyacnZ0RERGBQ4cOWTukCm337t3o168fgoKCIJFIsH79ep37Qgh88MEHCAwMhIuLC6KionDp0iWdMg8ePMDw4cPh4eEBLy8vjBkzBhkZGTplTp06hU6dOsHZ2RnBwcFYuHChub9ahTF//ny0adMG7u7uqFatGp555hnEx8frlMnOzsb48ePh6+sLNzc3PPfcc7h7965OmaSkJPTt2xeurq6oVq0apk2bhry8PJ0yu3btQsuWLSGXy1GnTh0sX77c3F+vQvnmm2/QtGlT7UZhkZGR+Oeff7T32c6mt2DBAkgkEkyePFl7je1sGrNmzYJEItH5FR4err1vE+0syGirVq0STk5O4n//+584e/asePXVV4WXl5e4e/eutUOrsDZv3izee+89sXbtWgFArFu3Tuf+ggULhKenp1i/fr04efKk6N+/vwgLCxOPHj3SlunVq5do1qyZOHjwoNizZ4+oU6eOGDp0qPZ+Wlqa8Pf3F8OHDxdnzpwRK1euFC4uLuK7776z1Ne0qp49e4ply5aJM2fOiBMnTog+ffqIkJAQkZGRoS0zduxYERwcLLZv3y6OHDki2rVrJ9q3b6+9n5eXJxo3biyioqLE8ePHxebNm4Wfn5+YMWOGtszVq1eFq6urmDp1qjh37pxYunSpkEqlYsuWLRb9vta0YcMGsWnTJnHx4kURHx8v3n33XSGTycSZM2eEEGxnUzt06JCoWbOmaNq0qZg0aZL2OtvZND788EPRqFEjcfv2be2ve/fuae/bQjszmSmDtm3bivHjx2vfq1QqERQUJObPn2/FqGzHk8mMWq0WAQEB4tNPP9VeS01NFXK5XKxcuVIIIcS5c+cEAHH48GFtmX/++UdIJBJx8+ZNIYQQX3/9tfD29hY5OTnaMu+8846oX7++mb9RxZScnCwAiNjYWCGEpk1lMpn4448/tGXOnz8vAIgDBw4IITRJp4ODg7hz5462zDfffCM8PDy07fr222+LRo0a6XzWkCFDRM+ePc39lSo0b29v8cMPP7CdTSw9PV3UrVtXxMTEiC5dumiTGbaz6Xz44YeiWbNmBu/ZSjtzmMlIubm5OHr0KKKiorTXHBwcEBUVhQMHDlgxMtuVkJCAO3fu6LSpp6cnIiIitG164MABeHl5oXXr1toyUVFRcHBwQFxcnLZM586d4eTkpC3Ts2dPxMfH4+HDhxb6NhVHWloaAMDHxwcAcPToUSiVSp12Dg8PR0hIiE47N2nSBP7+/toyPXv2hEKhwNmzZ7VlCteRX8Zef/5VKhVWrVqFzMxMREZGsp1NbPz48ejbt69eW7CdTevSpUsICgpCrVq1MHz4cCQlJQGwnXZmMmOklJQUqFQqnd80APD398edO3esFJVty2+34tr0zp07qFatms59R0dH+Pj46JQxVEfhz7AXarUakydPRocOHdC4cWMAmjZwcnKCl5eXTtkn27mkNiyqjEKhwKNHj8zxdSqk06dPw83NDXK5HGPHjsW6devQsGFDtrMJrVq1CseOHcP8+fP17rGdTSciIgLLly/Hli1b8M033yAhIQGdOnVCenq6zbRzpT81m8gejR8/HmfOnMHevXutHUqlVb9+fZw4cQJpaWn4888/MXLkSMTGxlo7rErj+vXrmDRpEmJiYuDs7GztcCq13r17a183bdoUERERCA0NxerVq+Hi4mLFyEqPPTNG8vPzg1Qq1ZvJfffuXQQEBFgpKtuW327FtWlAQACSk5N17ufl5eHBgwc6ZQzVUfgz7MGECROwceNG7Ny5EzVq1NBeDwgIQG5uLlJTU3XKP9nOJbVhUWU8PDxs5i8+U3ByckKdOnXQqlUrzJ8/H82aNcOSJUvYziZy9OhRJCcno2XLlnB0dISjoyNiY2PxxRdfwNHREf7+/mxnM/Hy8kK9evVw+fJlm/l5ZjJjJCcnJ7Rq1Qrbt2/XXlOr1di+fTsiIyOtGJntCgsLQ0BAgE6bKhQKxMXFads0MjISqampOHr0qLbMjh07oFarERERoS2ze/duKJVKbZmYmBjUr18f3t7eFvo21iOEwIQJE7Bu3Trs2LEDYWFhOvdbtWoFmUym087x8fFISkrSaefTp0/rJI4xMTHw8PBAw4YNtWUK15Ffxt5//tVqNXJyctjOJtK9e3ecPn0aJ06c0P5q3bo1hg8frn3NdjaPjIwMXLlyBYGBgbbz82ySacR2ZtWqVUIul4vly5eLc+fOiddee014eXnpzOQmXenp6eL48ePi+PHjAoBYtGiROH78uLh27ZoQQrM028vLS/z111/i1KlTYsCAAQaXZrdo0ULExcWJvXv3irp16+oszU5NTRX+/v5ixIgR4syZM2LVqlXC1dXVbpZmv/HGG8LT01Ps2rVLZ4llVlaWtszYsWNFSEiI2LFjhzhy5IiIjIwUkZGR2vv5Syx79OghTpw4IbZs2SKqVq1qcInltGnTxPnz58VXX31ld0tZp0+fLmJjY0VCQoI4deqUmD59upBIJGLbtm1CCLazuRRezSQE29lU3nzzTbFr1y6RkJAg9u3bJ6KiooSfn59ITk4WQthGOzOZKaOlS5eKkJAQ4eTkJNq2bSsOHjxo7ZAqtJ07dwoAer9GjhwphNAsz545c6bw9/cXcrlcdO/eXcTHx+vUcf/+fTF06FDh5uYmPDw8xOjRo0V6erpOmZMnT4qOHTsKuVwuqlevLhYsWGCpr2h1htoXgFi2bJm2zKNHj8S4ceOEt7e3cHV1FQMHDhS3b9/WqScxMVH07t1buLi4CD8/P/Hmm28KpVKpU2bnzp2iefPmwsnJSdSqVUvnM+zByy+/LEJDQ4WTk5OoWrWq6N69uzaREYLtbC5PJjNsZ9MYMmSICAwMFE5OTqJ69epiyJAh4vLly9r7ttDOEiGEME0fDxEREZHlcc4MERER2TQmM0RERGTTmMwQERGRTWMyQ0RERDaNyQwRERHZNCYzREREZNOYzBAREZFNYzJDRERENo3JDBFZTdeuXTF58mRrh0FENo7JDBEVqahkY/ny5fDy8rJ4PLt27YJEItE7wdfUmGQR2RYmM0RERGTTmMwQUbmNGjUKzzzzDGbPno2qVavCw8MDY8eORW5urrZMZmYmXnrpJbi5uSEwMBCfffaZXj2//PILWrduDXd3dwQEBGDYsGFITk4GACQmJqJbt24AAG9vb0gkEowaNQoAoFarMX/+fISFhcHFxQXNmjXDn3/+WWzMX3/9NerWrQtnZ2f4+/vj+eef136X2NhYLFmyBBKJBBKJBImJiQCAM2fOoHfv3nBzc4O/vz9GjBiBlJQUbZ1du3bFhAkTMGHCBHh6esLPzw8zZ84Ej8AjMi8mM0RkEtu3b8f58+exa9curFy5EmvXrsXs2bO196dNm4bY2Fj89ddf2LZtG3bt2oVjx47p1KFUKjF37lycPHkS69evR2JiojZhCQ4Oxpo1awAA8fHxuH37NpYsWQIAmD9/Pn7++Wd8++23OHv2LKZMmYIXX3wRsbGxBmM9cuQIJk6ciDlz5iA+Ph5btmxB586dAQBLlixBZGQkXn31Vdy+fRu3b99GcHAwUlNT8dRTT6FFixY4cuQItmzZgrt372Lw4ME6df/0009wdHTEoUOHsGTJEixatAg//PCDSdqYiIpgsvO3iajS6dKli5g0aZLe9WXLlglPT0/t+5EjRwofHx+RmZmpvfbNN98INzc3oVKpRHp6unBychKrV6/W3r9//75wcXExWH++w4cPCwAiPT1dCCHEzp07BQDx8OFDbZns7Gzh6uoq9u/fr/PsmDFjxNChQw3Wu2bNGuHh4SEUCkWpv/fcuXNFjx49dK5dv35dABDx8fHa5xo0aCDUarW2zDvvvCMaNGhQ5HckovJjzwwRmUSzZs3g6uqqfR8ZGYmMjAxcv34dV65cQW5uLiIiIrT3fXx8UL9+fZ06jh49in79+iEkJATu7u7o0qULACApKanIz718+TKysrIQHR0NNzc37a+ff/4ZV65cMfhMdHQ0QkNDUatWLYwYMQK//fYbsrKyiv1+J0+exM6dO3U+Izw8HAB0Pqddu3aQSCQ67XDp0iWoVKpi6yeisnO0dgBEVHF5eHggLS1N73pqaio8PT1N+lmZmZno2bMnevbsid9++w1Vq1ZFUlISevbsqTP35kkZGRkAgE2bNqF69eo69+RyucFn3N3dcezYMezatQvbtm3DBx98gFmzZuHw4cNFrtLKyMhAv3798Mknn+jdCwwMLOW3JCJzYDJDREWqX78+tm3bpnf92LFjqFevns61kydP4tGjR3BxcQEAHDx4EG5ubggODoavry9kMhni4uIQEhICAHj48CEuXryo7X25cOEC7t+/jwULFiA4OBiAZm5LYU5OTgCg08vRsGFDyOVyJCUlaesqDUdHR0RFRSEqKgoffvghvLy8sGPHDjz77LNwcnLS60lp2bIl1qxZg5o1a8LRsei/OuPi4nTeHzx4EHXr1oVUKi11bERkHA4zEVGR3njjDVy8eBETJ07EqVOnEB8fj0WLFmHlypV48803dcrm5uZizJgxOHfuHDZv3owPP/wQEyZMgIODA9zc3DBmzBhMmzYNO3bswJkzZzBq1Cg4OBT8FRQSEgInJycsXboUV69exYYNGzB37lydzwgNDYVEIsHGjRtx7949ZGRkwN3dHW+99RamTJmCn376CVeuXMGxY8ewdOlS/PTTTwa/18aNG/HFF1/gxIkTuHbtGn7++Weo1WrtsFfNmjURFxeHxMREpKSkQK1WY/z48Xjw4AGGDh2Kw4cP48qVK9i6dStGjx6tk/gkJSVh6tSpiI+Px8qVK7F06VJMmjTJVL8lRGSItSftEFHFdujQIREdHS2qVq0qPD09RUREhFi3bp1OmZEjR4oBAwaIDz74QPj6+go3Nzfx6quviuzsbG2Z9PR08eKLLwpXV1fh7+8vFi5cqDfRdsWKFaJmzZpCLpeLyMhIsWHDBgFAHD9+XFtmzpw5IiAgQEgkEjFy5EghhBBqtVosXrxY1K9fX8hkMlG1alXRs2dPERsba/A77dmzR3Tp0kV4e3sLFxcX0bRpU/H7779r78fHx4t27doJFxcXAUAkJCQIIYS4ePGiGDhwoPDy8hIuLi4iPDxcTJ48WTvht0uXLmLcuHFi7NixwsPDQ3h7e4t3331XZ0IwEZmeRAhugEBE5TNq1CikpqZi/fr11g7Fqrp27YrmzZtj8eLF1g6FyK5wmImIiIhsGpMZIiIismkcZiIiIiKbxp4ZIiIismlMZoiIiMimMZkhIiIim8ZkhoiIiGwakxkiIiKyaUxmiIiIyKYxmSEiIiKbxmSGiIiIbNr/A0/dLtfsVwwVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "losses_ = [l for (l,s) in losses]\n",
        "plt.plot(losses_)\n",
        "plt.grid()\n",
        "plt.xlabel(\"Update step\")\n",
        "plt.ylabel(\"Training loss\")\n",
        "plt.show()\n",
        "\n",
        "eval_losses_ = [l for (l,s) in eval_losses]\n",
        "eval_steps = [s for (l,s) in eval_losses]\n",
        "plt.plot(eval_steps, eval_losses_)\n",
        "plt.grid()\n",
        "plt.xlabel(\"Update step\")\n",
        "plt.ylabel(\"Validation loss\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aaee85e870cf47d59fe68bfd2e5c6367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd6a722354fc45a9aba111d3e4f81bcc",
              "IPY_MODEL_e4f2409b9c5b4e03a2d0dacb877bd1a8",
              "IPY_MODEL_ac7fd2f1553f4f05a95483aca960a65d"
            ],
            "layout": "IPY_MODEL_5cadb7c3923c4f78be514e744c2a9019"
          }
        },
        "cd6a722354fc45a9aba111d3e4f81bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53cccf8246d94244b870b517ea30406f",
            "placeholder": "​",
            "style": "IPY_MODEL_a7b67c1bdddf414892c966bfff2c49bd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e4f2409b9c5b4e03a2d0dacb877bd1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed65d7e9ed045c1a95489f486ac6b3b",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_017c582da00441c3b9e20e28b792278d",
            "value": 26
          }
        },
        "ac7fd2f1553f4f05a95483aca960a65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9df45a7573fe414d88a6fedbe5b17e14",
            "placeholder": "​",
            "style": "IPY_MODEL_6268c346f73f4b1e8be7b08beaf01907",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.38kB/s]"
          }
        },
        "5cadb7c3923c4f78be514e744c2a9019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53cccf8246d94244b870b517ea30406f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b67c1bdddf414892c966bfff2c49bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ed65d7e9ed045c1a95489f486ac6b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "017c582da00441c3b9e20e28b792278d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9df45a7573fe414d88a6fedbe5b17e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6268c346f73f4b1e8be7b08beaf01907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4227aa820574412fa35b865904c3bc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3023c8a4ad3340e0af7fb880432a7060",
              "IPY_MODEL_caec2fe11b18487aab358e3586cebaf9",
              "IPY_MODEL_85334869b60d46ccb341584806ca64f2"
            ],
            "layout": "IPY_MODEL_e3658c5f4bc74e79aa44faa6e4d93feb"
          }
        },
        "3023c8a4ad3340e0af7fb880432a7060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a213e82c4260472f899bb5e3784694ca",
            "placeholder": "​",
            "style": "IPY_MODEL_345b6b53dd99431792e107736c601563",
            "value": "config.json: 100%"
          }
        },
        "caec2fe11b18487aab358e3586cebaf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76dcd1614e4e4fd48c44ae943ae95ac9",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19abd8a981c341f7a379445d47c00678",
            "value": 665
          }
        },
        "85334869b60d46ccb341584806ca64f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97378dffec5742bcba643da722311d45",
            "placeholder": "​",
            "style": "IPY_MODEL_b5dc4ebe18014e45abf6af4ce5377740",
            "value": " 665/665 [00:00&lt;00:00, 82.7kB/s]"
          }
        },
        "e3658c5f4bc74e79aa44faa6e4d93feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a213e82c4260472f899bb5e3784694ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345b6b53dd99431792e107736c601563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76dcd1614e4e4fd48c44ae943ae95ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19abd8a981c341f7a379445d47c00678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97378dffec5742bcba643da722311d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5dc4ebe18014e45abf6af4ce5377740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f12d07ad22ab481397db0e8736579884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fedb2ad2aeb84cfbb8557e62dc29a0d8",
              "IPY_MODEL_b183060e48794cd8afc2f1696c99d5bd",
              "IPY_MODEL_5f2d6db1d8044b52b998b29edc868b6a"
            ],
            "layout": "IPY_MODEL_3d46743637a84f3f893390707e28b04d"
          }
        },
        "fedb2ad2aeb84cfbb8557e62dc29a0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806a074ef3884c1ab673bf5c9643fd1e",
            "placeholder": "​",
            "style": "IPY_MODEL_b5a2b165736f4bccb16645eca8571cd2",
            "value": "vocab.json: 100%"
          }
        },
        "b183060e48794cd8afc2f1696c99d5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d534a87acb3e4bc4a8f239b2c5c8b58d",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15a1c9e763ec4e01a423b6d1ad32aa1d",
            "value": 1042301
          }
        },
        "5f2d6db1d8044b52b998b29edc868b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13af8dbc8dff45f28ced8d4b2565d426",
            "placeholder": "​",
            "style": "IPY_MODEL_f7050cb4d71c47b5aaacb5fbe7f638cf",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "3d46743637a84f3f893390707e28b04d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806a074ef3884c1ab673bf5c9643fd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a2b165736f4bccb16645eca8571cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d534a87acb3e4bc4a8f239b2c5c8b58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a1c9e763ec4e01a423b6d1ad32aa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13af8dbc8dff45f28ced8d4b2565d426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7050cb4d71c47b5aaacb5fbe7f638cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad3f990645a14c27971468382cc1248e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_deb828d5d05848df966d7079a5b345ca",
              "IPY_MODEL_d2bcdce069584f35b8afd9ba5ac02d35",
              "IPY_MODEL_9cacdf8a2165429aa20906f7e8fae7f8"
            ],
            "layout": "IPY_MODEL_e98514dbbe4747e7a20fc115260e9fca"
          }
        },
        "deb828d5d05848df966d7079a5b345ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0cd9e4eb4945908b5ce35328457134",
            "placeholder": "​",
            "style": "IPY_MODEL_4fb934f1ef3c43a781b8daf123f820c1",
            "value": "merges.txt: 100%"
          }
        },
        "d2bcdce069584f35b8afd9ba5ac02d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7c7177d4644b6889e9284e6583047a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b30a44b9188540f1b676f74200fe9ae8",
            "value": 456318
          }
        },
        "9cacdf8a2165429aa20906f7e8fae7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3213f3114e124e1dab849055dfb99236",
            "placeholder": "​",
            "style": "IPY_MODEL_9800d01ca55a429993fca5fe3f46274a",
            "value": " 456k/456k [00:00&lt;00:00, 13.7MB/s]"
          }
        },
        "e98514dbbe4747e7a20fc115260e9fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0cd9e4eb4945908b5ce35328457134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb934f1ef3c43a781b8daf123f820c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a7c7177d4644b6889e9284e6583047a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b30a44b9188540f1b676f74200fe9ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3213f3114e124e1dab849055dfb99236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9800d01ca55a429993fca5fe3f46274a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa16ac0dd4be4d609ddf5a685cbaf7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b167b2d660a64fcd93830558319b8825",
              "IPY_MODEL_597d9713266448e8911ba6774914f5cd",
              "IPY_MODEL_9de1f861da034d05bce1e3e4b0134b12"
            ],
            "layout": "IPY_MODEL_6c29bd62fbcb4c62b84211f6b3478f17"
          }
        },
        "b167b2d660a64fcd93830558319b8825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b3d2420ade4a0cbcaac25d07a68c65",
            "placeholder": "​",
            "style": "IPY_MODEL_0c0210abcc4c4363a475784b5d44d9a7",
            "value": "tokenizer.json: 100%"
          }
        },
        "597d9713266448e8911ba6774914f5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f11c8f993e1a44ae852c58c5215b1e90",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_953cd0368abb4df7bd8ae3ec58325cdb",
            "value": 1355256
          }
        },
        "9de1f861da034d05bce1e3e4b0134b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fdf9926313f44889ff76983fa6cb7d1",
            "placeholder": "​",
            "style": "IPY_MODEL_e4686d632d444410bdef83cfe0512da6",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 7.38MB/s]"
          }
        },
        "6c29bd62fbcb4c62b84211f6b3478f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b3d2420ade4a0cbcaac25d07a68c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0210abcc4c4363a475784b5d44d9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f11c8f993e1a44ae852c58c5215b1e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953cd0368abb4df7bd8ae3ec58325cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fdf9926313f44889ff76983fa6cb7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4686d632d444410bdef83cfe0512da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccb3142c6148411ca038b1ab24d149bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ad3ccbaabb042639b5a9dea1b705dcb",
              "IPY_MODEL_20f8ba60976a4da69b9f8ecdbbfee1d7",
              "IPY_MODEL_9887782b6f2c409abfeae5594be766ca"
            ],
            "layout": "IPY_MODEL_9132e199de5f4161829aa035d83ff25c"
          }
        },
        "5ad3ccbaabb042639b5a9dea1b705dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3dfcb533f74fa78d6d295e992a8043",
            "placeholder": "​",
            "style": "IPY_MODEL_ed784516b3fd49279412daa03bd17057",
            "value": "README.md: "
          }
        },
        "20f8ba60976a4da69b9f8ecdbbfee1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4d82dc90a846ff9fc78af4bbcabcb7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac93e37112a45eb8f25b855ea3f3f11",
            "value": 1
          }
        },
        "9887782b6f2c409abfeae5594be766ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d4e82df8b34308bb0619b56bf509da",
            "placeholder": "​",
            "style": "IPY_MODEL_7d7931a0b03c4d1bb5e141ba2b17a177",
            "value": " 41.1k/? [00:00&lt;00:00, 4.12MB/s]"
          }
        },
        "9132e199de5f4161829aa035d83ff25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3dfcb533f74fa78d6d295e992a8043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed784516b3fd49279412daa03bd17057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a4d82dc90a846ff9fc78af4bbcabcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2ac93e37112a45eb8f25b855ea3f3f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67d4e82df8b34308bb0619b56bf509da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7931a0b03c4d1bb5e141ba2b17a177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f98ed06f4df430d9b43a322345166b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05d2475126b245f58415913daadac6e4",
              "IPY_MODEL_3e59e9fff8784e90bbc6d7395f50318c",
              "IPY_MODEL_c1d8ca0f36e947feb2b67a7d1a5b4fe1"
            ],
            "layout": "IPY_MODEL_9f65cae127454e76b6f07a1de0cd345d"
          }
        },
        "05d2475126b245f58415913daadac6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fc20630c5f49d08294accfd2b3ed63",
            "placeholder": "​",
            "style": "IPY_MODEL_7040424a42594d30a297f63f9018eb70",
            "value": "Resolving data files: 100%"
          }
        },
        "3e59e9fff8784e90bbc6d7395f50318c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ec16b8cfb04af2bfffa337643d06d6",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7283d05676fb47658a70bb53f5950c48",
            "value": 1024
          }
        },
        "c1d8ca0f36e947feb2b67a7d1a5b4fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5095556c634b0888e9c657ab96455f",
            "placeholder": "​",
            "style": "IPY_MODEL_e7a2b9f885024bb588fc691837b63b54",
            "value": " 1024/1024 [00:04&lt;00:00,  2.68it/s]"
          }
        },
        "9f65cae127454e76b6f07a1de0cd345d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43fc20630c5f49d08294accfd2b3ed63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7040424a42594d30a297f63f9018eb70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ec16b8cfb04af2bfffa337643d06d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7283d05676fb47658a70bb53f5950c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd5095556c634b0888e9c657ab96455f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a2b9f885024bb588fc691837b63b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a921fb569cb422aa8f8426abb7aaec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8e4aae2a5404b108b89a9a20dc5c981",
              "IPY_MODEL_71ecbfdb44674eaabb5f71bb16279834",
              "IPY_MODEL_21c28abb0681465ab9babba2f33500d6"
            ],
            "layout": "IPY_MODEL_bd4096919b7e4dc4aed8292e04b212e6"
          }
        },
        "e8e4aae2a5404b108b89a9a20dc5c981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9713c7f9b5684221b124330d6a8380bb",
            "placeholder": "​",
            "style": "IPY_MODEL_40c7d1ac09754bafb7a49c0f84d86008",
            "value": "Resolving data files: 100%"
          }
        },
        "71ecbfdb44674eaabb5f71bb16279834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90729b4f86f4b8c87398feff4dc758f",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76db9a5dc7d048e0a8c0bac28d6840df",
            "value": 1024
          }
        },
        "21c28abb0681465ab9babba2f33500d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41afe3bb0673490eb66b65d69cd7ddf5",
            "placeholder": "​",
            "style": "IPY_MODEL_466c587a3272436885f4b725d69ef631",
            "value": " 1024/1024 [00:00&lt;00:00, 19313.90it/s]"
          }
        },
        "bd4096919b7e4dc4aed8292e04b212e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9713c7f9b5684221b124330d6a8380bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c7d1ac09754bafb7a49c0f84d86008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a90729b4f86f4b8c87398feff4dc758f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76db9a5dc7d048e0a8c0bac28d6840df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41afe3bb0673490eb66b65d69cd7ddf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466c587a3272436885f4b725d69ef631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c09bb648daca48b2a223ea788bf70c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18504d4b21f2428d94ba9c82c9a9a5fd",
              "IPY_MODEL_dd6fccd8e72e4c7baaa52492ceef2915",
              "IPY_MODEL_c3e13d6e8b4d46ca8c2e93b344de3214"
            ],
            "layout": "IPY_MODEL_29201687179f443ba5c9e20f70e5fa6f"
          }
        },
        "18504d4b21f2428d94ba9c82c9a9a5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cc5908329948559f8e8cdd5c9c0efe",
            "placeholder": "​",
            "style": "IPY_MODEL_d2f8d68ca1d946338188047f76b00a3e",
            "value": "Resolving data files: 100%"
          }
        },
        "dd6fccd8e72e4c7baaa52492ceef2915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed7bf690fe964b9e8094522e8b93ab80",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87784bba62d0453f9eb68b3bf2414fec",
            "value": 1024
          }
        },
        "c3e13d6e8b4d46ca8c2e93b344de3214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9cb516e3cf4e3e83202a9841205eec",
            "placeholder": "​",
            "style": "IPY_MODEL_20ff0ad5c659495a9ede2e0d166cde5e",
            "value": " 1024/1024 [00:00&lt;00:00, 38251.61it/s]"
          }
        },
        "29201687179f443ba5c9e20f70e5fa6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cc5908329948559f8e8cdd5c9c0efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f8d68ca1d946338188047f76b00a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed7bf690fe964b9e8094522e8b93ab80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87784bba62d0453f9eb68b3bf2414fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce9cb516e3cf4e3e83202a9841205eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ff0ad5c659495a9ede2e0d166cde5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cb2454931e943d5b2c26754797409e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22f54e8bf37749ecac65acc58fce09f0",
              "IPY_MODEL_ae80531f0e0f4d7099f0f2f969fb749f",
              "IPY_MODEL_8db936b3803644e68739e96e3813fc81"
            ],
            "layout": "IPY_MODEL_c83285f1f4de42cf8259bc4abd4c9550"
          }
        },
        "22f54e8bf37749ecac65acc58fce09f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff6a75b90334d8eb7c16f343c4a4d1b",
            "placeholder": "​",
            "style": "IPY_MODEL_86b387f390e84798adb088702906748f",
            "value": "Resolving data files: 100%"
          }
        },
        "ae80531f0e0f4d7099f0f2f969fb749f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca896404845947debedd701c8ab32aad",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26e936723f5e4c1ab7b1491594f582a2",
            "value": 1024
          }
        },
        "8db936b3803644e68739e96e3813fc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e4902a9529457cb378934505ee167d",
            "placeholder": "​",
            "style": "IPY_MODEL_acba8a786c294e0086941d56e39559e7",
            "value": " 1024/1024 [00:00&lt;00:00, 21276.22it/s]"
          }
        },
        "c83285f1f4de42cf8259bc4abd4c9550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff6a75b90334d8eb7c16f343c4a4d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b387f390e84798adb088702906748f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca896404845947debedd701c8ab32aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e936723f5e4c1ab7b1491594f582a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92e4902a9529457cb378934505ee167d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acba8a786c294e0086941d56e39559e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}