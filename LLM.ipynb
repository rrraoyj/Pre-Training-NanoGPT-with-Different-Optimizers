{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "unlikely-plasma",
      "metadata": {
        "id": "unlikely-plasma"
      },
      "source": [
        "# Introduction to Large Language Models\n",
        "\n",
        "(Pytorch nanoGPT code is from: https://github.com/karpathy/nanoGPT/blob/master/model.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "senior-jesus",
      "metadata": {
        "id": "senior-jesus"
      },
      "source": [
        "## Intro\n",
        "\n",
        "This chapter serves as an introduction to the basic concepts in Large Language Model (LLM) architectures and training. In the first section we will introduce the basic blocks and mechanisms of the transformer architecture, which most modern LLMs are based on. Next, we will introduce the basic ideas involved in the training of the LLMs. In addition, this notebook is intended to provide a runnable code implementation of the nanoGPT model and a basic training pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quality-allocation",
      "metadata": {
        "id": "quality-allocation"
      },
      "source": [
        "## Transformer Architecture\n",
        "\n",
        "Most modern LLMs are based on the *decoder-only transformer* model architecture. Essentially, the decoder-only transformer (we will refer to it simply as transformer) is a deep learning model built from multiple *transformer layers* as well as an *embedding* and a *Language Model (LM) Head* layer in the input and output, respectively.\n",
        "\n",
        "The transformer model takes as input sequences of *tokens* and outputs a probability distribution over possible next tokens for each input position. Those probability distributions are then used to generate the output text of the model.\n",
        "\n",
        "Next we will describe in detail its components and provide the corresponding codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fluid-tackle",
      "metadata": {
        "id": "fluid-tackle"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from dataclasses import dataclass\n",
        "import inspect\n",
        "import numpy as np\n",
        "from typing import Callable, Iterable, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crude-market",
      "metadata": {
        "id": "crude-market"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "Neural Networks such as the transformer work with numbers, not text. Therefore the input texts need to be converted to sequences of numbers before the transformer can process them. Thus, the text is first converted into discrete components known as *tokens*, which constitute the model's vocabulary $V$. Each of the tokens corresponds to a unique number, the *token ID*.\n",
        "\n",
        "The module that performs the conversion is called the *tokenizer*. It is technically considered a preprocessing module, separate from the transformer architecture. There are a number of different approaches to tokenization with one of the most popular being *Byte Pair Encoding (BPE)*, which performs subword tokenization by iteratively merging the most frequent pairs of symbols in the text. An important parameter of the tokenizer is the vocabulary size $V$, which is the total number of unique tokens it can produce and the model can recognize.  \n",
        "\n",
        "In short, the tokenizer, given as input raw text sequences, outputs a batch of token sequences and their corresponding IDs, which normally have a shape $[B, L]$. Here $B$ is the *batch size* that determines the number of sequences (or samples) the transformer will process in parallel and $L$ is the number of tokens per sequence.\n",
        "\n",
        "The batch of token ID sequences will then be converted to a batch of *embeddings vectors* (one embedding per token) by the *embedding layer* of the transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "latest-regression",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "aaee85e870cf47d59fe68bfd2e5c6367",
            "cd6a722354fc45a9aba111d3e4f81bcc",
            "e4f2409b9c5b4e03a2d0dacb877bd1a8",
            "ac7fd2f1553f4f05a95483aca960a65d",
            "5cadb7c3923c4f78be514e744c2a9019",
            "53cccf8246d94244b870b517ea30406f",
            "a7b67c1bdddf414892c966bfff2c49bd",
            "3ed65d7e9ed045c1a95489f486ac6b3b",
            "017c582da00441c3b9e20e28b792278d",
            "9df45a7573fe414d88a6fedbe5b17e14",
            "6268c346f73f4b1e8be7b08beaf01907",
            "4227aa820574412fa35b865904c3bc5c",
            "3023c8a4ad3340e0af7fb880432a7060",
            "caec2fe11b18487aab358e3586cebaf9",
            "85334869b60d46ccb341584806ca64f2",
            "e3658c5f4bc74e79aa44faa6e4d93feb",
            "a213e82c4260472f899bb5e3784694ca",
            "345b6b53dd99431792e107736c601563",
            "76dcd1614e4e4fd48c44ae943ae95ac9",
            "19abd8a981c341f7a379445d47c00678",
            "97378dffec5742bcba643da722311d45",
            "b5dc4ebe18014e45abf6af4ce5377740",
            "f12d07ad22ab481397db0e8736579884",
            "fedb2ad2aeb84cfbb8557e62dc29a0d8",
            "b183060e48794cd8afc2f1696c99d5bd",
            "5f2d6db1d8044b52b998b29edc868b6a",
            "3d46743637a84f3f893390707e28b04d",
            "806a074ef3884c1ab673bf5c9643fd1e",
            "b5a2b165736f4bccb16645eca8571cd2",
            "d534a87acb3e4bc4a8f239b2c5c8b58d",
            "15a1c9e763ec4e01a423b6d1ad32aa1d",
            "13af8dbc8dff45f28ced8d4b2565d426",
            "f7050cb4d71c47b5aaacb5fbe7f638cf",
            "ad3f990645a14c27971468382cc1248e",
            "deb828d5d05848df966d7079a5b345ca",
            "d2bcdce069584f35b8afd9ba5ac02d35",
            "9cacdf8a2165429aa20906f7e8fae7f8",
            "e98514dbbe4747e7a20fc115260e9fca",
            "bf0cd9e4eb4945908b5ce35328457134",
            "4fb934f1ef3c43a781b8daf123f820c1",
            "1a7c7177d4644b6889e9284e6583047a",
            "b30a44b9188540f1b676f74200fe9ae8",
            "3213f3114e124e1dab849055dfb99236",
            "9800d01ca55a429993fca5fe3f46274a",
            "fa16ac0dd4be4d609ddf5a685cbaf7f0",
            "b167b2d660a64fcd93830558319b8825",
            "597d9713266448e8911ba6774914f5cd",
            "9de1f861da034d05bce1e3e4b0134b12",
            "6c29bd62fbcb4c62b84211f6b3478f17",
            "e2b3d2420ade4a0cbcaac25d07a68c65",
            "0c0210abcc4c4363a475784b5d44d9a7",
            "f11c8f993e1a44ae852c58c5215b1e90",
            "953cd0368abb4df7bd8ae3ec58325cdb",
            "2fdf9926313f44889ff76983fa6cb7d1",
            "e4686d632d444410bdef83cfe0512da6"
          ]
        },
        "id": "latest-regression",
        "outputId": "eadab9a8-3837-4003-ac34-733ea2374fcb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the GPT-2 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"Pad token/ID:\", tokenizer.pad_token,  tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n",
        "print(\"Vocabulary size |V|:\", tokenizer.vocab_size)\n",
        "\n",
        "# Example batch of texts\n",
        "texts = [\n",
        "    \"The cat sat on the mat\",\n",
        "    \"A quick brown fox jumps over the lazy dog!\"\n",
        "]\n",
        "\n",
        "# Tokenize the batch with padding, L=10\n",
        "encoded = tokenizer(texts, return_tensors=\"pt\", max_length=10 , truncation=True,  padding=\"max_length\" )\n",
        "\n",
        "tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in encoded[\"input_ids\"]]\n",
        "print(\"Tokens:\", *tokens, sep=\"\\n\")\n",
        "print(\"Input IDs:\\n\", encoded[\"input_ids\"])\n",
        "print(\"Attention Mask:\\n\", encoded[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb0614a",
      "metadata": {
        "id": "ccb0614a"
      },
      "source": [
        "Note that Ġ is a special symbol that the particular tokenizer usees to represent a space before a word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "social-safety",
      "metadata": {
        "id": "social-safety"
      },
      "source": [
        "### Embedding Layer\n",
        "\n",
        "The input tokens are discrete and therefore not directly optimizable by gradient-based methods. Thus they need to be converted to continuous, dense vectors that capture semantic meanings and can be learned and optimized by the transformer. This is done by the *embedding layer*.\n",
        "\n",
        "The embedding layer is essentially a trainable look-up table. It takes as input the token IDs and outputs the corresponding rows - which are the *embedding vectors* for the specified token IDs. It has shape ($|V|$, $d_{\\text{model}}$), where $d_{\\text{model}}$ is the dimension of the embedding vectors. Bellow is an example of how it looks in code:\n",
        "\n",
        "\n",
        "```python\n",
        "embedding.weight = [\n",
        "    [e1_1, e1_2, ..., e1_d],   # embedding for token 1\n",
        "    [e2_1, e2_2, ..., e2_d],   # embedding for token 2\n",
        "    ...\n",
        "    [en_1, en_2, ..., en_d],   # embedding for token n\n",
        "]\n",
        "# where n = |V| and d = d_model\n",
        "```\n",
        "\n",
        "Therefore, the embedding layer for an input tensor of shape $[B, L]$ it will output a tensor of shape $[B, L, d_{\\text{model}}]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reverse-faculty",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reverse-faculty",
        "outputId": "8d87da60-2d7a-40bc-fd37-cbccea4f0262"
      },
      "outputs": [],
      "source": [
        "V = tokenizer.vocab_size #|V| = 50256\n",
        "d_model = 3 # Small value for illustration purposes. E.g., nanoGPT uses d_model=768\n",
        "\n",
        "embedding = nn.Embedding(num_embeddings=V, embedding_dim=d_model)\n",
        "\n",
        "# Token IDs from previous example.\n",
        "input_ids = encoded[\"input_ids\"]\n",
        "\n",
        "print(\"Token IDs:\\n\", input_ids)\n",
        "\n",
        "embedded_vectors = embedding(input_ids)\n",
        "\n",
        "print(\"Embedding vectors:\\n\", embedded_vectors)\n",
        "print(\"Embedding Layer output shape:\", embedded_vectors.shape) # Output shape [B=2, L=10, d_model=3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "seasonal-choice",
      "metadata": {
        "id": "seasonal-choice"
      },
      "source": [
        "### Self-attention\n",
        "\n",
        "Self-attention is a mechanism that transforms the representation of each token in a sequence by relating it to different tokens of the sequence. This new representation can then be used by the model to e.g., predict the next word of the sequence.\n",
        "\n",
        "For example, lets say we have the sentence \"The cat sat on the mat\". We can assume a simple word tokenizer and an embedding layer which results in one embedding vector for each word:  \n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "| The    | cat   | sat   | on    | the   | mat   |\n",
        "|-------|-------|-------|-------|-------|-------|\n",
        "| $e_1$ | $e_2$ | $e_3$ | $e_4$ | $e_5$ | $e_6$ |\n",
        "\n",
        "</div>\n",
        "\n",
        "If we wanted to create a model to predict the next word, we could directly just use an MLP+softmax (see bellow for more details about softmax) with input one of the embedding vectors like the above and output a probability distribution over the vocabulary.\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input Tokens} \\quad [B, L] \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Embedding Layer}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Token Embeddings} \\quad [B, L, d_{\\text{model}}] \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{MLP (Feed-Forward Network)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{MLP Output} \\quad [B, L, |V|] \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Softmax (next token probabilities)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output Probabilities} \\quad [B, L, |V|]\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "\n",
        "However, currently each embedding $e_i$ contains information only for the particular word it embeds, regardless of the rest of the sequence. So for example given $e_5$ the model would just predict the most probable word after a \"the\", which is certainly not \"mat\". Instead, with a self-attention layer $e_5$ will be transformed into $e_5' = f(e_1, e_2, e_3, e_4, e_5)$, now containing the context. Here $f()$ represents the self-attention transformation that produces the *contextualized* embedding, which we will describe in details in the next part.\n",
        "\n",
        "**More on the Softmax Operator** Given a vector of logits $\\mathbf{z} = [z_1, z_2, \\dots, z_{|V|}] \\in \\mathbb{R}^{|V|} $, where $|V| $ is the vocabulary size, the softmax function is defined component-wise as:\n",
        "\n",
        "$$\n",
        "\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{|V|} e^{z_j}}, \\quad \\text{for } i = 1, \\dots, |V|.\n",
        "$$\n",
        "\n",
        "The output is a probability vector  $\\mathbf{p} = \\text{softmax}(\\mathbf{z}) \\in \\mathbb{R}^{|V|} $ such that:\n",
        "\n",
        "- $ p_i > 0 $ for all $ i $\n",
        "- $ \\sum_{i=1}^{|V|} p_i = 1 $\n",
        "\n",
        "Thus, $\\mathbf{p} \\in \\Delta^{|V|-1} $, the probability simplex.\n",
        "\n",
        "Bellow we will describe how self-attention is computed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "listed-panic",
      "metadata": {
        "id": "listed-panic"
      },
      "source": [
        "### Scaled Dot-Product Attention\n",
        "\n",
        "- Assume batch size B=1\n",
        "- X is the embedding matrix (contains the embedding vectors of $L$ tokens)\n",
        "- Assume single attention layer after the embedding layer\n",
        "\n",
        "Input matrix:\n",
        "\n",
        "$$\n",
        "X =\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "\\vdots \\\\\n",
        "x_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_{\\text{model}}}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "We apply learned projection matrices:\n",
        "\n",
        "$$\n",
        "W_Q \\in \\mathbb{R}^{d_{\\text{model}} \\times d_q}, \\quad\n",
        "W_K \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad\n",
        "W_V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}\n",
        "$$\n",
        "\n",
        "To obtain the queries, keys, and values:\n",
        "\n",
        "\n",
        "                    \n",
        "$$\n",
        "Q = X W_Q =\n",
        "\\begin{bmatrix}\n",
        "q_1 \\\\\n",
        "q_2 \\\\\n",
        "\\vdots \\\\\n",
        "q_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_q}, \\quad\n",
        "K = X W_K =\n",
        "\\begin{bmatrix}\n",
        "k_1 \\\\\n",
        "k_2 \\\\\n",
        "\\vdots \\\\\n",
        "k_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_k}, \\quad\n",
        "V = X W_V =\n",
        "\\begin{bmatrix}\n",
        "v_1 \\\\\n",
        "v_2 \\\\\n",
        "\\vdots \\\\\n",
        "v_L\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{L \\times d_v}\n",
        "$$\n",
        "\n",
        "Attention logits matrix $QK^T$:\n",
        "\n",
        "$$\n",
        "QK^T \\in \\mathbb{R}^{L \\times L} =\n",
        "\\begin{bmatrix}\n",
        "q_1 \\\\\n",
        "q_2 \\\\\n",
        "\\vdots \\\\\n",
        "q_L\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "k_1^T & k_2^T & \\cdots & k_L^T\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "q_1 k_1^T & q_1 k_2^T & \\cdots & q_1 k_L^T \\\\\n",
        "q_2 k_1^T & q_2 k_2^T & \\cdots & q_2 k_L^T \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "q_L k_1^T & q_L k_2^T & \\cdots & q_L k_L^T \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "Attention weight matrix $A$:\n",
        "\n",
        "\n",
        "$$\n",
        "A = [a_{ij}] \\in \\mathbb{R}^{L \\times L} =\n",
        "\\textrm{Softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) =\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\exp \\left( \\frac{q_1 k_1^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_1 k_j^T}{\\sqrt{d_k}} \\right)} & \\cdots & \\frac{\\exp \\left( \\frac{q_1 k_L^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_1 k_j^T}{\\sqrt{d_k}} \\right)} \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "\\frac{\\exp \\left( \\frac{q_L k_1^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_L k_j^T}{\\sqrt{d_k}} \\right)} & \\cdots & \\frac{\\exp \\left( \\frac{q_L k_L^T}{\\sqrt{d_k}} \\right)}{\\sum\\limits_{j=1}^{L} \\exp \\left( \\frac{q_L k_j^T}{\\sqrt{d_k}} \\right)}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Note that $a_{ij}$ is the attention weight of query $q_i$ wrt key $k_j$ and indicates the level of attention that token $i$ pays on token $j$.\n",
        "\n",
        "Attention output $Z$:\n",
        "\n",
        "\n",
        "$$\n",
        "Z \\in \\mathbb{R}^{L \\times d_v} =\n",
        "\\textrm{Softmax} \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) \\cdot V\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "a_{11} & a_{12} & \\cdots & a_{1L} \\\\\n",
        "a_{21} & a_{22} & \\cdots & a_{2L} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "a_{L1} & a_{L2} & \\cdots & a_{LL}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "v_1 \\\\\n",
        "v_2 \\\\\n",
        "\\vdots \\\\\n",
        "v_L\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "\\sum\\limits_{j=1}^{L} a_{1j} v_j \\\\\n",
        "\\sum\\limits_{j=1}^{L} a_{2j} v_j \\\\\n",
        "\\vdots \\\\\n",
        "\\sum\\limits_{j=1}^{L} a_{Lj} v_j\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "$Z$ is the output of the attention layer, which weights the value vectors $v_i$ based on the computed attention weights. Each $z_i$ combines information from different value vectors (corresponding to different tokens) according to the attention given to each key by each query.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "superb-consumer",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "superb-consumer",
        "outputId": "b975caf6-c808-48ce-cf24-6e2daa716545"
      },
      "outputs": [],
      "source": [
        "# Numpy implementation of dot-product attention:\n",
        "\n",
        "# Define embedding vectors for tokens (3 tokens/sq_len, 4-dimensional embeddings)\n",
        "embedding_dim = 4\n",
        "X = np.array([[0.1, 0.2, 0.3, 0.4],   # Embedding for token 1\n",
        "              [0.5, 0.6, 0.7, 0.8],   # Embedding for token 2\n",
        "              [0.9, 1.0, 1.1, 1.2]])  # Embedding for token 3\n",
        "\n",
        "# Define weight matrices for the transformations (W_Q, W_K, W_V)\n",
        "W_Q = np.random.rand(embedding_dim, embedding_dim)  # Query weight matrix\n",
        "W_K = np.random.rand(embedding_dim, embedding_dim)  # Key weight matrix\n",
        "W_V = np.random.rand(embedding_dim, embedding_dim)  # Value weight matrix\n",
        "\n",
        "# Compute the Q, K, V matrices by applying the transformations to the embeddings\n",
        "Q = np.dot(X, W_Q)  # Query matrix (Q)\n",
        "K = np.dot(X, W_K)  # Key matrix (K)\n",
        "V = np.dot(X, W_V)  # Value matrix (V)\n",
        "\n",
        "# Define the scaling factor (sqrt of key dimension)\n",
        "d_k = K.shape[1]\n",
        "scaling_factor = np.sqrt(d_k)\n",
        "\n",
        "# Compute the attention logits (Q K^T / sqrt(d_k))\n",
        "logits = np.dot(Q, K.T) / scaling_factor\n",
        "\n",
        "# Apply softmax to the logits to get attention weights\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "attention_weights = softmax(logits)\n",
        "\n",
        "# Compute the output Z (weighted sum of values)\n",
        "Z = np.dot(attention_weights, V)\n",
        "\n",
        "print(\"Embeddings:\\n\", X)\n",
        "print(\"\\nQuery Matrix (Q):\\n\", Q)\n",
        "print(\"\\nKey Matrix (K):\\n\", K)\n",
        "print(\"\\nValue Matrix (V):\\n\", V)\n",
        "print(\"\\nAttention Logits (Q K^T / sqrt(d_k)):\\n\", logits)\n",
        "print(\"\\nAttention Weights (Softmax of Logits):\\n\", attention_weights)\n",
        "print(\"\\nOutput Z (Weighted Sum of Values):\\n\", Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "moved-poland",
      "metadata": {
        "id": "moved-poland"
      },
      "source": [
        "### Masked (or causal) self-attention\n",
        "\n",
        "In practice, transformers use a version of self-attention called masked or causal self-attention. In contrast to (bidirectional) self-attention that computes attentions scores for all tokens in the sequence, masked self-attention uses a *causal mask* that hides future tokens, so each token can attend to itself and earlier tokens.\n",
        "\n",
        "Example of a casual mask:\n",
        "\n",
        "$$\n",
        "\\begin{array}{c|cccccc}\n",
        "    & \\text{The} & \\text{cat} & \\text{sat} & \\text{on} & \\text{the} & \\text{mat} \\\\\n",
        "\\hline\n",
        "\\text{The} & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
        "\\text{cat} & 1 & 1 & 0 & 0 & 0 & 0 \\\\\n",
        "\\text{sat} & 1 & 1 & 1 & 0 & 0 & 0 \\\\\n",
        "\\text{on}  & 1 & 1 & 1 & 1 & 0 & 0 \\\\\n",
        "\\text{the} & 1 & 1 & 1 & 1 & 1 & 0 \\\\\n",
        "\\text{mat}& 1 & 1 & 1 & 1 & 1 & 1\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Where 1 means the token can attend, 0 means it’s masked out. Note that for simplicity each word represents a token. So,\n",
        "- \"The\" can attend only to itself.\n",
        "- \"cat\" can attend only to \"The\" and \"cat\".\n",
        "- \"mat\" can attend to everything in this sentence.\n",
        "\n",
        "Usually this masking is done by setting the $q_i k_j^T$ with $i < j$ to $-\\infty$ in the $QK^T$ attention logits matrix so that the application of the softmax will give zero attention weights to those positions.\n",
        "\n",
        "In short, using the same notation as scaled-dot product attention where $X$ is the input embedding matrix, masked self attention computes:\n",
        "\n",
        "$$\n",
        "Z_\\text{masked}  \\in  \\mathbb{R}^{L \\times d_v}\n",
        "=\n",
        "\\text{Softmax}\\!\\left(\n",
        "\\frac{QK^{T}}{\\sqrt{d_k}} + \\log M\n",
        "\\right)V,\n",
        "\\quad Q=XW_Q,\\, K=XW_K,\\, V=XW_V.\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "(\\log M)_{ij} =\n",
        "\\begin{cases}\n",
        "0, & j \\le i, \\\\[4pt]\n",
        "-\\infty, & j > i.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Note that $i$ here corresponds to a row (query token index) and $j$ to a column (key token index) of $QK^{T}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "junior-colors",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "junior-colors",
        "outputId": "be3c8e81-1d2e-48d7-e141-6b16d33912af"
      },
      "outputs": [],
      "source": [
        "# Numpy implementation of masked self-attention:\n",
        "\n",
        "# Define embedding vectors for tokens (3 tokens/sq_len, 4-dimensional embeddings)\n",
        "embedding_dim = 4\n",
        "X = np.array([[0.1, 0.2, 0.3, 0.4],   # Embedding for token 1\n",
        "              [0.5, 0.6, 0.7, 0.8],   # Embedding for token 2\n",
        "              [0.9, 1.0, 1.1, 1.2]])  # Embedding for token 3\n",
        "\n",
        "# Define weight matrices for the transformations (W_Q, W_K, W_V)\n",
        "W_Q = np.random.rand(embedding_dim, embedding_dim)  # Query weight matrix\n",
        "W_K = np.random.rand(embedding_dim, embedding_dim)  # Key weight matrix\n",
        "W_V = np.random.rand(embedding_dim, embedding_dim)  # Value weight matrix\n",
        "\n",
        "# Compute the Q, K, V matrices by applying the transformations to the embeddings\n",
        "Q = np.dot(X, W_Q)  # Query matrix (Q)\n",
        "K = np.dot(X, W_K)  # Key matrix (K)\n",
        "V = np.dot(X, W_V)  # Value matrix (V)\n",
        "\n",
        "# Define the scaling factor (sqrt of key dimension)\n",
        "d_k = K.shape[1]\n",
        "scaling_factor = np.sqrt(d_k)\n",
        "\n",
        "# Compute the attention logits (Q K^T / sqrt(d_k))\n",
        "logits = np.dot(Q, K.T) / scaling_factor\n",
        "\n",
        "# Create causal mask: shape (seq_len, seq_len)\n",
        "seq_len = X.shape[0]\n",
        "mask = np.tril(np.ones((seq_len, seq_len)))  # Lower triangular matrix including diagonal\n",
        "\n",
        "# Apply mask: set logits where mask==0 to very large negative value (simulate -inf)\n",
        "logits_masked = np.where(mask == 1, logits, -1e9)\n",
        "\n",
        "# Apply softmax to the masked logits to get attention weights\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # for numerical stability\n",
        "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
        "\n",
        "attention_weights = softmax(logits_masked)\n",
        "\n",
        "# Compute the output Z (weighted sum of values)\n",
        "Z = np.dot(attention_weights, V)\n",
        "\n",
        "print(\"Embeddings:\\n\", X)\n",
        "print(\"\\nQuery Matrix (Q):\\n\", Q)\n",
        "print(\"\\nKey Matrix (K):\\n\", K)\n",
        "print(\"\\nValue Matrix (V):\\n\", V)\n",
        "print(\"\\nAttention Logits (Q K^T / sqrt(d_k)):\\n\", logits)\n",
        "print(\"\\nMask (1=keep, 0=mask):\\n\", mask)\n",
        "print(\"\\nMasked Attention Logits:\\n\", logits_masked)\n",
        "print(\"\\nAttention Weights (Softmax of Masked Logits):\\n\", attention_weights)\n",
        "print(\"\\nOutput Z (Weighted Sum of Values):\\n\", Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diagnostic-coaching",
      "metadata": {
        "id": "diagnostic-coaching"
      },
      "source": [
        "### Multi-Head Attention:\n",
        "\n",
        "$$\n",
        "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W^O\n",
        "\\quad \\text{where} \\quad \\\\\n",
        "\\text{head}_i = \\text{Attention}(Q W_i^Q, \\; K W_i^K, \\; V W_i^V)\n",
        "$$\n",
        "\n",
        "where the projection matrices are:\n",
        "$\n",
        "\\quad\n",
        "W_i^Q \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad\n",
        "W_i^K \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}, \\quad\n",
        "W_i^V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}, \\quad\n",
        "\\text{and} \\quad\n",
        "W^O \\in \\mathbb{R}^{h d_v \\times d_{\\text{model}}}\n",
        "$\n",
        "\n",
        "\n",
        "In short, multi-head attention allows the model to attend to different aspects of the input sequence simultaneously (e.g., some heads might focus on different context type than others) and is found to be beneficial in practice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "complete-rabbit",
      "metadata": {
        "id": "complete-rabbit"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation of causal self-attention (multi-head)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        # ! n_embd = d_model, c_attn acts as all three W_q, W_k, W_v at once and all have output dim n_embd.\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "driving-extraction",
      "metadata": {
        "id": "driving-extraction"
      },
      "source": [
        "### LayerNorm\n",
        "\n",
        "*Layer Normalization* (LayerNorm) is used to stabilize and accelerate training by normalizing the input across features.\n",
        "\n",
        "Given input vector $x \\in \\mathbb{R}^d$ (e.g., the hidden state of one token), compute:\n",
        "\n",
        "$$\\mu = \\frac{1}{d} \\sum_{i=1}^{d} x_i,  \\  \\ \\sigma^2 = \\frac{1}{d} \\sum_{i=1}^{d} (x_i - \\mu)^2$$\n",
        "\n",
        "Then Layer Normalization is applied as:\n",
        "\n",
        "$$  \\textrm{LayerNorm}(x)_i =   \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\cdot \\gamma_i + \\beta_i, $$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\gamma \\in \\mathbb{R}^d$: learnable scale\n",
        "\n",
        "- $\\beta \\in \\mathbb{R}^d$: learnable bias\n",
        "\n",
        "Given an input $X \\in \\mathbb{R}^{B \\times L \\times d_{\\textrm{model}}}$, LayerNorm($X$) will be applied independently for each token's hidden state, $x_{b,t} \\in \\mathbb{R}^{d_{\\textrm{model}}}$, unlike BatchNorm which normalizes across a batch. Note that $\\gamma$ and $\\beta$ dimensions will remain $d_{\\textrm{model}}$ as they are shared across tokens for all sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "personal-palestine",
      "metadata": {
        "id": "personal-palestine"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation of Layer Normalization\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
        "\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "other-configuration",
      "metadata": {
        "id": "other-configuration"
      },
      "source": [
        "### MLP Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "studied-exploration",
      "metadata": {
        "id": "studied-exploration"
      },
      "source": [
        "\n",
        "#### MLP diagram:\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input } x \\quad (B \\times L \\times d_{\\text{model}}) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Linear } (d_{\\text{model}} \\rightarrow 4 d_{\\text{model}}) \\\\\n",
        "(\\text{c\\_fc})\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{GELU Activation}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Linear } (4 d_{\\text{model}} \\rightarrow d_{\\text{model}}) \\\\\n",
        "(\\text{c\\_proj})\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Dropout}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output } x \\quad (B \\times L \\times d_{\\text{model}})\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "#### Block Layer diagram:\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input } x \\quad (B \\times L \\times d_{\\text{model}}) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{LayerNorm (ln\\_1)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Causal Self-Attention} \\\\\n",
        "\\text{(attn)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Residual: } x = x + \\text{Attention Output} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{LayerNorm (ln\\_2)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{MLP (diagram above)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Residual: } x = x + \\text{MLP Output} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output of Block } (B \\times L \\times d_{\\text{model}})\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "incomplete-turner",
      "metadata": {
        "id": "incomplete-turner"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation of MLP Layer\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conceptual-server",
      "metadata": {
        "id": "conceptual-server"
      },
      "source": [
        "### Decoder-only transformer (nanoGPT)\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "\\text{Input Tokens (indices)} \\quad (B \\times L) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Token Embedding (wte)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "+ \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Learned Positional Embedding (wpe)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Token Embeddings + Positional Embeddings (with Dropout)} \\quad (B \\times L \\times d_{\\text{model}}) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Block 1:} \\\\\n",
        "x = x + \\text{Causal Self-Attention}(\\text{LayerNorm}(x)) \\\\\n",
        "x = x + \\text{MLP}(\\text{LayerNorm}(x))\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Block 2:} \\\\\n",
        "x = x + \\text{Causal Self-Attention}(\\text{LayerNorm}(x)) \\\\\n",
        "x = x + \\text{MLP}(\\text{LayerNorm}(x))\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\vdots \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Block N:} \\\\\n",
        "x = x + \\text{Causal Self-Attention}(\\text{LayerNorm}(x)) \\\\\n",
        "x = x + \\text{MLP}(\\text{LayerNorm}(x))\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Final LayerNorm (ln\\_f)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Linear Projection (lm\\_head)} \\\\\n",
        "\\text{(weights tied with token embeddings)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output Logits} \\quad (B \\times L \\times |V|) \\\\\n",
        "\\downarrow \\\\\n",
        "\\boxed{\n",
        "\\begin{array}{c}\n",
        "\\text{Softmax (next token probabilities)}\n",
        "\\end{array}\n",
        "} \\\\\n",
        "\\downarrow \\\\\n",
        "\\text{Output Probabilities} \\quad (B \\times L \\times |V|)\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "split-projection",
      "metadata": {
        "id": "split-projection"
      },
      "outputs": [],
      "source": [
        "# Pytorch implemenation of nanoGPT\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
        "\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
        "\n",
        "        # init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        \"\"\"\n",
        "        Return the number of parameters in the model.\n",
        "        For non-embedding count (default), the position embeddings get subtracted.\n",
        "        The token embeddings would too, except due to the parameter sharing these\n",
        "        params are actually used as weights in the final layer, so we include them.\n",
        "        \"\"\"\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # if we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-100)\n",
        "        else:\n",
        "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
        "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
        "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # if the sequence context is growing too long we must crop it at block_size\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            # forward the model to get the logits for the index in the sequence\n",
        "            logits, _ = self(idx_cond)\n",
        "            # pluck the logits at the final step and scale by desired temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            # optionally crop the logits to only the top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            # apply softmax to convert logits to (normalized) probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "governmental-destiny",
      "metadata": {
        "id": "governmental-destiny"
      },
      "source": [
        "## LLM Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6839d0bc",
      "metadata": {
        "id": "6839d0bc"
      },
      "source": [
        "Now that we have implemented the model, we move to the training part of the tutorial. Our goal is to take the randomly initialized model and train it on a large text dataset.\n",
        "\n",
        "This is the first (and most expensive) stage of model training and it is known as *pre-training*, as we beging with a completely untrained model and train it on a large, generic dataset. Next, the model is usualy *fine-tuned* on more specialized or task-oriented datasets much smaller in size, and finally the model is trained to align with human preferences (*alignment*).\n",
        "\n",
        "For our tutorial, we will use a subset of the cleaned english part (en) of the C4 (Colossal Clean Crawled Corpus) dataset. In particular, C4/en consists of 305GB of english sentences. After tokenization, it roughly produces 150B tokens (although the exact value will depend on the tokenizer being used). More details about C4 can be found in this link: https://huggingface.co/datasets/allenai/c4.\n",
        "\n",
        "Next, we will go though our basic pre-training pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thrown-evanescence",
      "metadata": {
        "id": "thrown-evanescence"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from torch.utils.data import IterableDataset, get_worker_info"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7391d721",
      "metadata": {
        "id": "7391d721"
      },
      "source": [
        "### Training parameters\n",
        "\n",
        "Bellow we define our training parameters. For some of them we include more details here:\n",
        "\n",
        "`device=f\"cuda:0\"`: The ID of our GPU. Note that this simple training code does not support multi-GPU training as it is intended for training small models on relatively small amounts of data. However, in practice training LLMs entails the use of multiple GPUs using parallelization techniques. Such an implementation could be included in a future version of the tutorial.\n",
        "\n",
        "`device_batch_size=64`: The number of token sequences processed simultaneously on one GPU.\n",
        "\n",
        "`total_batch_size=256`: The number of token sequences the model \"sees\" at each training iteration. For our single GPU set-up:\n",
        "\n",
        "<p align=\"center\"><code>gradient_accumulation = total_batch_size / device_batch_size</code></p>\n",
        "\n",
        "(4 in this case) means that before the model weights are updated, the gradients from `gradient_accumulation=4` mini-batches (each having `device_batch_size=64` token sequences) are summed (accumulated) and averaged, so the update reflects the effect of all `total_batch_size=256` sequences together.\n",
        "\n",
        "`num_training_steps = 100`: The number of training steps (model updates) that will be performed. Note that it is set to 100 just for code testing purposes. In practice, for pretraining a good guideline is the *Chinchilla compute-optimal ratio*, i.e. using about 20 tokens per (non-embedding) model parameter. So, since our model has 124M trainable parameters, this corresponds to about 2.5B tokens needed for training. Given that we use `total_batch_size=256` and `max_length=256` (the maximum sequence length), each batch size will have 65,536 tokens (or in rare cases less if some sequences are smaller than the `max_length`), so roughly we need 2.5B / 65,536 $\\approx 38,000$ steps. For more details about compute optimal training and the Chinchilla ratio see: https://arxiv.org/abs/2203.15556."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "characteristic-scholarship",
      "metadata": {
        "id": "characteristic-scholarship"
      },
      "outputs": [],
      "source": [
        "# Environment parameters:\n",
        "device = f\"cuda:0\" # Our GPU id\n",
        "workers = 4 # CPU workers\n",
        "# Data parameters:\n",
        "device_batch_size = 64\n",
        "# Tokenization parameters:\n",
        "max_length = 256  # sequence length L\n",
        "# Optimizer parameters\n",
        "lr = 1e-3\n",
        "weight_decay = 0.0\n",
        "# LR scheduler parameters\n",
        "warmup_steps = 1000\n",
        "# Training parameters:\n",
        "num_training_steps = 5_000 # 38_000\n",
        "total_batch_size = 256\n",
        "grad_clipping = 0.0\n",
        "print_freq = 100\n",
        "# Evaluation parameters\n",
        "eval_every = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b01740",
      "metadata": {
        "id": "e2b01740"
      },
      "source": [
        "### C4 Dataset Streaming and Preprocessing\n",
        "\n",
        "1. **Load the dataset**\n",
        "   - Streams the C4/en dataset:\n",
        "     ```python\n",
        "     data = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
        "     val_data = load_dataset(\"allenai/c4\", \"en\", split=\"validation\", streaming=True)\n",
        "     ```\n",
        "   - The data are streamed on-the-fly without downloading the full dataset on disk.\n",
        "\n",
        "2. **Preprocessing**\n",
        "   - `PreprocessedIterableDataset` tokenizes each text example using the GPT-2 tokenizer.\n",
        "   - Examples are truncated and padded to `max_length`.\n",
        "   - Tokenized examples are collected into batches of size `device_batch_size`.\n",
        "   - Finally, each batch is converted into a single tensor of input IDs:\n",
        "     ```python\n",
        "     input_ids = torch.stack([item[\"input_ids\"].squeeze(0) for item in batch])\n",
        "     ```\n",
        "\n",
        "3. **DataLoader**\n",
        "   - Using PyTorch `DataLoader`:\n",
        "     ```python\n",
        "     dataloader = torch.utils.data.DataLoader(dataset, batch_size=None, num_workers=workers)\n",
        "     ```\n",
        "   - Batching is done inside the dataset iterator `PreprocessedIterableDataset`, so here set `batch_size=None` as the dataloader does not need to do additional batching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "regional-jerusalem",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "ccb3142c6148411ca038b1ab24d149bc",
            "5ad3ccbaabb042639b5a9dea1b705dcb",
            "20f8ba60976a4da69b9f8ecdbbfee1d7",
            "9887782b6f2c409abfeae5594be766ca",
            "9132e199de5f4161829aa035d83ff25c",
            "fd3dfcb533f74fa78d6d295e992a8043",
            "ed784516b3fd49279412daa03bd17057",
            "8a4d82dc90a846ff9fc78af4bbcabcb7",
            "2ac93e37112a45eb8f25b855ea3f3f11",
            "67d4e82df8b34308bb0619b56bf509da",
            "7d7931a0b03c4d1bb5e141ba2b17a177",
            "4f98ed06f4df430d9b43a322345166b9",
            "05d2475126b245f58415913daadac6e4",
            "3e59e9fff8784e90bbc6d7395f50318c",
            "c1d8ca0f36e947feb2b67a7d1a5b4fe1",
            "9f65cae127454e76b6f07a1de0cd345d",
            "43fc20630c5f49d08294accfd2b3ed63",
            "7040424a42594d30a297f63f9018eb70",
            "f8ec16b8cfb04af2bfffa337643d06d6",
            "7283d05676fb47658a70bb53f5950c48",
            "cd5095556c634b0888e9c657ab96455f",
            "e7a2b9f885024bb588fc691837b63b54",
            "9a921fb569cb422aa8f8426abb7aaec2",
            "e8e4aae2a5404b108b89a9a20dc5c981",
            "71ecbfdb44674eaabb5f71bb16279834",
            "21c28abb0681465ab9babba2f33500d6",
            "bd4096919b7e4dc4aed8292e04b212e6",
            "9713c7f9b5684221b124330d6a8380bb",
            "40c7d1ac09754bafb7a49c0f84d86008",
            "a90729b4f86f4b8c87398feff4dc758f",
            "76db9a5dc7d048e0a8c0bac28d6840df",
            "41afe3bb0673490eb66b65d69cd7ddf5",
            "466c587a3272436885f4b725d69ef631",
            "c09bb648daca48b2a223ea788bf70c5b",
            "18504d4b21f2428d94ba9c82c9a9a5fd",
            "dd6fccd8e72e4c7baaa52492ceef2915",
            "c3e13d6e8b4d46ca8c2e93b344de3214",
            "29201687179f443ba5c9e20f70e5fa6f",
            "06cc5908329948559f8e8cdd5c9c0efe",
            "d2f8d68ca1d946338188047f76b00a3e",
            "ed7bf690fe964b9e8094522e8b93ab80",
            "87784bba62d0453f9eb68b3bf2414fec",
            "ce9cb516e3cf4e3e83202a9841205eec",
            "20ff0ad5c659495a9ede2e0d166cde5e",
            "4cb2454931e943d5b2c26754797409e4",
            "22f54e8bf37749ecac65acc58fce09f0",
            "ae80531f0e0f4d7099f0f2f969fb749f",
            "8db936b3803644e68739e96e3813fc81",
            "c83285f1f4de42cf8259bc4abd4c9550",
            "4ff6a75b90334d8eb7c16f343c4a4d1b",
            "86b387f390e84798adb088702906748f",
            "ca896404845947debedd701c8ab32aad",
            "26e936723f5e4c1ab7b1491594f582a2",
            "92e4902a9529457cb378934505ee167d",
            "acba8a786c294e0086941d56e39559e7"
          ]
        },
        "id": "regional-jerusalem",
        "outputId": "9d021de6-645f-4711-a2a4-2c6f0f95a35f"
      },
      "outputs": [],
      "source": [
        "data = load_dataset(\n",
        "            \"allenai/c4\", \"en\", split=\"train\", streaming=True\n",
        "        )\n",
        "val_data = load_dataset(\n",
        "            \"allenai/c4\", \"en\", split=\"validation\", streaming=True\n",
        "        )\n",
        "\n",
        "class PreprocessedIterableDataset(IterableDataset):\n",
        "    def __init__(self, data, tokenizer, device_batch_size, max_length):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device_batch_size = device_batch_size\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __iter__(self):\n",
        "        iter_data = iter(self.data)\n",
        "\n",
        "        batch = []\n",
        "        for example in iter_data:\n",
        "            tokenized_example = self.tokenizer(\n",
        "                example[\"text\"],\n",
        "                max_length=self.max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "            batch.append(tokenized_example)\n",
        "\n",
        "            if len(batch) == self.device_batch_size:\n",
        "                yield self._format_batch(batch)\n",
        "                batch = []\n",
        "\n",
        "        if batch:\n",
        "            yield self._format_batch(batch)\n",
        "\n",
        "    def _format_batch(self, batch):\n",
        "        input_ids = torch.stack([item[\"input_ids\"].squeeze(0) for item in batch])\n",
        "        return input_ids\n",
        "\n",
        "# GPT-2 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "dataset = PreprocessedIterableDataset(\n",
        "                data, tokenizer, device_batch_size=device_batch_size, max_length=max_length\n",
        "            )\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=None, num_workers=workers,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f458b3",
      "metadata": {
        "id": "65f458b3"
      },
      "source": [
        "### Model parameters and loading\n",
        "\n",
        "Bellow we define nanoGPT using standard parameters. It will consist of 12 transformer layers, each having embedding dimension $d_{\\textrm{model}}=768$. It has a total of 123.55M trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "friendly-leonard",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "friendly-leonard",
        "outputId": "c77dcd01-bcc2-43a3-d83c-7ffb130a07ef"
      },
      "outputs": [],
      "source": [
        "# model parameters:\n",
        "n_layer = 12\n",
        "n_head = 12\n",
        "n_embd = 768\n",
        "dropout = 0.0\n",
        "bias = False\n",
        "block_size = 1024 # the maximum sequence length the model can handle\n",
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n",
        "                  bias=bias, vocab_size=vocab_size, dropout=dropout)\n",
        "\n",
        "gptconf = GPTConfig(**model_args)\n",
        "model = GPT(gptconf).to(device)\n",
        "\n",
        "model = torch.compile(model) # for faster training\n",
        "\n",
        "n_total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04abeb85",
      "metadata": {
        "id": "04abeb85"
      },
      "source": [
        "### Optimizer and LR scheduler\n",
        "\n",
        "Bellow we define the standard Adam optimizer class (code based on transformers.optimization library) and a learning rate scheduler that consists of a linear warmup and a cosine decay phase.\n",
        "\n",
        "Note that ee define the optimizer class here so it can serve as a foundation for creating other optimizer classes. Alternatively, you could use a predefined optimizer, for example:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(\n",
        "            params=trainable_params, lr=lr, weight_decay=weight_decay\n",
        "        )\n",
        "```\n",
        "\n",
        "We encourage experimenting with different optimizers and learning rate schedules. You can implement your own or try existing ones, for example from:  \n",
        "- https://docs.pytorch.org/docs/stable/optim.html\n",
        "- https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules#transformers.SchedulerType\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee4b074",
      "metadata": {
        "id": "4ee4b074"
      },
      "outputs": [],
      "source": [
        "class Adam(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Implements Adam algorithm with weight decay fix as introduced in [Decoupled Weight Decay\n",
        "    Regularization](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "    Parameters:\n",
        "        params (`Iterable[nn.parameter.Parameter]`):\n",
        "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
        "        lr (`float`, *optional*, defaults to 0.001):\n",
        "            The learning rate to use.\n",
        "        betas (`Tuple[float,float]`, *optional*, defaults to `(0.9, 0.999)`):\n",
        "            Adam's betas parameters (b1, b2).\n",
        "        eps (`float`, *optional*, defaults to 1e-06):\n",
        "            Adam's epsilon for numerical stability.\n",
        "        weight_decay (`float`, *optional*, defaults to 0.0):\n",
        "            Decoupled weight decay to apply.\n",
        "        correct_bias (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not to correct bias in Adam (for instance, in Bert TF repository they use `False`).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params: Iterable[nn.parameter.Parameter],\n",
        "        lr: float = 1e-3,\n",
        "        betas: Tuple[float, float] = (0.9, 0.999),\n",
        "        eps: float = 1e-6,\n",
        "        weight_decay: float = 0.0,\n",
        "        correct_bias: bool = True,\n",
        "    ):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr} - should be >= 0.0\")\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[0]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[1]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps} - should be >= 0.0\")\n",
        "        defaults = {\"lr\": lr, \"betas\": betas, \"eps\": eps, \"weight_decay\": weight_decay, \"correct_bias\": correct_bias}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure: Callable = None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (`Callable`, *optional*): A closure that reevaluates the model and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if \"step\" not in state:\n",
        "                    state[\"step\"] = 0\n",
        "\n",
        "                # State initialization\n",
        "                if \"exp_avg\" not in state:\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(grad)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(grad)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
        "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
        "\n",
        "                step_size = group[\"lr\"]\n",
        "\n",
        "                if group[\"correct_bias\"]:\n",
        "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
        "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
        "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # Adam update\n",
        "                u = exp_avg / denom\n",
        "\n",
        "                p.add_(u, alpha=-step_size)\n",
        "\n",
        "                if group[\"weight_decay\"] > 0.0:\n",
        "                    p.add_(p, alpha=(-group[\"lr\"] * group[\"weight_decay\"]))\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k6rxTdNVGkMz",
      "metadata": {
        "id": "k6rxTdNVGkMz"
      },
      "outputs": [],
      "source": [
        "class RMSProp(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    A simple implementation of RMSProp.\n",
        "\n",
        "    Keeps an exponential moving average of squared gradients and uses it\n",
        "    to normalize the current gradient.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, alpha=0.99, eps=1e-8, weight_decay=0.0):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
        "        if not 0.0 <= alpha < 1.0:\n",
        "            raise ValueError(f\"Invalid alpha value: {alpha}\")\n",
        "        if eps < 0.0:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps}\")\n",
        "\n",
        "        defaults = {\n",
        "            \"lr\": lr,\n",
        "            \"alpha\": alpha,   # decay for moving average of squared grads\n",
        "            \"eps\": eps,\n",
        "            \"weight_decay\": weight_decay,\n",
        "        }\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group[\"lr\"]\n",
        "            alpha = group[\"alpha\"]\n",
        "            eps = group[\"eps\"]\n",
        "            weight_decay = group[\"weight_decay\"]\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "\n",
        "                state = self.state[p]\n",
        "                if len(state) == 0:\n",
        "                    state[\"square_avg\"] = torch.zeros_like(p)\n",
        "\n",
        "                square_avg = state[\"square_avg\"]\n",
        "\n",
        "                # L2-style weight decay: g <- g + wd * p\n",
        "                if weight_decay != 0.0:\n",
        "                    grad = grad.add(p, alpha=weight_decay)\n",
        "\n",
        "\n",
        "                square_avg.mul_(alpha).addcmul_(grad, grad, value=1.0 - alpha)\n",
        "\n",
        "                # RMSProp update\n",
        "                denom = square_avg.sqrt().add_(eps)\n",
        "                p.addcdiv_(grad, denom, value=-lr)\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AnG5euB3JV0X",
      "metadata": {
        "id": "AnG5euB3JV0X"
      },
      "outputs": [],
      "source": [
        "class SignSGD(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    A simple implementation of signSGD.\n",
        "\n",
        "    Parameter update: p <- p - lr * sign(grad)\n",
        "    Optionally with L2-style weight decay.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, weight_decay=0.0):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
        "        defaults = {\"lr\": lr, \"weight_decay\": weight_decay}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group[\"lr\"]\n",
        "            weight_decay = group[\"weight_decay\"]\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "\n",
        "                # L2-style weight decay\n",
        "                if weight_decay != 0.0:\n",
        "                    grad = grad.add(p, alpha=weight_decay)\n",
        "\n",
        "                # gradient\n",
        "                d_p = grad.sign()\n",
        "                p.add_(d_p, alpha=-lr)\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C6a9P03kJ_pI",
      "metadata": {
        "id": "C6a9P03kJ_pI"
      },
      "outputs": [],
      "source": [
        "def create_optimizer(name, params, lr, weight_decay):\n",
        "    name = name.lower()\n",
        "    if name == \"adam\":\n",
        "        return Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    elif name == \"rmsprop\":\n",
        "        return RMSProp(params, lr=lr, weight_decay=weight_decay)\n",
        "    elif name == \"signsgd\":\n",
        "        return SignSGD(params, lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer name: {name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fresh-connectivity",
      "metadata": {
        "id": "fresh-connectivity"
      },
      "outputs": [],
      "source": [
        "# optimizer using our Adam class defined above\n",
        "optimizer = Adam(trainable_params, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# learning rate scheduler\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=num_training_steps,\n",
        "    last_epoch=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6611360",
      "metadata": {
        "id": "c6611360"
      },
      "source": [
        "### Main Training Code\n",
        "\n",
        "Before the training loop:\n",
        "\n",
        "- **Initialization**: Initialize `global_step`, `update_step`, and `tokens_seen`. Set up `gradient_accumulation` based on `total_batch_size` and `device_batch_size`. Note that `update_step` counts the actual number of updates performed, while `global_step = update_step * gradient_accumulation`.\n",
        "\n",
        "Inside the training loop:\n",
        "\n",
        "\n",
        "\n",
        "1. **Batch Processing**\n",
        "   - Load a batch from the `dataloader` and move it to the device.\n",
        "   - Prepare labels by shifting input tokens left (next-token prediction) and masking padding (`-100` for ignored positions):\n",
        "\n",
        "      ```python\n",
        "        input_ids = batch.to(device)\n",
        "        labels = input_ids.clone()\n",
        "        labels[:, :-1] = input_ids[:, 1:]   # shift left\n",
        "        labels[:, -1] = pad_idx             # pad the last token\n",
        "        labels[labels == pad_idx] = -100    # mask out padding\n",
        "        labels = labels.to(device)\n",
        "      ```\n",
        "\n",
        "2. **Forward and Backward Pass**:\n",
        "   - Compute logits and loss after passing the input and labels to the model (forward pass). Then scale the loss by `gradient_accumulation` and call `.backward()` for the backward pass.\n",
        "        ```python\n",
        "        logits, loss = model(input_ids, targets=labels)\n",
        "        scaled_loss = loss / gradient_accumulation\n",
        "        scaled_loss.backward()\n",
        "        ```\n",
        "   - Accumulate gradients over multiple mini-batches if needed:\n",
        "   \n",
        "        ```python\n",
        "        if global_step % gradient_accumulation != 0:\n",
        "            continue\n",
        "        ```\n",
        "     \n",
        "3. **Optimizer Step**:\n",
        "   - Apply gradient clipping if configured.\n",
        "   - Update model parameters with `optimizer.step()` and learning rate scheduler `scheduler.step()`.\n",
        "   - Reset gradients with `optimizer.zero_grad()`.\n",
        "   - Increment `update_step`.\n",
        "\n",
        "      ```python\n",
        "      if grad_clipping != 0.0:\n",
        "          torch.nn.utils.clip_grad_norm_(trainable_params, grad_clipping)\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "          \n",
        "      update_step += 1\n",
        "      ```\n",
        "\n",
        "4. **Logging**: Print progress every `print_freq` updates.  \n",
        "\n",
        "5. **Termination**: Stop training when `num_training_steps` is reached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c509366a",
      "metadata": {
        "id": "c509366a"
      },
      "outputs": [],
      "source": [
        "# Evaluation code\n",
        "\n",
        "def collate_fn(batch_list):\n",
        "    batch =  torch.stack([torch.Tensor(example[\"input_ids\"]).long() for example in batch_list])\n",
        "    return batch\n",
        "\n",
        "def batch_fn(dataset, batch_size):\n",
        "    batch = []\n",
        "    for example in dataset:\n",
        "        batch.append(example)\n",
        "        if len(batch) == batch_size:\n",
        "            batch = collate_fn(batch)\n",
        "            yield batch\n",
        "            batch = []\n",
        "    if len(batch) > 0:\n",
        "        yield batch\n",
        "\n",
        "def preprocess_batched(batch):\n",
        "    batch = tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return batch\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(\n",
        "    model, val_data, preprocess_batched, pad_idx, device, batch_size\n",
        "):\n",
        "\n",
        "    val_data = val_data.shuffle(seed=42)\n",
        "\n",
        "    val_data_mapped = val_data.map(\n",
        "        preprocess_batched,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\", \"timestamp\", \"url\"],\n",
        "    )\n",
        "    val_data_mapped.batch = lambda batch_size: batch_fn(\n",
        "        val_data_mapped, batch_size\n",
        "    )\n",
        "\n",
        "    target_eval_tokens = 1_000_000 #10_000_000\n",
        "    evaluated_on_tokens = 0\n",
        "    total_loss = torch.tensor(0.0).to(device)\n",
        "    total_batches = 0\n",
        "\n",
        "    for batch in val_data_mapped.batch(batch_size=batch_size):\n",
        "        if evaluated_on_tokens > target_eval_tokens:\n",
        "            break\n",
        "        total_batches += 1\n",
        "\n",
        "        input_ids = batch.to(device)\n",
        "        labels = input_ids.clone()\n",
        "        labels[:, :-1] = input_ids[:, 1:]   # shift left\n",
        "        labels[:, -1] = pad_idx             # pad the last token\n",
        "        labels[labels == pad_idx] = -100    # mask out padding\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        _, loss = model(input_ids, targets=labels)\n",
        "        total_loss += loss.detach()\n",
        "\n",
        "        evaluated_on_tokens += (batch != pad_idx).sum().item()\n",
        "\n",
        "    total_loss = total_loss / total_batches\n",
        "\n",
        "    return total_loss, evaluated_on_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RJMiZHtLOEAg",
      "metadata": {
        "id": "RJMiZHtLOEAg"
      },
      "outputs": [],
      "source": [
        "pad_idx = tokenizer.pad_token_id\n",
        "\n",
        "world_size = 1  # The number of GPUs we will use, here is set to 1 as multi-GPU training is not implemented.\n",
        "\n",
        "gradient_accumulation = None\n",
        "\n",
        "if total_batch_size is not None:\n",
        "    if gradient_accumulation is None:\n",
        "        assert (\n",
        "            total_batch_size % world_size == 0\n",
        "        ), \"total_batch_size must be divisible by world_size\"\n",
        "        gradient_accumulation = total_batch_size // (\n",
        "            device_batch_size * world_size\n",
        "        )\n",
        "        assert (\n",
        "            gradient_accumulation > 0\n",
        "        ), \"gradient_accumulation must be greater than 0\"\n",
        "\n",
        "assert (\n",
        "    gradient_accumulation * device_batch_size * world_size\n",
        "    == total_batch_size\n",
        "), \"gradient_accumulation * device_batch_size * world_size must be equal to total_batch_size\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mq6Pb7S8OFPH",
      "metadata": {
        "id": "mq6Pb7S8OFPH"
      },
      "outputs": [],
      "source": [
        "def run_experiment(optimizer_name, lr, weight_decay, num_training_steps, seed=42):\n",
        "    import random\n",
        "\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    gptconf = GPTConfig(**model_args)\n",
        "    model = GPT(gptconf).to(device)\n",
        "    model = torch.compile(model)\n",
        "\n",
        "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "\n",
        "    optimizer = create_optimizer(\n",
        "        optimizer_name,\n",
        "        trainable_params,\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "    )\n",
        "\n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=num_training_steps,\n",
        "        last_epoch=-1,\n",
        "    )\n",
        "\n",
        "    global_step = 0  # = update_step * gradient_accumulation\n",
        "    update_step = 0\n",
        "    tokens_seen = 0  # = global_step / gradient_accumulation\n",
        "    tokens_seen_before = 0\n",
        "\n",
        "    losses = []\n",
        "    eval_losses = []\n",
        "\n",
        "    # ========== 4. training loop ==========\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        if batch_idx == 0:\n",
        "            tokens_seen_before = tokens_seen\n",
        "        if update_step >= num_training_steps:\n",
        "            print(\n",
        "                f\"[{optimizer_name} | lr={lr}] Reached max number of update steps ({num_training_steps}). Stopping training.\"\n",
        "            )\n",
        "            break\n",
        "\n",
        "        global_step += 1\n",
        "\n",
        "        input_ids = batch.to(device)\n",
        "        labels = input_ids.clone()\n",
        "        labels[:, :-1] = input_ids[:, 1:]   # shift left\n",
        "        labels[:, -1] = pad_idx             # pad the last token\n",
        "        labels[labels == pad_idx] = -100    # mask out padding\n",
        "        labels = labels.to(device)\n",
        "        tokens_seen += (input_ids != pad_idx).sum().item()\n",
        "\n",
        "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):  # Automatic mixed precision\n",
        "            logits, loss = model(input_ids, targets=labels)\n",
        "            scaled_loss = loss / gradient_accumulation\n",
        "\n",
        "        scaled_loss.backward()\n",
        "\n",
        "\n",
        "        if global_step % gradient_accumulation != 0:\n",
        "            continue\n",
        "\n",
        "        losses.append((loss.item(), update_step))\n",
        "\n",
        "        if update_step % print_freq == 0:\n",
        "            print(\n",
        "                f\"[{optimizer_name} | lr={lr}] \"\n",
        "                f\"Update step: {update_step}/{num_training_steps} | loss: {loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "\n",
        "        if grad_clipping != 0.0:\n",
        "            torch.nn.utils.clip_grad_norm_(trainable_params, grad_clipping)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        update_step += 1\n",
        "\n",
        "        if eval_every > 0 and ((update_step % eval_every == 0) or (update_step == num_training_steps)):\n",
        "            total_loss, evaluated_on_tokens = evaluate_model(\n",
        "                model, val_data, preprocess_batched, pad_idx, device, device_batch_size,\n",
        "            )\n",
        "\n",
        "            total_loss_val = total_loss.detach().cpu().item()\n",
        "            eval_losses.append((total_loss_val, update_step))\n",
        "\n",
        "            print(\n",
        "                f\"[Eval Step {update_step} | {optimizer_name} | lr={lr}] \"\n",
        "                f\"Loss: {total_loss_val:.4f}, PPL: {np.exp(total_loss_val):.2f}, \"\n",
        "                f\"Eval tokens {evaluated_on_tokens}\"\n",
        "            )\n",
        "\n",
        "    print(f\"Training finished for optimizer={optimizer_name}, lr={lr}\")\n",
        "    return model, losses, eval_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vha94swJONQ2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vha94swJONQ2",
        "outputId": "548a2137-f8e1-4100-cb14-93e7399f8d6b"
      },
      "outputs": [],
      "source": [
        "# training test\n",
        "model_test, losses_test, eval_losses_test = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=100,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lvhrzkKlO3UE",
      "metadata": {
        "id": "lvhrzkKlO3UE"
      },
      "outputs": [],
      "source": [
        "exp_config = {\n",
        "    \"adam\":    [1e-4, 3e-4, 1e-3],\n",
        "    \"rmsprop\": [3e-4, 1e-3, 3e-3],\n",
        "    \"signsgd\": [1e-4, 3e-4, 1e-3],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gf_6mzfgPg6O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf_6mzfgPg6O",
        "outputId": "c2a12c76-274c-4eab-ac41-3f14ef7eb7fa"
      },
      "outputs": [],
      "source": [
        "# ---- Adam ----\n",
        "model_a1, losses_a1, eval_a1 = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_a2, losses_a2, eval_a2 = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_a3, losses_a3, eval_a3 = run_experiment(\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZWdpqNGxlyTq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWdpqNGxlyTq",
        "outputId": "32503553-a051-40cc-915b-62c082a13790"
      },
      "outputs": [],
      "source": [
        "model_r1, losses_r1, eval_r1 = run_experiment(\n",
        "    optimizer_name=\"rmsprop\",\n",
        "    lr=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_r2, losses_r2, eval_r2 = run_experiment(\n",
        "    optimizer_name=\"rmsprop\",\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_r3, losses_r3, eval_r3 = run_experiment(\n",
        "    optimizer_name=\"rmsprop\",\n",
        "    lr=3e-3,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KTJyRNv86FaK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTJyRNv86FaK",
        "outputId": "b553733d-247c-465c-c6d6-9205c2848ea9"
      },
      "outputs": [],
      "source": [
        "# ---- SignSGD:\n",
        "\n",
        "# 1) lr = 1e-5\n",
        "model_s1, losses_s1, eval_s1 = run_experiment(\n",
        "    optimizer_name=\"signsgd\",\n",
        "    lr=1e-5,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 2) lr = 3e-5\n",
        "model_s2, losses_s2, eval_s2 = run_experiment(\n",
        "    optimizer_name=\"signsgd\",\n",
        "    lr=3e-5,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 3) lr = 1e-4\n",
        "model_s3, losses_s3, eval_s3 = run_experiment(\n",
        "    optimizer_name=\"signsgd\",\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.0,\n",
        "    num_training_steps=5_000,\n",
        "    seed=42,\n",
        ")\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4623dcf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "4623dcf2",
        "outputId": "58df0645-026a-4724-d72b-4346fe0e6d1a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "losses_ = [l for (l,s) in losses]\n",
        "plt.plot(losses_)\n",
        "plt.grid()\n",
        "plt.xlabel(\"Update step\")\n",
        "plt.ylabel(\"Training loss\")\n",
        "plt.show()\n",
        "\n",
        "eval_losses_ = [l for (l,s) in eval_losses]\n",
        "eval_steps = [s for (l,s) in eval_losses]\n",
        "plt.plot(eval_steps, eval_losses_)\n",
        "plt.grid()\n",
        "plt.xlabel(\"Update step\")\n",
        "plt.ylabel(\"Validation loss\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "017c582da00441c3b9e20e28b792278d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05d2475126b245f58415913daadac6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fc20630c5f49d08294accfd2b3ed63",
            "placeholder": "​",
            "style": "IPY_MODEL_7040424a42594d30a297f63f9018eb70",
            "value": "Resolving data files: 100%"
          }
        },
        "06cc5908329948559f8e8cdd5c9c0efe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0210abcc4c4363a475784b5d44d9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13af8dbc8dff45f28ced8d4b2565d426": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a1c9e763ec4e01a423b6d1ad32aa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18504d4b21f2428d94ba9c82c9a9a5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cc5908329948559f8e8cdd5c9c0efe",
            "placeholder": "​",
            "style": "IPY_MODEL_d2f8d68ca1d946338188047f76b00a3e",
            "value": "Resolving data files: 100%"
          }
        },
        "19abd8a981c341f7a379445d47c00678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a7c7177d4644b6889e9284e6583047a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f8ba60976a4da69b9f8ecdbbfee1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4d82dc90a846ff9fc78af4bbcabcb7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac93e37112a45eb8f25b855ea3f3f11",
            "value": 1
          }
        },
        "20ff0ad5c659495a9ede2e0d166cde5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21c28abb0681465ab9babba2f33500d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41afe3bb0673490eb66b65d69cd7ddf5",
            "placeholder": "​",
            "style": "IPY_MODEL_466c587a3272436885f4b725d69ef631",
            "value": " 1024/1024 [00:00&lt;00:00, 19313.90it/s]"
          }
        },
        "22f54e8bf37749ecac65acc58fce09f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff6a75b90334d8eb7c16f343c4a4d1b",
            "placeholder": "​",
            "style": "IPY_MODEL_86b387f390e84798adb088702906748f",
            "value": "Resolving data files: 100%"
          }
        },
        "26e936723f5e4c1ab7b1491594f582a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29201687179f443ba5c9e20f70e5fa6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac93e37112a45eb8f25b855ea3f3f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fdf9926313f44889ff76983fa6cb7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3023c8a4ad3340e0af7fb880432a7060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a213e82c4260472f899bb5e3784694ca",
            "placeholder": "​",
            "style": "IPY_MODEL_345b6b53dd99431792e107736c601563",
            "value": "config.json: 100%"
          }
        },
        "3213f3114e124e1dab849055dfb99236": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345b6b53dd99431792e107736c601563": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d46743637a84f3f893390707e28b04d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e59e9fff8784e90bbc6d7395f50318c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ec16b8cfb04af2bfffa337643d06d6",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7283d05676fb47658a70bb53f5950c48",
            "value": 1024
          }
        },
        "3ed65d7e9ed045c1a95489f486ac6b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c7d1ac09754bafb7a49c0f84d86008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41afe3bb0673490eb66b65d69cd7ddf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4227aa820574412fa35b865904c3bc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3023c8a4ad3340e0af7fb880432a7060",
              "IPY_MODEL_caec2fe11b18487aab358e3586cebaf9",
              "IPY_MODEL_85334869b60d46ccb341584806ca64f2"
            ],
            "layout": "IPY_MODEL_e3658c5f4bc74e79aa44faa6e4d93feb"
          }
        },
        "43fc20630c5f49d08294accfd2b3ed63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466c587a3272436885f4b725d69ef631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cb2454931e943d5b2c26754797409e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22f54e8bf37749ecac65acc58fce09f0",
              "IPY_MODEL_ae80531f0e0f4d7099f0f2f969fb749f",
              "IPY_MODEL_8db936b3803644e68739e96e3813fc81"
            ],
            "layout": "IPY_MODEL_c83285f1f4de42cf8259bc4abd4c9550"
          }
        },
        "4f98ed06f4df430d9b43a322345166b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05d2475126b245f58415913daadac6e4",
              "IPY_MODEL_3e59e9fff8784e90bbc6d7395f50318c",
              "IPY_MODEL_c1d8ca0f36e947feb2b67a7d1a5b4fe1"
            ],
            "layout": "IPY_MODEL_9f65cae127454e76b6f07a1de0cd345d"
          }
        },
        "4fb934f1ef3c43a781b8daf123f820c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ff6a75b90334d8eb7c16f343c4a4d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53cccf8246d94244b870b517ea30406f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597d9713266448e8911ba6774914f5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f11c8f993e1a44ae852c58c5215b1e90",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_953cd0368abb4df7bd8ae3ec58325cdb",
            "value": 1355256
          }
        },
        "5ad3ccbaabb042639b5a9dea1b705dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3dfcb533f74fa78d6d295e992a8043",
            "placeholder": "​",
            "style": "IPY_MODEL_ed784516b3fd49279412daa03bd17057",
            "value": "README.md: "
          }
        },
        "5cadb7c3923c4f78be514e744c2a9019": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2d6db1d8044b52b998b29edc868b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13af8dbc8dff45f28ced8d4b2565d426",
            "placeholder": "​",
            "style": "IPY_MODEL_f7050cb4d71c47b5aaacb5fbe7f638cf",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "6268c346f73f4b1e8be7b08beaf01907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67d4e82df8b34308bb0619b56bf509da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c29bd62fbcb4c62b84211f6b3478f17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7040424a42594d30a297f63f9018eb70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71ecbfdb44674eaabb5f71bb16279834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90729b4f86f4b8c87398feff4dc758f",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76db9a5dc7d048e0a8c0bac28d6840df",
            "value": 1024
          }
        },
        "7283d05676fb47658a70bb53f5950c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76db9a5dc7d048e0a8c0bac28d6840df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76dcd1614e4e4fd48c44ae943ae95ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7931a0b03c4d1bb5e141ba2b17a177": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806a074ef3884c1ab673bf5c9643fd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85334869b60d46ccb341584806ca64f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97378dffec5742bcba643da722311d45",
            "placeholder": "​",
            "style": "IPY_MODEL_b5dc4ebe18014e45abf6af4ce5377740",
            "value": " 665/665 [00:00&lt;00:00, 82.7kB/s]"
          }
        },
        "86b387f390e84798adb088702906748f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87784bba62d0453f9eb68b3bf2414fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4d82dc90a846ff9fc78af4bbcabcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8db936b3803644e68739e96e3813fc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e4902a9529457cb378934505ee167d",
            "placeholder": "​",
            "style": "IPY_MODEL_acba8a786c294e0086941d56e39559e7",
            "value": " 1024/1024 [00:00&lt;00:00, 21276.22it/s]"
          }
        },
        "9132e199de5f4161829aa035d83ff25c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e4902a9529457cb378934505ee167d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953cd0368abb4df7bd8ae3ec58325cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9713c7f9b5684221b124330d6a8380bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97378dffec5742bcba643da722311d45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9800d01ca55a429993fca5fe3f46274a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9887782b6f2c409abfeae5594be766ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d4e82df8b34308bb0619b56bf509da",
            "placeholder": "​",
            "style": "IPY_MODEL_7d7931a0b03c4d1bb5e141ba2b17a177",
            "value": " 41.1k/? [00:00&lt;00:00, 4.12MB/s]"
          }
        },
        "9a921fb569cb422aa8f8426abb7aaec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8e4aae2a5404b108b89a9a20dc5c981",
              "IPY_MODEL_71ecbfdb44674eaabb5f71bb16279834",
              "IPY_MODEL_21c28abb0681465ab9babba2f33500d6"
            ],
            "layout": "IPY_MODEL_bd4096919b7e4dc4aed8292e04b212e6"
          }
        },
        "9cacdf8a2165429aa20906f7e8fae7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3213f3114e124e1dab849055dfb99236",
            "placeholder": "​",
            "style": "IPY_MODEL_9800d01ca55a429993fca5fe3f46274a",
            "value": " 456k/456k [00:00&lt;00:00, 13.7MB/s]"
          }
        },
        "9de1f861da034d05bce1e3e4b0134b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fdf9926313f44889ff76983fa6cb7d1",
            "placeholder": "​",
            "style": "IPY_MODEL_e4686d632d444410bdef83cfe0512da6",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 7.38MB/s]"
          }
        },
        "9df45a7573fe414d88a6fedbe5b17e14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f65cae127454e76b6f07a1de0cd345d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a213e82c4260472f899bb5e3784694ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b67c1bdddf414892c966bfff2c49bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a90729b4f86f4b8c87398feff4dc758f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaee85e870cf47d59fe68bfd2e5c6367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd6a722354fc45a9aba111d3e4f81bcc",
              "IPY_MODEL_e4f2409b9c5b4e03a2d0dacb877bd1a8",
              "IPY_MODEL_ac7fd2f1553f4f05a95483aca960a65d"
            ],
            "layout": "IPY_MODEL_5cadb7c3923c4f78be514e744c2a9019"
          }
        },
        "ac7fd2f1553f4f05a95483aca960a65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9df45a7573fe414d88a6fedbe5b17e14",
            "placeholder": "​",
            "style": "IPY_MODEL_6268c346f73f4b1e8be7b08beaf01907",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.38kB/s]"
          }
        },
        "acba8a786c294e0086941d56e39559e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad3f990645a14c27971468382cc1248e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_deb828d5d05848df966d7079a5b345ca",
              "IPY_MODEL_d2bcdce069584f35b8afd9ba5ac02d35",
              "IPY_MODEL_9cacdf8a2165429aa20906f7e8fae7f8"
            ],
            "layout": "IPY_MODEL_e98514dbbe4747e7a20fc115260e9fca"
          }
        },
        "ae80531f0e0f4d7099f0f2f969fb749f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca896404845947debedd701c8ab32aad",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26e936723f5e4c1ab7b1491594f582a2",
            "value": 1024
          }
        },
        "b167b2d660a64fcd93830558319b8825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b3d2420ade4a0cbcaac25d07a68c65",
            "placeholder": "​",
            "style": "IPY_MODEL_0c0210abcc4c4363a475784b5d44d9a7",
            "value": "tokenizer.json: 100%"
          }
        },
        "b183060e48794cd8afc2f1696c99d5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d534a87acb3e4bc4a8f239b2c5c8b58d",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15a1c9e763ec4e01a423b6d1ad32aa1d",
            "value": 1042301
          }
        },
        "b30a44b9188540f1b676f74200fe9ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5a2b165736f4bccb16645eca8571cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5dc4ebe18014e45abf6af4ce5377740": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd4096919b7e4dc4aed8292e04b212e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0cd9e4eb4945908b5ce35328457134": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09bb648daca48b2a223ea788bf70c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18504d4b21f2428d94ba9c82c9a9a5fd",
              "IPY_MODEL_dd6fccd8e72e4c7baaa52492ceef2915",
              "IPY_MODEL_c3e13d6e8b4d46ca8c2e93b344de3214"
            ],
            "layout": "IPY_MODEL_29201687179f443ba5c9e20f70e5fa6f"
          }
        },
        "c1d8ca0f36e947feb2b67a7d1a5b4fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5095556c634b0888e9c657ab96455f",
            "placeholder": "​",
            "style": "IPY_MODEL_e7a2b9f885024bb588fc691837b63b54",
            "value": " 1024/1024 [00:04&lt;00:00,  2.68it/s]"
          }
        },
        "c3e13d6e8b4d46ca8c2e93b344de3214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9cb516e3cf4e3e83202a9841205eec",
            "placeholder": "​",
            "style": "IPY_MODEL_20ff0ad5c659495a9ede2e0d166cde5e",
            "value": " 1024/1024 [00:00&lt;00:00, 38251.61it/s]"
          }
        },
        "c83285f1f4de42cf8259bc4abd4c9550": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca896404845947debedd701c8ab32aad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caec2fe11b18487aab358e3586cebaf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76dcd1614e4e4fd48c44ae943ae95ac9",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19abd8a981c341f7a379445d47c00678",
            "value": 665
          }
        },
        "ccb3142c6148411ca038b1ab24d149bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ad3ccbaabb042639b5a9dea1b705dcb",
              "IPY_MODEL_20f8ba60976a4da69b9f8ecdbbfee1d7",
              "IPY_MODEL_9887782b6f2c409abfeae5594be766ca"
            ],
            "layout": "IPY_MODEL_9132e199de5f4161829aa035d83ff25c"
          }
        },
        "cd5095556c634b0888e9c657ab96455f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6a722354fc45a9aba111d3e4f81bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53cccf8246d94244b870b517ea30406f",
            "placeholder": "​",
            "style": "IPY_MODEL_a7b67c1bdddf414892c966bfff2c49bd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ce9cb516e3cf4e3e83202a9841205eec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bcdce069584f35b8afd9ba5ac02d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7c7177d4644b6889e9284e6583047a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b30a44b9188540f1b676f74200fe9ae8",
            "value": 456318
          }
        },
        "d2f8d68ca1d946338188047f76b00a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d534a87acb3e4bc4a8f239b2c5c8b58d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6fccd8e72e4c7baaa52492ceef2915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed7bf690fe964b9e8094522e8b93ab80",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87784bba62d0453f9eb68b3bf2414fec",
            "value": 1024
          }
        },
        "deb828d5d05848df966d7079a5b345ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0cd9e4eb4945908b5ce35328457134",
            "placeholder": "​",
            "style": "IPY_MODEL_4fb934f1ef3c43a781b8daf123f820c1",
            "value": "merges.txt: 100%"
          }
        },
        "e2b3d2420ade4a0cbcaac25d07a68c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3658c5f4bc74e79aa44faa6e4d93feb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4686d632d444410bdef83cfe0512da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4f2409b9c5b4e03a2d0dacb877bd1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed65d7e9ed045c1a95489f486ac6b3b",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_017c582da00441c3b9e20e28b792278d",
            "value": 26
          }
        },
        "e7a2b9f885024bb588fc691837b63b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e4aae2a5404b108b89a9a20dc5c981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9713c7f9b5684221b124330d6a8380bb",
            "placeholder": "​",
            "style": "IPY_MODEL_40c7d1ac09754bafb7a49c0f84d86008",
            "value": "Resolving data files: 100%"
          }
        },
        "e98514dbbe4747e7a20fc115260e9fca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed784516b3fd49279412daa03bd17057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed7bf690fe964b9e8094522e8b93ab80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f11c8f993e1a44ae852c58c5215b1e90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12d07ad22ab481397db0e8736579884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fedb2ad2aeb84cfbb8557e62dc29a0d8",
              "IPY_MODEL_b183060e48794cd8afc2f1696c99d5bd",
              "IPY_MODEL_5f2d6db1d8044b52b998b29edc868b6a"
            ],
            "layout": "IPY_MODEL_3d46743637a84f3f893390707e28b04d"
          }
        },
        "f7050cb4d71c47b5aaacb5fbe7f638cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ec16b8cfb04af2bfffa337643d06d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa16ac0dd4be4d609ddf5a685cbaf7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b167b2d660a64fcd93830558319b8825",
              "IPY_MODEL_597d9713266448e8911ba6774914f5cd",
              "IPY_MODEL_9de1f861da034d05bce1e3e4b0134b12"
            ],
            "layout": "IPY_MODEL_6c29bd62fbcb4c62b84211f6b3478f17"
          }
        },
        "fd3dfcb533f74fa78d6d295e992a8043": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedb2ad2aeb84cfbb8557e62dc29a0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806a074ef3884c1ab673bf5c9643fd1e",
            "placeholder": "​",
            "style": "IPY_MODEL_b5a2b165736f4bccb16645eca8571cd2",
            "value": "vocab.json: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
